<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href="http://zhos.me">
  <title>A+</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="A+">
<meta property="og:url" content="http://zhos.me/page/5/index.html">
<meta property="og:site_name" content="A+">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A+">
  
    <link rel="alternative" href="/atom.xml" title="A+" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>
</html>
<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Zhos</a></h1>
		</hgroup>
		
		<p class="header-subtitle">武德</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Zhos</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>武德<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 100%"><a href="/">主页</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-yuque/认识和实现：批量标准化" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/认识和实现：批量标准化/">认识和实现：批量标准化</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/认识和实现：批量标准化/" class="archive-article-date">
  	<time datetime="2018-12-19T14:43:17.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b" target="_blank" rel="noopener">链接</a><br>在本文中，我将回顾Ioffe和Svegedy的批量规范化的有用性。 我还将在Keras中实现批量标准化，并在训练性能方面取得实质性进展。<br><a name="worndf"></a></p>
<h3 id="批量归一化的直观解释"><a href="#批量归一化的直观解释" class="headerlink" title="批量归一化的直观解释"></a><a href="#worndf"></a>批量归一化的直观解释</h3><p><a name="iegmed"></a></p>
<h3 id="训练中的问题"><a href="#训练中的问题" class="headerlink" title="训练中的问题"></a><a href="#iegmed"></a>训练中的问题</h3><p>问题1：随着网络训练，早期层的权重发生变化，因此后期层的输入变化很大。 每层必须根据每批输入的不同分布重新调整其权重。 这减缓了模型训练。 如果我们可以在分布中使层输入更相似，那么网络可以专注于学习类之间的差异。<br>不同批次分布的另一个影响是消失的梯度。 消失的梯度问题是一个大问题，特别是对于S形激活函数。 如果g（x）表示sigmoid激活函数，则为| x | 增加，g’（x）趋于零。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230849299-89520b64-5633-46b5-a7ab-8343e37bce6d.png#width=731" alt><br>问题2.当输入分布变化时，神经元输出也会变化。 这导致神经元输出偶尔波动到S形函数的可饱和区域。 在那里，神经元既不能更新自己的权重，也不能将梯度传递回先前的层。 我们如何保持神经元输出不变为可饱和区域？</p>
<p>如果我们可以将神经元输出限制在零附近的区域，我们可以确保每个层在反向传播期间都会传回一个实质的梯度。 这将导致更快的训练时间和更准确的结果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230974089-30772f12-78be-446d-ac94-1f658676b64c.png#width=731" alt><br><a name="laeagu"></a></p>
<h4 id="批量标准作为解决方案。"><a href="#批量标准作为解决方案。" class="headerlink" title="批量标准作为解决方案。"></a><a href="#laeagu"></a>批量标准作为解决方案。</h4><p>批量标准化减轻了不同层输入的影响。 通过归一化神经元的输出，激活函数将仅接收接近零的输入。 这确保了非消失的梯度，解决了第二个问题。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231047448-2503dee7-466f-4472-a4d3-d4051a58af2f.png#width=747" alt><br>批量归一化将层输出转换为单位高斯分布。 当这些输出通过激活功能馈送时，层激活也将变得更加正常分布。<br>由于一层的输出是下一层的输入，因此层输入现在具有明显较小的批次间差异。 通过减少层输入的变化分布，我们解决了第一个问题。<br><a name="6w4qpz"></a></p>
<h3 id="数学解释"><a href="#数学解释" class="headerlink" title="数学解释"></a><a href="#6w4qpz"></a>数学解释</h3><p>通过批量归一化，我们为每个激活函数寻找以零为中心的单位方差分布。 在训练期间，我们采用激活输入x并将其减去批次均值μ以实现零中心分布。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231155587-c517033a-5650-4858-8dc8-fe71e96bb8f0.png#width=204" alt><br>接下来，我们取x并将其除以批量方差和一个小数，以防止除以零σ+ε。 这可确保所有激活输入分布都具有单位差异。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231189951-b72be3c8-1a47-42a5-bd6d-04e2ba9a6006.png#width=215" alt><br>最后，我们将x hat进行线性转换以缩放并移动批量标准化的输出。 尽管在反向传播期间网络发生了变化，但仍能确保保持这种正常化效果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231250609-5da7503e-4334-4d00-9e24-61689bab04a2.png#width=231" alt><br>在测试模型时，我们不使用批处理均值或方差，因为这会破坏模型。 （提示：单个观察的平均值和方差是多少？）相反，我们计算训练群体的移动平均值和方差估计值。 这些估计值是培训期间计算的所有批次平均值和方差的平均值。<br><a name="kg00mo"></a></p>
<h3 id="批量标准化的好处"><a href="#批量标准化的好处" class="headerlink" title="批量标准化的好处"></a><a href="#kg00mo"></a>批量标准化的好处</h3><p>批量标准化的好处如下。<br>1.有助于防止具有可饱和非线性（sigmoid，tanh等）的网络中的消失梯度<br>通过批量标准化，我们确保任何激活函数的输入不会变为可饱和区域。 批量归一化将这些输入的分布转换为单位高斯（零中心和单位方差）。<br>2.规范模型<br>也许。 Ioffe和Svegeddy提出了这一主张，但没有就此问题进行广泛撰写。 也许这是归一化层输入的结果？<br>3.允许更高的学习率<br>通过在训练期间防止梯度消失的问题，我们可以设置更高的学习率。 批量标准化还降低了对参数标度的依赖性。 较大的学习速率可以增加层参数的规模，这导致梯度在反向传播期间回传时放大。 我需要阅读更多关于此的内容。<br><a name="5qelzv"></a></p>
<h3 id="在Keras实施"><a href="#在Keras实施" class="headerlink" title="在Keras实施"></a><a href="#5qelzv"></a>在Keras实施</h3><p>引入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import keras</span><br><span class="line">from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.image as mpimg</span><br><span class="line"></span><br><span class="line">from keras.models import Model, Sequential</span><br><span class="line">from keras.layers import Input</span><br><span class="line"></span><br><span class="line">from keras.callbacks import ModelCheckpoint, EarlyStopping</span><br><span class="line">from keras.layers import BatchNormalization</span><br><span class="line">from keras.layers import GlobalAveragePooling2D</span><br><span class="line">from keras.layers import Activation</span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D, Dense</span><br><span class="line">from keras.layers import MaxPooling2D, Dropout, Flatten</span><br><span class="line"></span><br><span class="line">import time</span><br></pre></td></tr></table></figure></p>
<p>数据加载和预处理<br>在这笔记本中，我们使用Cifar 100数据集，因为它具有相当的挑战性，并且不会永远用于训练。 唯一的预处理是零中心和图像变化发生器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">from keras.datasets import cifar100</span><br><span class="line">from keras.utils import np_utils</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode=&apos;fine&apos;)</span><br><span class="line"></span><br><span class="line">#scale and regularize the dataset</span><br><span class="line">x_train = (x_train-np.mean(x_train))</span><br><span class="line">x_test = (x_test - x_test.mean())</span><br><span class="line"></span><br><span class="line">x_train = x_train.astype(&apos;float32&apos;)</span><br><span class="line">x_test = x_test.astype(&apos;float32&apos;)</span><br><span class="line"></span><br><span class="line">#onehot encode the target classes</span><br><span class="line">y_train = np_utils.to_categorical(y_train)</span><br><span class="line">y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">        shear_range=0.2,</span><br><span class="line">        zoom_range=0.2,</span><br><span class="line">        horizontal_flip=True)</span><br><span class="line"></span><br><span class="line">train_datagen.fit(x_train)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow(x_train,</span><br><span class="line">                                     y = y_train,</span><br><span class="line">                                    batch_size=80,)</span><br></pre></td></tr></table></figure></p>
<p><a name="kl8xlg"></a></p>
<h3 id="在Keras中构建模型"><a href="#在Keras中构建模型" class="headerlink" title="在Keras中构建模型"></a><a href="#kl8xlg"></a>在Keras中构建模型</h3><p>我们的架构将包括堆叠的3x3卷积，然后是最大池化和dropout。 每个网络中有5个卷积块。 最后一层是一个完全连接的层，有100个节点和softmax激活。<br>我们将构建4个不同的卷积网络，每个网络都具有sigmoid或ReLU激活以及批量标准化或不标准化。 我们将比较每个网络的验证损失。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">def conv_block_first(model, bn=True, activation=&quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    The first convolutional block in each architecture. Only    separate so we can specify the input shape.</span><br><span class="line">    &quot;&quot;&quot;    </span><br><span class="line">   #First Stacked Convolution</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;, input_shape =   x_train.shape[1:]))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line">    #Second Stacked Convolution</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(MaxPooling2D())</span><br><span class="line">    model.add(Dropout(0.15))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def conv_block(model, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Generic convolutional block with 2 stacked 3x3 convolutions, max pooling, dropout, </span><br><span class="line">    and an optional Batch Normalization.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(MaxPooling2D())</span><br><span class="line">    model.add(Dropout(0.15))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def conv_block_final(model, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    I bumped up the number of filters in the final block. I made this separate so that I might be able to integrate Global Average Pooling later on. </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Conv2D(100,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(100,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def fn_block(model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    I&apos;m not going for a very deep fully connected block, mainly so I can save on memory.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Dense(100, activation = &quot;softmax&quot;))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def build_model(blocks=3, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Builds a sequential network based on the specified parameters.</span><br><span class="line">    </span><br><span class="line">    blocks: number of convolutional blocks in the network, must be greater than 2.</span><br><span class="line">    bn: whether to include batch normalization or not.</span><br><span class="line">    activation: activation function to use throughout the network.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model = conv_block_first(model, bn=bn, activation=activation)</span><br><span class="line"></span><br><span class="line">    for block in range(1,blocks-1):</span><br><span class="line">        model = conv_block(model, bn=bn, activation = activation)</span><br><span class="line"></span><br><span class="line">    model = conv_block_final(model, bn=bn, activation=activation)</span><br><span class="line">    model = fn_block(model)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def compile_model(model, optimizer = &quot;rmsprop&quot;, loss = &quot;categorical_crossentropy&quot;, metrics = [&quot;accuracy&quot;]):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Compiles a neural network.</span><br><span class="line">    </span><br><span class="line">    model: the network to be compiled.</span><br><span class="line">    optimizer: the optimizer to use.</span><br><span class="line">    loss: the loss to use.</span><br><span class="line">    metrics: a list of keras metrics.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.compile(optimizer = optimizer,</span><br><span class="line">                 loss = loss,</span><br><span class="line">                 metrics = metrics)</span><br><span class="line">    return model</span><br><span class="line">#COMPILING THE 4 MODELS</span><br><span class="line">sigmoid_without_bn = build_model(blocks = 5, bn=False, activation = &quot;sigmoid&quot;)</span><br><span class="line">sigmoid_without_bn = compile_model(sigmoid_without_bn)</span><br><span class="line"></span><br><span class="line">sigmoid_with_bn = build_model(blocks = 5, bn=True, activation = &quot;sigmoid&quot;)</span><br><span class="line">sigmoid_with_bn = compile_model(sigmoid_with_bn)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">relu_without_bn = build_model(blocks = 5, bn=False, activation = &quot;relu&quot;)</span><br><span class="line">relu_without_bn = compile_model(relu_without_bn)</span><br><span class="line"></span><br><span class="line">relu_with_bn = build_model(blocks = 5, bn=True, activation = &quot;relu&quot;)</span><br><span class="line">relu_with_bn = compile_model(relu_with_bn)</span><br></pre></td></tr></table></figure></p>
<p><a name="c4xpfd"></a></p>
<h3 id="模特训练"><a href="#模特训练" class="headerlink" title="模特训练"></a><a href="#c4xpfd"></a>模特训练</h3><p>没有批量标准化的Sigmoid<br>训练陷入困境。 有100个课程，这个模型从未达到比随机猜测更好的性能（10％准确度）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history1 = sigmoid_without_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        epochs=20,</span><br><span class="line">        verbose=0,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231717659-060d4678-06bf-4045-abc1-cd7ce7cb6c77.png#width=743" alt><br><a name="m0uloq"></a></p>
<h3 id="具有批量标准化的Sigmoid"><a href="#具有批量标准化的Sigmoid" class="headerlink" title="具有批量标准化的Sigmoid"></a><a href="#m0uloq"></a>具有批量标准化的Sigmoid</h3><p>与没有批量标准化不同，该模型在训练期间开始实施。 这可能是批量标准化减轻消失梯度的结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history2 = sigmoid_with_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        verbose=0,</span><br><span class="line">        epochs=20,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231810973-aebf7896-6c50-4d6c-8372-702891142c6f.png#width=724" alt><br><a name="w5h1ml"></a></p>
<h3 id="没有批量标准化的ReLU"><a href="#没有批量标准化的ReLU" class="headerlink" title="没有批量标准化的ReLU"></a><a href="#w5h1ml"></a>没有批量标准化的ReLU</h3><p>在没有批量规范的情况下实施ReLU导致一些初始收益，然后收敛到非最优的局部最小值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history3 = relu_without_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        epochs=20,</span><br><span class="line">        verbose=0,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231864866-451c1cd9-d6ae-4f7e-9aa2-1da0b34f889b.png#width=737" alt><br>具有批量标准化的ReLU<br>与sigmoid模型一样，批量标准化提高了该网络的训练能力。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history4 = relu_with_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        verbose=0,</span><br><span class="line">        epochs=20,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231931611-3c026d90-61b0-41df-b4dc-7a538bf01ce6.png#width=730" alt><br><a name="e5gkmq"></a></p>
<h3 id="比较架构"><a href="#比较架构" class="headerlink" title="比较架构"></a><a href="#e5gkmq"></a>比较架构</h3><p>我们在这里清楚地看到批量标准化的好处。 没有批量标准化的ReLU和S形模型都无法保持训练性能提升。 这可能是渐变消失的结果。 具有批量标准化的体系结构训练得更快，并且比没有批量标准化的体系结构表现更好。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231970491-afc0113d-a1fb-4218-90d5-7104d35cb98b.png#width=724" alt><br><a name="0457"></a></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a><a href="#0457"></a>Conclusion</h3><p>结论<br>批量标准化减少了训练时间并提高了神经网络的稳定性。 此效果适用于sigmoid和ReLU激活功能。 原帖可以在我的<a href="https://www.harrisonjansma.com/" target="_blank" rel="noopener">网站</a>上找到，代码可以在我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/tree/master/07-28-18-Implementing-Batch-Norm" target="_blank" rel="noopener">GitHub</a>上找到。<br><a name="f6b6"></a></p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a><a href="#f6b6"></a>Resources</h3><ul>
<li><p>Original paper by Ioffe and Szegedy. <a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">here.</a></p>
</li>
<li><p>Insert a batch normalization before or after nonlinearities? <a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="noopener">Usage explanation</a></p>
</li>
<li><p>For an explanation of the math and implementation in TensorFlow. <a href="https://towardsdatascience.com/pitfalls-of-batch-norm-in-tensorflow-and-sanity-checks-for-training-networks-e86c207548c8" target="_blank" rel="noopener">Pitfalls of Batch Norm</a></p>
</li>
<li><p>Also this post <a href="https://towardsdatascience.com/how-to-use-batch-normalization-with-tensorflow-and-tf-keras-to-train-deep-neural-networks-faster-60ba4d054b73" target="_blank" rel="noopener">How to use Batch Normalization with TensorFlow and tf.keras</a></p>
</li>
</ul>
<p><a name="3277"></a></p>
<h3 id="Further-reading"><a href="#Further-reading" class="headerlink" title="Further reading"></a><a href="#3277"></a>Further reading</h3><p>Below are some more recent research papers that extend Ioffe and Svegedy’s work.<br><a href="https://arxiv.org/abs/1702.03275v2" target="_blank" rel="noopener">[1]</a> How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)<br><a href="https://arxiv.org/abs/1702.03275v2" target="_blank" rel="noopener">[2]</a> Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models<br><a href="https://arxiv.org/abs/1607.06450v1" target="_blank" rel="noopener">[3]</a> Layer Normalization<br><a href="https://arxiv.org/abs/1602.07868v3" target="_blank" rel="noopener">[4]</a> Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks<br><a href="https://arxiv.org/abs/1803.08494v3" target="_blank" rel="noopener">[5]</a> Group Normalization</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/认识和实现：批量标准化/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/不要在卷积网络中使用Dropout" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/">不要在卷积网络中使用Dropout</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/" class="archive-article-date">
  	<time datetime="2018-12-19T14:04:13.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16" target="_blank" rel="noopener">链接</a></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545228300354-eac11f1e-9363-4b7f-a68d-3b8e81fd80e0.png#width=747" alt><br>如果您想知道如何使用dropout，这里有您要的答案。</p>
<p>我注意到有很多资源可以用来学习深度学习的内容和原因。 不幸的是，当需要制作模型时，他们很少有资源来解释何时以及如何。<br>我正在为试图实施深度学习的其他数据科学家撰写本文。 因此，您不必像我一样通过研究文章和Reddit讨论。<br>在本文中，您将了解为什么dropout在卷积体系结构中不再受欢迎。</p>
<p><a name="drs4ub"></a></p>
<h4 id="DROPOUT"><a href="#DROPOUT" class="headerlink" title="DROPOUT"></a><a href="#drs4ub"></a>DROPOUT</h4><p>如果你正在读这篇文章，我认为你已经了解了什么是dropout，以及它在正则化神经网络方面的作用。 如果您想要复习，请阅读Amar Budhiraja的这篇文章。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545228517714-8daebec1-a6f7-4fcc-b4a8-8c826e025c76.png#width=747" alt><br>通常，当我们的网络存在过度拟合的风险时，我们只需要实现正规化。 如果网络太大，如果您训练时间过长，或者您没有足够的数据，则会发生这种情况。<br>如果在卷积网络末端有完全连接的层，则实现dropout很容易。<br><a name="qseuim"></a></p>
<h4 id="使用Keras"><a href="#使用Keras" class="headerlink" title="使用Keras"></a><a href="#qseuim"></a>使用Keras</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dropout(rate, noise_shape=None, seed=None)</span><br></pre></td></tr></table></figure>
<p>以0.5的dropout率开始并将其调低，直到性能最大化。 （<a href="https://www.reddit.com/r/MachineLearning/comments/3oztvk/why_50_when_using_dropout/" target="_blank" rel="noopener">资源</a>）<br><a name="dx1bhs"></a></p>
<h4 id="例如"><a href="#例如" class="headerlink" title="例如"></a><a href="#dx1bhs"></a>例如</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model=keras.models.Sequential()</span><br><span class="line">model.add(keras.layers.Dense(150, activation=&quot;relu&quot;))</span><br><span class="line">model.add(keras.layers.Dropout(0.5))</span><br></pre></td></tr></table></figure>
<p>请注意，这仅适用于您的convnet的完全连接区域。 对于所有其他地区，您不应使用dropout。<br>相反，您应该在卷积之间插入批量标准化。 这将使您的模型正常化，并使您的模型在训练期间更加稳定。<br><a name="042axx"></a></p>
<h4 id="批正则化"><a href="#批正则化" class="headerlink" title="批正则化"></a><a href="#042axx"></a>批正则化</h4><p>批标准化是规范卷积网络的另一种方法。<br>除了正则化效应之外，批量归一化还可以使您的卷积网络在训练期间抵抗消失的梯度。 这可以减少训练时间并获得更好的性能。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229002104-b14e8bf0-9ba5-4470-85c3-ac86fed74c75.png#width=747" alt><br>批量标准化可以消除消失的梯度<br><br><br></p>
<p><a name="uat1zt"></a></p>
<h4 id="Keras实施"><a href="#Keras实施" class="headerlink" title="Keras实施"></a><a href="#uat1zt"></a>Keras实施</h4><p>要在Keras中实现批量标准化，请使用以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.BatchNormalization()</span><br></pre></td></tr></table></figure></p>
<p>构建具有批量规范化的卷积体系结构时：</p>
<ul>
<li><p>在卷积和激活层之间插入批量标准化层。 （<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="noopener">资源</a>）</p>
</li>
<li><p>您可以在此功能中调整一些超参数，并使用它们。</p>
</li>
</ul>
<p>您也可以在激活功能之后插入批量标准化，但根据我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">经验</a>，这两种方法都具有相似的性能。<br><a name="i9denc"></a></p>
<h4 id="例如-1"><a href="#例如-1" class="headerlink" title="例如"></a><a href="#i9denc"></a>例如</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Activation(&quot;relu&quot;))</span><br></pre></td></tr></table></figure>
<p>批量标准化取代了dropout。<br>即使您不需要担心过度拟合，实现批量标准化也有很多好处。 正因为如此，它的正规化效应，批量归一化已经在很大程度上取代了现代卷积体系结构中的dropout。<br>“我们提出了一种使用批量规范化网络构建，训练和执行推理的算法。 由此产生的网络可以通过饱和非线性进行训练，更能容忍增加的训练率，并且通常不需要Dropout进行正规化。“ -  Ioffe and Svegedy 2015<br>至于为什么dropout在最近的应用中失宠，主要有两个原因。<br><strong>首先</strong>，在对卷积层进行正则化时，dropout通常不太有效。<br>原因？ 由于卷积层具有很少的参数，因此它们开始时需要较少的正则化。 此外，由于在特征图中编码的空间关系，激活可以变得高度相关。 这使得dropout无效。（<a href="https://www.reddit.com/r/MachineLearning/comments/5l3f1c/d_what_happened_to_dropout/" target="_blank" rel="noopener">资源</a>）<br><strong>其次</strong>，擅长正规化的dropout现在已经过时了。<br>像VGG16这样在网络末端包含完全连接的层的大型模型。 对于这样的模型，过度拟合是通过在完全连接的层之间包括dropout来解决的。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229692686-cc1c012c-7f9a-4865-b6eb-fe547e0f1213.png#width=470" alt><br>不幸的是，<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">最近的架构</a>远离了这个完全连接块。<br>通过用全局平均池替换密集层，现代的网络可以减少模型大小，同时提高性能。<br>我将在未来再写一篇文章，详细说明如何在卷积网络中实现全球平均汇集。 在此之前，我建议阅读<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">ResNet论文</a>，以了解GAP的好处。<br><a name="btyoyw"></a></p>
<h4 id="一个实验"><a href="#一个实验" class="headerlink" title="一个实验"></a><a href="#btyoyw"></a>一个实验</h4><p>我创建了一个实验来测试批量标准化是否会减少在卷积之间插入时的泛化错误。 （<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">链接</a>）<br>我构建了5个相同的卷积体系结构，并在卷积之间插入了dropout，批量规范或任何（控制）。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229984300-3501e371-42ce-41de-8aec-2d6962959cd3.png#width=500" alt><br>通过在Cifar100数据集上训练每个模型，我获得了以下结果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230018898-2895598f-bf57-42f7-ad4f-b7440add1220.png#width=724" alt><br>批量标准化模型的良好表现说明应在卷积之间使用批量标准化。<br>此外，不应在卷基层之间放置dropout，因为dropout的模型往往比控制模型表现更差。<br>有关更多信息，请查看我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">GitHub</a>上的完整文章。<br>小贴士<br>如果你想知道是否应该在卷积网络中实现dropout，现在你知道了。 仅在完全连接的层上使用dropout，并在卷积之间实现批量标准化。<br>如果您想了解有关批量标准化的更多信息，请阅读：<br><a href="https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b" target="_blank" rel="noopener">https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/理解二进制交叉熵、对数损失函数:一种可视化解释" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/">理解二进制交叉熵、对数损失函数:一种可视化解释</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/" class="archive-article-date">
  	<time datetime="2018-12-19T08:27:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a" target="_blank" rel="noopener">链接</a></p>
<p><a name="61a3ec66"></a></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><a href="#ba72yr"></a>介绍</h2><p>如果您正在训练二进制分类器，则可能使用二进制交叉熵/对数损失作为损失函数。<br>你有没有想过使用这种损失函数究竟是什么意思？ 问题是，考虑到今天的库和框架的易用性，很容易忽略所使用的损失函数的真正含义。<br>动机<br>我正在寻找一篇博文，以一种视觉上清晰简洁的方式解释二进制交叉熵/对数损失背后的概念，所以我可以在Data Science Retreat向我的学生展示它。 由于我找不到任何符合我目的的东西，我自己负责编写任务:-)。<br>一个简单的分类问题<br>让我们从10个随机点开始：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = [-2.2, -1.4, -0.8, 0.2, 0.4, 0.8, 1.2, 2.2, 2.9, 4.6]</span><br></pre></td></tr></table></figure></p>
<p>这是我们唯一的特征：x。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208575711-9a5c4e19-f272-468f-b36e-0d7074d62586.png#align=left&amp;display=inline&amp;height=111&amp;originHeight=111&amp;originWidth=625&amp;status=done&amp;width=625" alt><br>现在，让我们为我们的点分配一些颜色：红色和绿色。 这些是我们的标签。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208606509-b2a7b1cd-b1cf-4ca4-baca-88196d101a0b.png#align=left&amp;display=inline&amp;height=110&amp;originHeight=110&amp;originWidth=643&amp;status=done&amp;width=643" alt><br>因此，我们的分类问题非常简单：鉴于我们的特征x，我们需要预测其标签：红色或绿色。</p>
<p>由于这是一个二元分类，我们也可以将这个问题描述为：“是点绿色”，或者更好的是，“点是绿色的概率是多少”？ 理想情况下，绿点的概率为1.0（绿色），而红点的概率为0.0（绿色）。</p>
<p>在此设置中，绿点属于正类（YES，它们是绿色），而红点属于负类（NO，它们不是绿色）。<br>如果我们拟合模型来执行此分类，它将预测每个点的绿色概率。 根据我们对点的颜色的了解，我们如何评估预测概率的优劣（或差）？ 这是损失功能的全部目的！ 它应该为错误预测返回高值，为良好预测返回低值。</p>
<p>对于像我们的例子那样的二进制分类，典型的损失函数是二进制交叉熵/对数损失函数。<br><a name="6dab43bd"></a></p>
<h2 id="损失函数：二进制交叉熵-对数损失函数"><a href="#损失函数：二进制交叉熵-对数损失函数" class="headerlink" title="损失函数：二进制交叉熵/对数损失函数"></a><a href="#gh52id"></a>损失函数：二进制交叉熵/对数损失函数</h2><p>如果你观察这个损失函数，这就是你会发现的：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208847996-2aba3677-2186-4f8c-bdab-ae8590ad7c6b.png#align=left&amp;display=inline&amp;height=79&amp;originHeight=79&amp;originWidth=548&amp;status=done&amp;width=548" alt><br>Binary Cross-Entropy / Log Loss<br>其中y是标签（绿点为1，红点为0），p(y)是所有N点的点为绿色的预测概率。</p>
<p>阅读这个公式，它告诉你，对于每个绿点（y = 1），它将log（p（y））添加到损失中，即它是绿色的对数概率。 相反，它为每个红点（y = 0）添加log（1-p（y）），即，它为红色的对数概率。 不一定很难，当然也不是那么直观……</p>
<p>此外，熵与这一切有什么关系？ 为什么我们首先记录概率？ 这些是有效的问题，我希望在下面的“给我看数学”部分回答它们。</p>
<p><a name="9acf4584"></a></p>
<h3 id="计算损失-可视化方法"><a href="#计算损失-可视化方法" class="headerlink" title="计算损失-可视化方法"></a><a href="#sbsnmi"></a>计算损失-可视化方法</h3><p>首先，让我们根据他们的类别（正面或负面）分割点数，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214792607-9e822a37-5f9e-46cb-bc0b-0a68f744faff.png#align=left&amp;display=inline&amp;height=224&amp;originHeight=224&amp;originWidth=620&amp;status=done&amp;width=620" alt><br>现在，让我们训练一个Logistic回归来对我们的点进行分类。 拟合回归是一个S形曲线，表示任何给定x点的绿色概率。 它看起来像这样：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214823897-b1ef51c7-4c5f-4ca4-8543-81231a9f1918.png#align=left&amp;display=inline&amp;height=215&amp;originHeight=215&amp;originWidth=686&amp;status=done&amp;width=686" alt><br>那么，对于属于正类（绿色）的所有点，我们的分类器给出的预测概率是多少？ 这些是S形曲线下的绿色条形，在与这些点对应的x坐标处。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214857312-a0a2e0e3-5317-4fe4-b9a8-64d6f07dbdf1.png#align=left&amp;display=inline&amp;height=209&amp;originHeight=209&amp;originWidth=683&amp;status=done&amp;width=683" alt><br>好的，到目前为止，真好！ 负面阶级的观点怎么样？ 请记住，S形曲线下的绿色条表示给定点为绿色的概率。 那么，给定点是红色的概率是多少？ 红色条在S形曲线上方，当然:-)<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214885683-601d1b29-50b1-4f89-98d8-242b19e28808.png#align=left&amp;display=inline&amp;height=209&amp;originHeight=209&amp;originWidth=678&amp;status=done&amp;width=678" alt><br>总而言之，我们最终会得到这样的结论：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214919348-98029aeb-bbdd-4969-b2bd-c5d5a5b9b83d.png#align=left&amp;display=inline&amp;height=210&amp;originHeight=210&amp;originWidth=683&amp;status=done&amp;width=683" alt><br>条形表示与每个点的相应真实类别相关联的预测概率！</p>
<p>好的，我们有预测的概率……通过计算二进制交叉熵/对数损失来评估它们的时间！</p>
<p>这些概率就是我们所需要的，所以，让我们摆脱x轴并将条带彼此相邻：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214956710-95a7d392-f358-48ef-bf1e-6fc94c658e98.png#align=left&amp;display=inline&amp;height=262&amp;originHeight=262&amp;originWidth=425&amp;status=done&amp;width=425" alt><br>好吧，吊杆不再有意义了，所以让我们重新定位它们：</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215026705-0bd2aed9-8956-416f-9449-899f50e0ef36.png#align=left&amp;display=inline&amp;height=254&amp;originHeight=254&amp;originWidth=434&amp;status=done&amp;width=434" alt><br>既然我们正试图计算损失，我们需要惩罚不好的预测，对吧？ 如果与真实类相关的概率为1.0，我们需要将其损失为零。 相反，如果这个概率很低，比如0.01，我们需要它的损失是巨大的！<br>事实证明，对于这个目的，取概率的（负）对数就足够了（因为0.0和1.0之间的值的对数是负的，我们采用负对数来获得损失的正值）。<br>实际上，我们使用日志的原因来自交叉熵的定义，请查看下面的“给我看数学”部分了解更多详情。<br>下图给出了一个清晰的图片 - 如果真实类的预测概率接近零，则损失呈指数增长：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215109720-0cebdd78-1004-4e66-8dba-ed416c518790.png#align=left&amp;display=inline&amp;height=307&amp;originHeight=307&amp;originWidth=418&amp;status=done&amp;width=418" alt><br>很公平！ 让我们采用概率的（负）对数 - 这些是每个点的相应损失。<br>最后，我们计算所有这些损失的平均值。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215139483-4a54d212-a279-400b-afe6-df918499a792.png#align=left&amp;display=inline&amp;height=257&amp;originHeight=257&amp;originWidth=441&amp;status=done&amp;width=441" alt><br>瞧！ 我们已经成功计算了这个玩具示例的二进制交叉熵/对数损失。 它是0.3329！<br>告诉我代码<br>如果你想仔细检查我们找到的值，只需运行下面的代码并亲自看看:-)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import log_loss</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.array([-2.2, -1.4, -.8, .2, .4, .8, 1.2, 2.2, 2.9, 4.6])</span><br><span class="line">y = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])</span><br><span class="line"></span><br><span class="line">logr = LogisticRegression(solver=&apos;lbfgs&apos;)</span><br><span class="line">logr.fit(x.reshape(-1, 1), y)</span><br><span class="line"></span><br><span class="line">y_pred = logr.predict_proba(x.reshape(-1, 1))[:, 1].ravel()</span><br><span class="line">loss = log_loss(y, y_pred)</span><br><span class="line"></span><br><span class="line">print(&apos;x = &#123;&#125;&apos;.format(x))</span><br><span class="line">print(&apos;y = &#123;&#125;&apos;.format(y))</span><br><span class="line">print(&apos;p(y) = &#123;&#125;&apos;.format(np.round(y_pred, 2)))</span><br><span class="line">print(&apos;Log Loss / Cross Entropy = &#123;:.4f&#125;&apos;.format(loss))</span><br></pre></td></tr></table></figure></p>
<p>告诉我数学（真的吗？！）<br>除了笑话之外，这篇文章并不打算在数学上倾向于……但是对于你们这些人，我的读者，想要了解熵的作用，所有这些中的对数，我们在这里:-)<br>如果你想深入了解信息理论，包括所有这些概念 - 熵，交叉熵等等 - 检查Chris Olah的帖子，它非常详细！<br><a name="b2c9e438"></a></p>
<h4 id="分布"><a href="#分布" class="headerlink" title="分布"></a><a href="#gs7ekn"></a>分布</h4><p>让我们从分配点开始吧。 由于y表示我们的点的类（我们有3个红点和7个绿点），这就是它的分布，我们称之为q（y），如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215306977-97044aee-62cc-46c7-b7b2-cc4e60a53c39.png#align=left&amp;display=inline&amp;height=284&amp;originHeight=284&amp;originWidth=432&amp;status=done&amp;width=432" alt></p>
<p>熵<br>熵是与给定分布q（y）相关的不确定性的度量。<br>如果我们所有的积分都是绿色怎么办 那个分布的不确定性是什么？ ZERO，对吗？ 毕竟，对于一个点的颜色毫无疑问：它总是绿色的！ 所以，熵是零！<br>另一方面，如果我们确切地知道一半的点是绿色而另一半点是红色的呢？ 那是最糟糕的情况，对吗？ 猜测点的颜色绝对没有优势：它完全是随机的！ 对于这种情况，熵由下面的公式给出（我们有两个类别（颜色） - 红色或绿色 - 因此，2）：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215372228-11ebb814-6d1e-4797-b42e-94b77db29f6d.png#align=left&amp;display=inline&amp;height=43&amp;originHeight=43&amp;originWidth=166&amp;status=done&amp;width=166" alt><br>对于中间的其他情况，我们可以使用下面的公式计算分布的熵，如q（y），其中C是类的数量：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215399649-c50c5363-f426-4527-bf68-134aee0b35a4.png#align=left&amp;display=inline&amp;height=80&amp;originHeight=80&amp;originWidth=306&amp;status=done&amp;width=306" alt><br>因此，如果我们知道随机变量的真实分布，我们就可以计算其熵。 但是，如果是这样的话，为什么首先要费心去训练分类器呢？ 毕竟，我们知道真正的分布……<br>但是，如果我们不这样做呢？ 我们可以尝试用其他一些分布近似真实分布，比如p（y）吗？ 我们当然可以！:-)<br><a name="bf08985d"></a></p>
<h4 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a><a href="#ekaaou"></a>交叉熵</h4><p>让我们假设我们的观点遵循其他分布p（y）。 但我们知道它们实际上来自真实（未知）分布q（y），对吧？<br>如果我们像这样计算熵，我们实际上是在计算两个分布之间的交叉熵：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215448740-5ec55a28-5c13-46a0-b6d1-197063d62b05.png#align=left&amp;display=inline&amp;height=85&amp;originHeight=85&amp;originWidth=320&amp;status=done&amp;width=320" alt><br>如果我们奇迹般地将p（y）与q（y）完美匹配，则交叉熵和熵的计算值也将匹配。<br>由于这可能永远不会发生，因此交叉熵将具有比在真实分布上计算的熵更大的BIGGER值。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215480123-9afd0d8f-9398-450a-b194-4ab6348a4685.png#align=left&amp;display=inline&amp;height=47&amp;originHeight=47&amp;originWidth=208&amp;status=done&amp;width=208" alt><br>事实证明，交叉熵和熵之间的这个区别有一个名字……<br><a name="bbec16ca"></a></p>
<h4 id="Kullback-Leibler发散"><a href="#Kullback-Leibler发散" class="headerlink" title="Kullback-Leibler发散"></a><a href="#fk7aht"></a>Kullback-Leibler发散</h4><p>Kullback-Leibler Divergence，简称“KL Divergence”，衡量两种发行版之间的差异：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215542635-c4a2d275-64a9-45c9-b68e-3f99fce5fcf5.png#align=left&amp;display=inline&amp;height=89&amp;originHeight=89&amp;originWidth=619&amp;status=done&amp;width=619" alt><br>这意味着，p（y）越接近q（y），发散越低，因此交叉熵越低。<br>所以，我们需要找到一个好的p（y）来使用……但是，这是我们的分类器应该做的，不是吗？！ 确实如此！ 它寻找最好的p（y），这是最小化交叉熵的那个。<br><a name="7162a4e0"></a></p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><a href="#xokywp"></a>损失函数</h4><p>在训练期间，分类器使用其训练集中的N个点中的每一个来计算交叉熵损失，有效地拟合分布p（y）！ 由于每个点的概率是1 / N，因此交叉熵由下式给出：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215580283-c3d40241-87ec-4541-aaf9-971fc6cc90e7.png#align=left&amp;display=inline&amp;height=85&amp;originHeight=85&amp;originWidth=411&amp;status=done&amp;width=411" alt><br>还记得上面的图6到10吗？ 我们需要在与每个点的真实类相关联的概率之上计算交叉熵。 这意味着使用绿色条形作为正类（y = 1）中的点，使用红色条形作为负类中的点（y = 0），或者数学上说：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215611182-db1eab68-632e-45e8-ac03-396234f18194.png#align=left&amp;display=inline&amp;height=75&amp;originHeight=75&amp;originWidth=230&amp;status=done&amp;width=230" alt><br>最后一步是计算两个类中所有点的平均值，正面和负面：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215637206-7fda25fc-c763-46c0-9eca-6e4fe9cec776.png#align=left&amp;display=inline&amp;height=92&amp;originHeight=92&amp;originWidth=592&amp;status=done&amp;width=592" alt><br>最后，通过一些操作，我们可以采用相同的公式，从正面或负面的类中获取任何一点：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215662641-4915d2cb-3c29-4fc8-a535-c0db8b055951.png#align=left&amp;display=inline&amp;height=79&amp;originHeight=79&amp;originWidth=548&amp;status=done&amp;width=548" alt><br>瞧！ 我们回到二进制交叉熵/日志丢失的原始公式:-)<br><a name="fef1217c"></a></p>
<h3 id="最后的想法"><a href="#最后的想法" class="headerlink" title="最后的想法"></a><a href="#3038bg"></a>最后的想法</h3><p>我真的希望这篇文章能够对一个经常被认为理所当然的概念，即二元交叉熵作为损失函数的概念有所启发。 此外，我也希望它能够向您展示机器学习和信息理论如何联系在一起。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/关于目标检测，所有你应该知道的深度学习模型" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/关于目标检测，所有你应该知道的深度学习模型/">关于目标检测，所有你应该知道的深度学习模型</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/关于目标检测，所有你应该知道的深度学习模型/" class="archive-article-date">
  	<time datetime="2018-12-19T07:22:45.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://medium.com/@syshen/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540" target="_blank" rel="noopener">链接</a></p>
<p><a name="e60a"></a></p>
<h3 id="Computer-vision-object-detection-models-R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-YOLO"><a href="#Computer-vision-object-detection-models-R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-YOLO" class="headerlink" title="Computer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO"></a><a href="#e60a"></a>Computer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO</h3><p>这篇是简介一些用来辨识影像中物体的AI 模型。</p>
<p>在前面有提到，透过CNN模型，你可以输入一张图片，<a href="https://medium.com/@syshen/%E5%85%A5%E9%96%80%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-2-d694cad7d1e5" target="_blank" rel="noopener">得到该图片属于哪种类别的结果</a>，这过程我们把他称作分类(Classification)。</p>
<p>但在真实世界的应用情境通常要从一张图片中辨识所有出现的物体， 并且标示出位置来(标出位置称之为Object Localization)。你一定在网路上看过类似底下的影片，这段影片可以看出中国闭路摄影机(CCTV)发展的概况，不只是可以框出影像中每个物件，辨别物件种类，侦测出移动物体的动量，甚至是人脸辨识，实现楚门世界的恶梦。要做到这就需要靠深度学习中的Object Detection 演算法，这也是最近几年来深度学习最蓬勃发展的一块领域。<br><a href="https://youtu.be/aE1kA0Jy0Xg" target="_blank" rel="noopener">https://youtu.be/aE1kA0Jy0Xg</a><br>基本的想法是，既然CNN 对于物体的分类又快又好，那我们可不可以拿CNN 来扫描并辨识图片中的任何物体？答案当然是 — 可以。</p>
<p>最简单的作法就是用Sliding Windows 的概念，也就是用一个固定大小的框框，逐一的扫过整张图片，每次框出来的图像丢到CNN 中去判断类别。由于物体的大小是不可预知的，所以还要用不同大小的框框去侦测。但是Sliding Window 是非常暴力的作法，对单一影像我们需要扫描非常多次，每扫一次都需要算一次CNN，这将会耗费大量的运算资源，而且速度慢，根本无法拿来应用！<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204251780-a74eec91-8d1c-42c3-b27a-da11667ac2c3.png#width=826" alt></p>
<p>所以后来就有人提出了R-CNN (Regions with CNN)<br><a name="68d0"></a></p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a><a href="#68d0"></a>R-CNN</h3><p>与其用Sliding Window的方式扫过一轮，<a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">R-CNN</a>的作法是预先筛选出约2000个可能的区域，再将这2000区域个别去作分类，所以他的演算法流程如下：</p>
<ol>
<li><p>产生一群约2000 个可能的区域(Region Proposals)</p>
</li>
<li><p>经由一个预先训练好的CNN 模型如AlexNet 撷取特征，将结果储存起来。</p>
</li>
<li><p>然后再以SVM (Support Vector Machine) 分类器来区分是否为物体或者背景。</p>
</li>
<li><p>最后经由一个线性回归模型来校正bounding box 位置。</p>
</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204292906-82d75e3e-ada2-4402-8a3e-e1f746718a78.png#width=826" alt><br><a name="9185"></a></p>
<h4 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a><a href="#9185"></a>Selective Search</h4><p>R-CNN用来筛选Region Proposals的方法称之为<a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="noopener">Selective Search</a>，而Selective Search又是基于Felzenszwal于2004年发表的论文<a href="http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf" target="_blank" rel="noopener">Graph Base Image Segmentation</a>。</p>
<p>图像经由Graph Base Image Segmentation 可以切出数个Segment 来，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204317496-a09e245d-e3f5-4fa9-9e62-3fbcd048e2c9.png#width=554" alt><br>而Selective Search 的作法是将Segment 的结果先各自画出bounding box，然后以一个回圈，每次合并相似度最高的两个box，直到整张图合并成单一个box 为止，在这过程中的所有box 便是selective search 出来的region proposals。Selective Search 的演算法如下：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204363747-83bbc0c6-5f23-4b0c-bae2-3d3d18561a34.png#width=826" alt><br>取自Selective Search 论文。先以Graph base image segmentation 取得一些区域，计算每个区域间的相似度，每次合并相似度最高的两个区域，直到整张图片成为单一区域为止。<br>但是R-CNN 存在一些问题，速度仍然不够快：</p>
<ol>
<li><p>R-CNN 一开始必须先产生约2000 个区域，每个区域都要丢进CNN 中去撷取特征，所以需要跑过至少2000 次的CNN</p>
</li>
<li><p>R-CNN 的model 是分开成三部份，分别是用来取出特征的CNN，分类的SVM，以及优化bounding box 的线性回归。所以R-CNN 不容易作训练。</p>
</li>
</ol>
<p>所以R-CNN的其中一个作者<a href="http://www.rossgirshick.info/" target="_blank" rel="noopener">Ross Girshick (RBG大神)</a>在2015年又提出了一个改良版本，并称之为Fast R-CNN。<br><a name="1250"></a></p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a><a href="#1250"></a>Fast R-CNN</h3><p><a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">Fast R-CNN</a>的想法很简单，在R-CNN中，2000多个区域都要个别去运算CNN，这些区域很多都是重叠的，也就是说这些重叠区域的CNN很多都是重复算的。所以Fast R-CNN的原则就是全部只算一次CNN就好，CNN撷取出来的特征可以让这2000多个区域共用！</p>
<p>Fast R-CNN 采用的作法就是RoIPooling (Region of Interest Pooling)。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204447478-48e75d73-6502-4714-a7e2-b1064c212381.png#width=826" alt><br>Fast RCNN 一样要预选Region proposals，但是只做一次CNN。在跑完Convolution layers 的最后一层时，会得到一个HxW 的feature map，同时也要将region proposals 对应到HxW 上，然后在feature map 上取各自region 的MaxPooling，每个region 会得到一个相同大小的矩阵(例如2x2)。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204932699-604244a0-ec32-4161-b825-10e50a4d088b.png#width=800" alt><br>from <a href="https://blog.deepsense.ai/region-of-interest-pooling-explained/" target="_blank" rel="noopener">https://blog.deepsense.ai/region-of-interest-pooling-explained/</a><br>然后各自连接上FC 网路，以及softmax 去作分类。在分类的同时也作bounding box 的线性回归运算。</p>
<p>Fast RCNN 的优点是：</p>
<ol>
<li><p>只需要作一次CNN，有效解省运算时间</p>
</li>
<li><p>使用单一网络，简化训练过程</p>
</li>
</ol>
<p><a name="fcaf"></a></p>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a><a href="#fcaf"></a>Faster R-CNN</h3><p>不管是R-CNN还是Fast R-CNN都还是要先透过selective search预选region proposals，这是一个缓慢的步骤。在2015年时，Microsoft的<a href="http://shaoqingren.com/" target="_blank" rel="noopener">Shaoqing Ren</a> , <a href="http://kaiminghe.com/" target="_blank" rel="noopener">Kaiming He</a> , <a href="http://www.rossgirshick.info/" target="_blank" rel="noopener">Ross Girshick</a> ,以及<a href="http://www.jiansun.org/" target="_blank" rel="noopener">Jian Sun</a>提出了<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN</a>，一个更快的R-CNN。<br>Faster R-CNN 的想法也很直觉，与其预先筛选region proposals，到不如从CNN 的feature map 上选出region proposals。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545204990054-48efb89e-132f-444c-938d-7e4441882e73.png#width=650" alt><br><a name="fef5"></a></p>
<h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a><a href="#fef5"></a>Region Proposal Network</h4><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205011580-f995c601-05b6-4d1c-9958-ca8d13714c32.png#width=826" alt><br>RPN (Region Proposal Network) 也是一个Convolution Network，Input 是之前CNN 输出的feature map，输出是一个bounding box 以及该bounding box 包含一个物体的机率。</p>
<p>RPN 在feature map 上取sliding window，每个sliding window 的中心点称之为anchor point，然后将事先准备好的k 个不同尺寸比例的box 以同一个anchor point 去计算可能包含物体的机率(score) ，取机率最高的box。这k 个box 称之为anchor box。所以每个anchor point 会得到2k 个score，以及4k 个座标位置(box 的左上座标，以及长宽，所以是4 个数值)。在Faster R-CNN 论文里，预设是取3 种不同大小搭配3 种不同长宽比的anchor box，所以k 为3x3 = 9 。</p>
<p>经由RPN 之后，我们便可以得到一些最有可能的bounding box，虽然这些bounding box 不见得精确，但是透过类似于Fast RCNN 的RoIPooling， 一样可以很快的对每个region 分类，并找到最精确的bounding box 座标。<br><a name="83ca"></a></p>
<h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a><a href="#83ca"></a>Mask R-CNN</h3><p>前述几个方法都是在找到物体外围的bounding box，bounding box基本上都是方形，另外一篇有趣的论文是Facebook AI researcher <a href="http://kaiminghe.com/" target="_blank" rel="noopener">Kaiming He</a>所提出的<a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">Mask R-CNN</a>，透过Mask R-CNN不只是找到bounding box，可以做到接近pixel level的遮罩(图像分割Image segmentation)。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205050916-f7cefd4c-be49-44ba-8786-bb25170f7e4d.png#width=826" alt><br>要了解Mask R-CNN 如何取遮罩，要先看一下FCN (Fully Convolutional Network)</p>
<p><a name="28c4"></a></p>
<h4 id="FCN-Fully-Convolutional-Network-for-Image-Segmentation"><a href="#FCN-Fully-Convolutional-Network-for-Image-Segmentation" class="headerlink" title="FCN (Fully Convolutional Network) for Image Segmentation"></a><a href="#28c4"></a>FCN (Fully Convolutional Network) for Image Segmentation</h4><p>有别于CNN 网络最后是连上一个全连接(Fully Connected)的网络，FCN (Fully Convolutional Network)最后接上的是一个卷积层。一般的CNN 只能接受固定大小的Input，但是FCN 则能接受任何大小的Input，例如W x H 。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205073642-70d8970e-7b91-4772-93fe-4c805439a274.png#width=826" alt><br><em>图上方一般的CNN 网络，只能接受大小固定的输入，得到单一维度的输出，分别代表每个类别的机率。图下则是FCN 网路，最后两层由卷积取代，输出为hxwx 1000，代表每个pixel 种类的机率，可以视为一个heapmap。</em></p>
<p>在CNN 的过程中会一直作downsampling，所以FCN 最后的输出可能为H/32 x W/32，实际上得到的会是一个像heapmap 的结果。但是由于这过程是downsampling，所以Segment 的结果是比较粗糙，为了让Segment 的效果更好，要再做upsampling，来补足像素。upsamping 的作法是取前面几层的结果来作差补运算。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205110140-81193d10-5537-493b-9d73-b9b4353ac2d1.png#width=826" alt><br>FCN 的结果会跟前面几层的输出作差补运算<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205127937-663202b8-0a40-43e5-a833-7854a202f6f9.png#width=826" alt><br>Mask R-CNN是建构于Faster R-CNN之上，如果是透过RoIPooling取得Region proposals之后，针对每个region会再跑FCN取得遮罩分割，但是由于RoIPooling在做Max pooling时，会使用最近插值法( <a href="http://monkeycoding.com/?tag=nearest-neighbor-interpolation" target="_blank" rel="noopener">Nearest Neighbor Interpolation</a> )取得数值，所以出来的遮罩会有偏移现象，再加上pooling下来的结果，会让region的尺寸出现非整数的情况，然后取整数的结果就是没办法做到Pixel层级的遮罩。所以Mask R-CNN改采用双线性插值法( <a href="http://monkeycoding.com/?tag=nearest-neighbor-interpolation" target="_blank" rel="noopener">Bilinear Interpolation</a> )来改善RoIPooling，称之为RoIAlign，RoIAlign会让遮罩位置更准确。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205148755-2522b72b-9b05-4e9b-af6f-ef024168767e.png#width=826" alt><br>Mask RCNN 架构，将原有的RoIPooling 改成 RoIAlign。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205172687-cd927423-a678-4557-8914-e933152be762.png#width=826" alt><br>Fast R-CNN 的RoIPool。将一个7x5 的Anchor box 取2x2 的MaxPool，由于使用最近插值法，会有偏差。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205202715-768d38b1-ac5b-48f7-91fd-35ef7abb8a64.png#width=826" alt></p>
<p>RoIAlign的作法是使用双线性插值法( <a href="http://monkeycoding.com/?tag=nearest-neighbor-interpolation" target="_blank" rel="noopener">Bilinear Interpolation</a> )，减少mis-alignment的问题。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205230066-e554096e-51e2-492f-8e1d-fbd2fd312f9d.png#width=826" alt><br><a name="c62f"></a></p>
<h3 id="YOLO-You-Only-Look-Once"><a href="#YOLO-You-Only-Look-Once" class="headerlink" title="YOLO: You Only Look Once"></a><a href="#c62f"></a>YOLO: You Only Look Once</h3><p><a href="https://pjreddie.com/media/files/papers/yolo.pdf" target="_blank" rel="noopener">YOLO</a>有个很讨喜的名字，取自<a href="https://zh.wikipedia.org/wiki/YOLO" target="_blank" rel="noopener">You Only Live Once</a>，但用在Object detection上则为You only look once，意思是说YOLO模型的特性只需要对图片作一次CNN便能够判断里面的物体类别跟位置，大大提升辨识速度。</p>
<p>R-CNN 的概念是先提出几个可能包含物体的Region proposal，再针对每个region 使用CNN 作分类，最后再以regression 修正bounding box 位置，速度慢且不好训练。YOLO 的好处是单一网路设计，判断的结果会包含bounding box 位置，以及每个bounding box 所属类别及概率。整个网路设计是end-to-end 的，容易训练，而且速度快。</p>
<ol>
<li><p>YOLO 速度快，在Titan X GPU 上可以达到每秒45 祯的速度，简化版的YOLO 甚至可以达到150 fps 的速度。这意味着YOLO 已经可以对影像作即时运算了。准确度(mAP) 也狠甩其他深度学习模型好几条街。看看底下YOLO2 的demo 视频，这侦测速度会吓到吃手手了<a href="https://youtu.be/VOC3huqHrss" target="_blank" rel="noopener">https://youtu.be/VOC3huqHrss</a></p>
</li>
<li><p>有别于R-CNN 都是先提region 再做判断，看的范围比较小，容易将背景的background patch 看成物体。YOLO 在训练跟侦测时都是一次看整张图片，背景错误侦测率(background error, 抑或false positive) 都只有Fast R-CNN 的一半。</p>
</li>
<li><p>YOLO 的泛用性也比R-CNN 或者DPM 方式来得好很多，在新的domain 使用YOLO 依旧可以很稳定。<br>YOLO 的概念是将一张图片切割成S x S 个方格，每个方格以自己为中心点各自去判断B 个bounding boxes 中包含物体的confidence score 跟种类。<br>confidence score = Pr(Object) * IOU (ground truth)<br>如果该bounding box 不包含任何物体(Pr(Object) = 0)，confidence score 便为零，而IOU 则为bounding box 与ground truth 的交集面积，交集面积越大，分数越高。<br>每个方格预测的结果包含5 个数值，x 、y 、w 、 h 跟confidence，x 与y 是bounding box 的中间点，w 与h 是bounding box 的宽跟高。</p>
</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205319660-33410751-7339-4534-a37e-f2d61752ae1b.png#width=826" alt><br>S = 7，B = 2，PASCAL VOC label 20 种种类，所以tensor 为S x S x (5 * B + C) = 7 x 7 x 30<br>YOLO 的网路设计包含了24 个卷积层，跟2 层的FC 网络。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205351976-8c342184-e75a-4ac0-add0-a2e06853c86d.png#width=826" alt><br>另外一个版本的YOLO Fast 则只有9 个卷积层，不过最后的输出都是7x7x30 的tensor。</p>
<p><a name="e2e8"></a></p>
<h4 id="YOLO-的缺点"><a href="#YOLO-的缺点" class="headerlink" title="YOLO 的缺点"></a><a href="#e2e8"></a>YOLO 的缺点</h4><ol>
<li><p>由于YOLO 对于每个方格提两个bounding box 去作侦测，所以不容易去区分两个相邻且中心点又非常接近的物体</p>
</li>
<li><p>只有两种bounding box，所以遇到长宽比不常见的物体的检测率较差</p>
</li>
</ol>
<p><a name="5aaa"></a></p>
<h4 id="YOLO-与其他模型的比较"><a href="#YOLO-与其他模型的比较" class="headerlink" title="YOLO 与其他模型的比较"></a><a href="#5aaa"></a>YOLO 与其他模型的比较</h4><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205373222-774ef6c0-1da2-49fa-a9c6-1aa802765f10.png#width=826" alt><br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205389614-e1f9cac9-d060-463b-b15f-cae65400191c.png#width=826" alt><br><a name="da63"></a></p>
<h3 id="YOLO2"><a href="#YOLO2" class="headerlink" title="YOLO2"></a><a href="#da63"></a>YOLO2</h3><p><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO2</a>建构于YOLO之上，但是有更好的准确度，更快速的判断速度，能够判断更多的物件种类(多达9000种)，所以是<strong>更好(Better)、更快(Faster)、更强大(Stronger)</strong>！<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205410945-959e3ef1-9aac-408a-bde4-e16a2f47fb24.png#width=826" alt><br>YOLO2 在准确度上比YOLO 好，且追上什至超越其他模型像是Faster R-CNN 或者SSD 等，速度还是别人的2–10 倍以上。</p>
<p>YOLO2 采用了许多改善方式，例如batch normalization、anchor box 等，使用了这些改良方式让YOLO2 不管在辨识速度还是准确率上都有了提升，此外对于不同图档大小也有很好的相容性，提供了在速度与准确性上很好的平衡，所以也很适合运用在一些便宜的GPU 或者CPU 上，依旧提供水准以上的速度与准确率。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205442472-9616bcc1-7bd3-4ecf-a655-b4ec3dde4948.png#width=826" alt><br><a name="ccdb"></a></p>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a><a href="#ccdb"></a>结语</h3><p>物体辨识(Object detection)的进展飞快，为了整理这篇大概也看了七八篇论文，还有很多都还没涵盖到的，例如SSD ( <a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">Single Shot Mulitbox Detector</a> )。如果想更了解AI在Computer Vision最近几年的发展，也可以参考这篇<a href="http://www.themtank.org/a-year-in-computer-vision" target="_blank" rel="noopener">搜文</a> <a href="http://www.themtank.org/a-year-in-computer-vision" target="_blank" rel="noopener">A Year in Computer vision</a>，内容涵盖了Classification、Object detection、Object tracking、Segmentation、Style transfer、Action recognition、3D object、Human post recognition等等，看完会大致知道在Computer Vision中有哪些AI所做的努力，以及各自的进展。</p>
<p>Google的Tensorflow也有提供<a href="https://github.com/tensorflow/models/tree/master/research/object_detection" target="_blank" rel="noopener">Object detection API</a>，透过使用API ，不用理解这些模型的实作也能快速实作出速度不错涵盖率又广的object detection。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545205466794-6c46e6e8-6b5c-4375-ab82-46fb5c460706.png#width=826" alt></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/关于目标检测，所有你应该知道的深度学习模型/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/目标检测和定位算法的演变" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/目标检测和定位算法的演变/">目标检测和定位算法的演变</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/目标检测和定位算法的演变/" class="archive-article-date">
  	<time datetime="2018-12-19T06:21:01.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/evolution-of-object-detection-and-localization-algorithms-e241021d8bad" target="_blank" rel="noopener">链接</a><br>通过对基本概念的直观解释，了解对象检测和本地化的最新进展。<br>目标检测是计算机视觉领域中非常迅速成熟的领域之一。 感谢深度学习！ 每年，新的算法/模型都会比以前更好。 事实上，Facebook AI团队上周刚刚发布了最先进的物体检测软件系统之一。 该软件称为Detectron，它包含许多用于物体检测的研究项目，并由Caffe2深度学习框架提供支持。<br>今天，有大量用于目标检测的预训练模型（YOLO，RCNN，Faster RCNN，Mask RCNN，Multibox等）。 因此，只需花费少量精力即可检测视频或图像中的大多数对象。 但我的博客的目标不是谈论这些模型的实现。 相反，我试图以清晰简洁的方式解释基本概念。<br>我最近完成了3周的Andrew Ng的卷积神经网络课程，其中他谈到了目标检测算法。 此博客的大部分内容都受到该课程的启发。<br><br>编辑：我目前正在进行Fast.ai的尖端深度学习编码课程，由Jeremy Howard教授。 现在，我使用PyTorch和fast.ai库实现了下面讨论的算法。 这是代码的<a href="https://github.com/groverpr/deep-learning/tree/master/computer_vision" target="_blank" rel="noopener">链接</a>。 如果您想了解下面讨论的算法的实现部分，请查看此信息。 该实现已经从fast.ai<a href="https://github.com/fastai/fastai/tree/master/courses" target="_blank" rel="noopener">课程笔记</a>本借用，附有评论和注释。<br><a name="zs11cg"></a></p>
<h2 id="关于CNN的简介"><a href="#关于CNN的简介" class="headerlink" title="关于CNN的简介"></a><a href="#zs11cg"></a>关于CNN的简介</h2><p>在我解释目标检测算法的工作之前，我想在卷积神经网络（也称为CNN或ConvNets）上写上几笔。 CNN是深度学习时代大多数计算机视觉任务的基本构建模块。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545200900345-553c0b70-f95a-4497-aed7-dc9b3febdcde.png#width=826" alt><br><strong>我们想要什么？</strong> 我们需要一些查看图像的算法，查看图像中的图案并告知图像中的对象类型。 例如，是猫或狗的形象。<br><strong>什么是电脑的图像？</strong> 只是数字矩阵。 对于例如 见上图1。 左边的图像只是手写数字2的28 * 28像素图像（取自MNIST数据），在Excel电子表格中表示为数字矩阵。<br><strong>我们怎样才能教电脑学会识别图像中的物体？</strong> 通过让计算机学习垂直边缘，水平边缘，圆形以及许多其他人类未知的模式。<br><strong>计算机如何学习模式？</strong>卷积！<br><br>（阅读本文时请看上图）卷积是两个矩阵之间的数学运算，给出第三个矩阵。 我们称之为滤波器或内核（图1中的3x3）的较小矩阵在图像像素矩阵上操作。 根据滤波器矩阵中的数字，输出矩阵可以识别输入图像中存在的特定模式。 在上面的示例中，滤波器是垂直边缘检测器，其学习输入图像中的垂直边缘。 在深度学习的背景下，输入图像及其后续输出从许多这样的滤波器传递。 过滤器中的数字是通过神经网络学习的，模式是自己导出的。<br><strong>为什么卷积有效？</strong> 因为在大多数图像中，对象具有可以通过卷积来利用的相对像素密度（数字的大小）的一致性。<br>我知道CNN上只有几行对于不了解CNN的读者来说是不够的。 但CNN不是本博客的主题，我已经提供了基本介绍，因此读者可能不需要再打开10个链接来先了解CNN，然后再继续。<br>阅读本博客后，如果您仍想了解更多关于CNN的信息，我强烈建议您阅读Adam Geitgey撰写的这篇<a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721" target="_blank" rel="noopener">博客</a>。<br><a name="hcfpka"></a></p>
<h2 id="计算机视觉任务的分类"><a href="#计算机视觉任务的分类" class="headerlink" title="计算机视觉任务的分类"></a><a href="#hcfpka"></a>计算机视觉任务的分类</h2><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545201176058-a349b8fe-bc13-4e55-8106-c6bc54387534.png#width=826" alt><br>以图2中的猫狗图像为例，以下是计算机视觉建模算法最常见的任务：</p>
<ol>
<li><p><strong>图像分类</strong>：这是最常见的计算机视觉问题，其中算法查看图像并对其中的对象进行分类。 图像分类具有广泛的应用，从社交网络上的面部检测到医学中的癌症检测。 通常使用卷积神经网络（CNN）对这些问题进行建模。</p>
</li>
<li><p><strong>目标分类和定位</strong>：假设我们不仅想知道图像中是否有猫，而且猫的确切位置。 对象定位算法不仅标记对象的类，还在图像中的对象位置周围绘制边界框。</p>
</li>
<li><p><strong>多个目标检测和定位</strong>：如果图像中有多个物体（如上图中的3只狗和2只猫），我们想要检测它们，该怎么办？ 这将是一个对象检测和定位问题。 众所周知的应用是在自动驾驶汽车中，该算法不仅需要检测汽车，还需要检测车架中的行人，摩托车，树木和其他物体。 这些问题需要利用从图像分类和对象定位中学到的思想或概念。</p>
</li>
</ol>
<p>现在回到计算机视觉任务。 在深度学习的背景下，上述3种任务之间的基本算法差异就是选择相关的输入和输出。 让我用信息图解释这一行。<br><a name="rdrdnd"></a></p>
<h2 id="1-图像分类"><a href="#1-图像分类" class="headerlink" title="1 图像分类"></a><a href="#rdrdnd"></a>1 图像分类</h2><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545201367951-62c92f43-597b-4174-82e8-9f7640900af4.png#width=826" alt></p>
<ol>
<li><p>图2中的信息图显示了用于图像分类的典型CNN的外观。通过n滤波器（图3中n = 4）卷积一些高度，宽度和通道深度（上面的情况下为940,550,3）的输入图像[如果你仍然感到困惑究竟卷积是什么意思，请检查 这个链接来理解深度神经网络中的卷积]。</p>
</li>
<li><p>卷积的输出用非线性变换处理，通常是Max Pool和RELU。</p>
</li>
<li><p>Convolution，Max Pool和RELU的上述3个操作被执行多次。</p>
</li>
<li><p>最终层的输出被发送到Softmax层，该层转换0和1之间的数字，从而给出图像特定类的概率。 我们将损失降至最低，以便使最后一层的预测接近实际值。</p>
</li>
</ol>
<p><a name="0vv7zh"></a></p>
<h2 id="2-物体分类和定位"><a href="#2-物体分类和定位" class="headerlink" title="2.物体分类和定位"></a><a href="#0vv7zh"></a>2.物体分类和定位</h2><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545201635254-f917f28e-ef71-4efd-a175-9c89c060370f.png#width=826" alt></p>
<p>现在，为了使我们的模型绘制对象的边界框，我们只需更改前一算法的输出标签，以使我们的模型学习对象类以及对象在图像中的位置。 我们在输出层添加4个数字，包括对象的质心位置和图像中边界框的宽度和高度的比例。<br>简单吧？ 只需添加一堆输出单元即可吐出您想要识别的不同位置的x,y坐标。 对于我们拥有的所有图像中的特定对象，这些不同的位置或界标将是一致的。 对于例如对于汽车而言,高度将小于宽度，并且与图像中的其他点相比，质心将具有一些特定的像素密度。<br><br>隐含相同的逻辑，如果图像中有多个对象并且我们想要对所有这些对象进行分类和定位，您认为会发生什么变化？ 我建议你暂时停下来思考，你可能会自己得到答案。<br><a name="irp4tp"></a></p>
<h2 id="3-目标检测和定位"><a href="#3-目标检测和定位" class="headerlink" title="3.目标检测和定位"></a><a href="#irp4tp"></a>3.目标检测和定位</h2><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545201786310-58306acb-5629-4864-8fb1-fa3c62ebdca7.png#width=826" alt></p>
<p>为了检测图像中的各种对象，我们可以直接使用我们从目前为止学到的东西。 不同之处在于我们希望我们的算法能够对图像中的所有对象进行分类和定位，而不仅仅是一个。 因此，我们的想法是，只需将图像裁剪成多个图像，然后为所有裁剪的图像运行CNN以检测对象。<br>算法的工作方式如下：</p>
<ol>
<li><p>制作一个比实际图像尺寸小得多的窗口。 裁剪它并将其传递给ConvNet（CNN）并让ConvNet进行预测。</p>
</li>
<li><p>继续滑动窗口并将裁剪后的图像传递到ConvNet。</p>
</li>
<li><p>在使用此窗口大小裁剪图像的所有部分后，再次重复所有步骤以获得更大的窗口大小。 再次将裁剪后的图像传递到ConvNet并让它进行预测。</p>
</li>
<li><p>最后，您将拥有一组裁剪区域，这些区域将包含一些对象，以及对象的类和边界框</p>
</li>
</ol>
<p>该解决方案被称为具有滑动窗口的物体检测。 这是非常基本的解决方案，有以下几点需要注意：<br><strong>A.计算成本高：</strong>裁剪多个图像并通过ConvNet传递它将在计算上非常昂贵。<br><strong>解决方案</strong>：有一个简单的hack来提高滑动窗口方法的计算能力。 它是用1x1卷积层替换ConvNet中的完全连接层，对于给定的窗口大小，只传递一次输入图像。 因此，在实际实现中，我们不会一次传递一个裁剪后的图像，但我们会立即传递完整的图像。</p>
<p><strong>B.不准确的边界框</strong>：我们在整个图像上滑动方形窗口，也许对象是矩形的，或者没有一个正方形与对象的实际大小完全匹配。 虽然该算法具有查找和定位图像中多个对象的能力，但是边界框的准确性仍然很差。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545202101543-96dbf0cd-cf32-463f-bc52-ce24e9fa7c51.png#width=478" alt><br>我已经谈到了对象检测问题的最基本的解决方案。 但它有许多警告，并不是最准确的，并且实施起来计算成本很高。 那么，我们如何才能使我们的算法更好更快？<br><strong>好的解决方案？YOLO
</strong><br>事实证明，我们有YOLO（你只看一次），它比滑动窗口算法更准确，更快。 它仅基于我们已经知道的算法顶部的微小调整。 我们的想法是将图像分成多个网格。 然后我们改变数据的标签，以便我们为每个网格单元实现定位和分类算法。 让我再向您解释一下这个信息图。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545202200059-aac2dc95-09af-4e82-9b90-0ff6da1c6b8e.png#width=826" alt></p>
<p><a name="1k73ha"></a></p>
<h4 id="YOLO简单的步骤："><a href="#YOLO简单的步骤：" class="headerlink" title="YOLO简单的步骤："></a><a href="#1k73ha"></a>YOLO简单的步骤：</h4><blockquote>
<ol>
<li>将图像分成多个网格。 为了说明，我在上图中绘制了4x4网格，但YOLO的实际实现具有不同的网格数量。 （7x7用于在PASCAL VOC数据集上培训YOLO）</li>
</ol>
</blockquote>
<blockquote>
<ol>
<li>标记训练数据，如上图所示。 如果C是我们数据中唯一对象的数量，S <em> S是我们分割图像的网格数，那么我们的输出向量将是长度S </em> S <em>（C + 5）。 对于例如 在上面的例子中，我们的目标向量是4 </em> 4 <em>（3 + 5），因为我们将图像划分为4 </em> 4网格，并训练3个独特的对象：汽车，光和行人。</li>
</ol>
</blockquote>
<blockquote>
<ol>
<li>制作一个具有损失函数的深度卷积神经网络作为输出激活和标签矢量之间的误差。 基本上，该模型通过ConvNet仅在输入图像的一个前向通道中预测所有网格的输出。</li>
</ol>
</blockquote>
<blockquote>
<ol>
<li>请记住，对象存在于网格单元格（P.Object）中的标签由该网格中对象的质心的存在决定。 重要的是不允许在不同的网格中多次对一个对象进行计数。</li>
</ol>
</blockquote>
<p><strong>YOLO的注意事项及其解决方案：</strong></p>
<ul>
<li>A.无法检测同一网格中的多个对象。</li>
</ul>
<p> 通过选择较小的网格大小可以解决此问题。 但即使选择较小的网格大小，在对象彼此非常接近的情况下，算法仍然会失败，如鸟群的图像。<br>解决方案：<strong>Anchor boxes</strong>。 除了每个网格单元具有5 + C标签（其中C是不同对象的数量）之外，<strong>Anchor boxes</strong>的想法是每个网格单元具有（5 + C）* A标签，其中A是必需的<strong>Anchor boxes</strong>。 如果将一个对象分配给一个网格中的一个<strong>Anchor boxes</strong>，则可以将另一个对象分配给同一网格的另一个<strong>Anchor boxes</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545202412058-e7d724af-065d-48e1-b4cb-f0b6183a5eac.png#width=826" alt></p>
<ul>
<li>B.可多次检测一个物体的可能性。</li>
</ul>
<p>解决方案：非最大抑制。 非最大抑制消除了非常接近高概率边界框的低概率边界框。<br><a name="csrntv"></a></p>
<h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a><a href="#csrntv"></a>结论：</h2><p>截至今天，有多种版本的预训练YOLO模型可用于不同的深度学习框架，包括Tensorflow。 最新的YOLO论文是：“YOLO9000：更好，更快，更强”。 该模型接受了9000个课程的培训。 还有一些基于选择性区域提案的区域CNN（R-CNN）算法，我没有讨论过。 由Facebook AI开发的Detectron软件系统也实现了R-CNN，Masked R-CNN的变体。<br><a name="4c1f"></a></p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a><a href="#4c1f"></a>参考文献:</h4><ol>
<li><p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong><br><a href="https://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.02640.pdf</a></p>
</li>
<li><p><strong>YOLO9000: Better, Faster, Stronger</strong><br><a href="https://arxiv.org/pdf/1612.08242.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1612.08242.pdf</a></p>
</li>
<li><p><strong>Convolutional Neural Networks by Andrew Ng (deeplearning.ai)</strong><br><a href="https://www.coursera.org/learn/convolutional-neural-networks" target="_blank" rel="noopener">https://www.coursera.org/learn/convolutional-neural-networks</a></p>
</li>
</ol>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/目标检测和定位算法的演变/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/评论：U-Net（生物医学图像分割）" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/评论：U-Net（生物医学图像分割）/">评论：U-Net（生物医学图像分割）</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/评论：U-Net（生物医学图像分割）/" class="archive-article-date">
  	<time datetime="2018-12-19T05:38:12.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/review-u-net-biomedical-image-segmentation-d02bf06ca760" target="_blank" rel="noopener">链接</a><br>在这个U-Net评论中。 U-Net是生物医学图像分割领域着名的全卷积网络（FCN）之一，它在2015年MICCAI上发表，在我写这篇故事时引用了3000多篇。 （SH Tsang @ Medium）<br>在生物医学图像标注领域，我们总是需要获得相关知识的专家来标注每个图像。 而且他们也会花费大量时间来标注。 如果标注过程变为自动，则可以实现较少的人力和较低的成本。 或者它可以作为减少人为错误的辅助角色。</p>
<blockquote>
<p>您可能会问：“阅读有关生物医学图像分割的内容是否过于狭窄？”<br>但是，我们可能会学习它的技术，并将其应用于不同的行业。 比如说，在施工/制造/制造过程中的质量控制/自动检查/自动机器人，或者我们可能想到的任何其他东西。 这些活动涉及定量诊断。 如果我们可以自动化，则可以以更高的精度节省成本。</p>
</blockquote>
<p>在本文中，他们分割/标注电子显微镜（EM）图像。 他们还对网络进行了一些修改，以便在2015 ISBI中一下子对X射线图像进行分段/标注。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545198583802-f9cc7158-6135-46a5-b544-1978e1871a3f.png#align=left&amp;display=inline&amp;height=354&amp;originHeight=256&amp;originWidth=512&amp;status=done&amp;width=708" alt><br><a name="6f31bc1f"></a></p>
<h2 id="什么是涵盖的"><a href="#什么是涵盖的" class="headerlink" title="什么是涵盖的"></a><a href="#w9n2hv"></a>什么是涵盖的</h2><ol>
<li>A. EM图像分割</li>
<li>U-Net网络架构</li>
<li>重叠平铺策略</li>
<li>数据增强的弹性变形</li>
<li>触摸物体的分离</li>
<li>结果<br><a name="583d02e2"></a><h2 id="B-牙科X射线图像分割"><a href="#B-牙科X射线图像分割" class="headerlink" title="B.牙科X射线图像分割"></a><a href="#vs2glw"></a>B.牙科X射线图像分割</h2></li>
<li>U-Net的一些修改</li>
<li>结果<br><a name="1f5abe88"></a><h2 id="A-1-U-net网络架构"><a href="#A-1-U-net网络架构" class="headerlink" title="A.1 U-net网络架构"></a><a href="#iuwfgw"></a>A.1 U-net网络架构</h2><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199231926-18020858-3aa4-47c6-b68c-3b9f477175f6.png#align=left&amp;display=inline&amp;height=574&amp;originHeight=627&amp;originWidth=902&amp;status=done&amp;width=826" alt><br>U-net架构如上所示。 它由收缩路径和扩展路径组成。<br><a name="464297ce"></a><h4 id="收缩路径"><a href="#收缩路径" class="headerlink" title="收缩路径"></a><a href="#8nvimi"></a>收缩路径</h4>连续两次3×3转换和2×2最大合并完成。 这有助于提取更多高级功能，但也会减少功能图的大小。<br><a name="e0ad13ea"></a><h4 id="扩张路径"><a href="#扩张路径" class="headerlink" title="扩张路径"></a><a href="#9scaye"></a>扩张路径</h4></li>
<li>连续执行2×2 Up-conv和2×3×3 Conv以恢复分割图的大小。 但是，上述过程虽然增加了“什么”，但减少了“哪里”。 这意味着，我们可以获得高级功能，但我们也会丢失本地化信息。</li>
<li>因此，在每个up-conv之后，我们还具有相同级别的特征映射（灰色箭头）的串联。 这有助于将收缩路径的本地化信息提供给扩展路径。</li>
<li>最后，1×1转换将特征映射大小从64映射到2，因为输出特征映射只有2个类，单元格和膜。<br><a name="b359c062"></a><h2 id="A-2-重叠平铺策略"><a href="#A-2-重叠平铺策略" class="headerlink" title="A.2 重叠平铺策略"></a><a href="#uqa0mk"></a>A.2 重叠平铺策略</h2><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199376322-d00ca454-7b16-4c02-bb99-ebef49b086d1.png#align=left&amp;display=inline&amp;height=267&amp;originHeight=267&amp;originWidth=557&amp;status=done&amp;width=557" alt><br>由于使用了无填充卷积，因此输出大小小于输入大小。 不是在网络之前缩小尺寸而是在网络之后进行上采样，而是使用重叠切片策略。 由此，如上图所示，逐个部分地预测整个图像。 使用蓝色区域预测图像中的黄色区域。 在图像边界处，通过镜像外推图像。<br><a name="ff8a9392"></a><h2 id="A-3数据增强的弹性变形"><a href="#A-3数据增强的弹性变形" class="headerlink" title="A.3数据增强的弹性变形"></a><a href="#t1qdkv"></a>A.3数据增强的弹性变形</h2><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199438382-5e3f4be0-d382-4924-a7d8-19a220a66152.png#align=left&amp;display=inline&amp;height=473&amp;originHeight=473&amp;originWidth=488&amp;status=done&amp;width=488" alt><br>由于训练集只能由专家标注，因此训练集很小。 为了增加训练集的大小，通过随机变形输入图像和输出分割图来完成数据增加。<br><a name="ad98132d"></a><h2 id="A-4接触目标的分离"><a href="#A-4接触目标的分离" class="headerlink" title="A.4接触目标的分离"></a><a href="#6xmasa"></a>A.4接触目标的分离</h2><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199528214-e934fe93-dcae-42bf-81db-1289452fbe16.png#align=left&amp;display=inline&amp;height=278&amp;originHeight=278&amp;originWidth=503&amp;status=done&amp;width=503" alt><br>由于触摸物体彼此紧密放置，它们很容易被网络合并，将它们分开，重量图被应用于网络的输出。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199557533-ba5e366c-233e-468f-89a7-ca7cbe75af22.png#align=left&amp;display=inline&amp;height=78&amp;originHeight=77&amp;originWidth=439&amp;status=done&amp;width=444" alt><br>为了如上计算权重图，d1(x)是到位置x处最近的单元边界的距离，d2(x)是到第二个最近的单元边界的距离。 因此，在边界处，重量如图中高得多。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199618197-57bfbffa-b257-4989-a971-882147af45b5.png#align=left&amp;display=inline&amp;height=118&amp;originHeight=118&amp;originWidth=423&amp;status=done&amp;width=423" alt><br>因此，交叉熵函数在权重图处在每个位置处罚。 它有助于迫使网络学习触摸细胞之间的小分离边界。<br><a name="d5f7fde3"></a><h3 id="A-5-结果"><a href="#A-5-结果" class="headerlink" title="A.5. 结果"></a><a href="#7761"></a>A.5. 结果</h3><a name="3e377a66"></a><h4 id="A-5-1-ISBI-2012-Challenge"><a href="#A-5-1-ISBI-2012-Challenge" class="headerlink" title="A.5.1. ISBI 2012 Challenge"></a><a href="#b2c8"></a>A.5.1. ISBI 2012 Challenge</h4><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199702716-70057810-8bc6-46ca-8dc2-70a1e6e63c40.png#align=left&amp;display=inline&amp;height=267&amp;originHeight=267&amp;originWidth=774&amp;status=done&amp;width=774" alt><br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199710221-c1e90900-ada5-4943-966f-35894c3de37a.png#align=left&amp;display=inline&amp;height=222&amp;originHeight=222&amp;originWidth=567&amp;status=done&amp;width=567" alt></li>
<li>变形误差：一种惩罚拓扑分歧的分段指标。</li>
<li>Rand Error：两个聚类或分段之间相似性的度量。</li>
<li>像素错误：标准像素错误。</li>
<li>训练时间：10小时</li>
<li>测试速度：每张图像约1秒<br><a name="52ed776c"></a><h4 id="A-5-2-PhC-U373-and-DIC-HeLa-数据集"><a href="#A-5-2-PhC-U373-and-DIC-HeLa-数据集" class="headerlink" title="A.5.2. PhC-U373 and DIC-HeLa 数据集"></a><a href="#89a2"></a><strong>A.5.2. PhC-U373 and DIC-HeLa 数据集</strong></h4><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199768149-5b434356-9e41-4638-a066-09b9d8a5df2e.png#align=left&amp;display=inline&amp;height=317&amp;originHeight=340&amp;originWidth=886&amp;status=done&amp;width=826" alt><br><a name="530d6eee"></a><h3 id="B-1-U-Net的一些修改"><a href="#B-1-U-Net的一些修改" class="headerlink" title="B.1. U-Net的一些修改"></a><a href="#7dbc"></a>B.1. U-Net的一些修改</h3><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199805742-7dc888f5-e4f3-4d3f-83db-dbec0df55e50.png#align=left&amp;display=inline&amp;height=193&amp;originHeight=234&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199816881-16840727-0a97-47a5-9e45-4a30f0e54fa7.png#align=left&amp;display=inline&amp;height=535&amp;originHeight=535&amp;originWidth=770&amp;status=done&amp;width=770" alt><br>这次，使用4×4 Up-conv，并使用1×1 Conv将特征映射从64映射到7，因为每个位置的输出有7个类。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199843951-b3dd1726-e02f-46fb-9016-0951ea0be26e.png#align=left&amp;display=inline&amp;height=276&amp;originHeight=276&amp;originWidth=728&amp;status=done&amp;width=728" alt><br>在重叠平铺策略中，使用零填充而不是在图像边界处镜像。 因为镜像对牙齿没有任何意义。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199870989-cf53104b-0645-4518-9319-f0726d67e413.png#align=left&amp;display=inline&amp;height=371&amp;originHeight=371&amp;originWidth=733&amp;status=done&amp;width=733" alt><br>使用softmax损失的低分辨率特征图还有额外的损耗层，以指导深层直接学习分段类。<br><a name="7785671a"></a><h3 id="B-2-结果"><a href="#B-2-结果" class="headerlink" title="B.2. 结果"></a><a href="#d538"></a>B.2. 结果</h3><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545199907301-15f83213-8564-4f2b-964b-2eb02f92eafe.png#align=left&amp;display=inline&amp;height=561&amp;originHeight=561&amp;originWidth=633&amp;status=done&amp;width=633" alt><br>I have also reviewed <a href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" target="_blank" rel="noopener">CUMedVision1</a> and <a href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" target="_blank" rel="noopener">CUMedVision2</a>. Please feel free to visit if interested.<br><a name="References"></a><h3 id="References"><a href="#References" class="headerlink" title="References"></a><a href="#76be"></a>References</h3></li>
</ol>
<ul>
<li><p>[2015] [MICCAI]<br><a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="noopener">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></p>
</li>
<li><p>[2015] [ISBI]<br><a href="http://www-o.ntust.edu.tw/~cweiwang/ISBI2015/challenge2/isbi2015_Ronneberger.pdf" target="_blank" rel="noopener">Dental X-ray Image Segmentation using a U-shaped Deep Convolutional Network</a></p>
</li>
</ul>
<p><a name="3416b5da"></a></p>
<h3 id="My-Related-Reviews"><a href="#My-Related-Reviews" class="headerlink" title="My Related Reviews"></a><a href="#2785"></a>My Related Reviews</h3><p>[<a href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" target="_blank" rel="noopener">CUMedVision1</a>] [<a href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" target="_blank" rel="noopener">CUMedVision2</a>] [<a href="https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1" target="_blank" rel="noopener">FCN</a>] [<a href="https://towardsdatascience.com/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e" target="_blank" rel="noopener">DeconvNet</a>]</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/评论：U-Net（生物医学图像分割）/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/去除正则化会避免模型过拟合吗？" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/去除正则化会避免模型过拟合吗？/">去除正则化会避免模型过拟合吗？</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/去除正则化会避免模型过拟合吗？/" class="archive-article-date">
  	<time datetime="2018-12-19T04:28:16.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://medium.com/@diazagasatya/will-dropout-regularization-prevents-your-model-to-overfit-11afa10cd4e0" target="_blank" rel="noopener">medium</a><br><em>有人可能会争辩说，最好是过拟合你的模型，然后对其进行逆向工程而不是相反。</em><br>在这个项目中，我们可以看到将Dropout正则化实现到神经网络后的准确性和验证损失的差异。 我们将使用PyTorch库从头开始构建一个顺序神经网络，以便在fashion-MNIST数据集中对10个不同的类进行分类。 这个数据集是28x28灰度图像的衣服。 我们将深入研究dropout的方法，并证明它是否能防止过度拟合。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545194059986-5d2850f6-9304-4568-b09c-e84e6bf6c37e.png#width=699" alt><br>该项目的灵感来自：</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Facebook Udacity PyTorch Challenge.</span><br></pre></td></tr></table></figure>
</blockquote>
<p>首先，我们将创建一个没有正则化实现的神经网络，我们的假设是我们可以推断，随着时间的推移，我们的模型在验证集中表现不佳，因为我们用训练集训练我们的模型越多， 通过对测试数据的特定特征进行分类则越好，从而创建不良的泛化模型去推理。<br><a name="dhgofx"></a></p>
<h4 id="让我们导入Fashion-MNIST数据集"><a href="#让我们导入Fashion-MNIST数据集" class="headerlink" title="让我们导入Fashion-MNIST数据集"></a><a href="#dhgofx"></a>让我们导入Fashion-MNIST数据集</h4><p>让我们使用torchvision下载数据集，通常我们将20％的数据集分开用于验证集。 但在这种情况下，我们将直接从torchvision下载数据集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> helper</span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), </span><br><span class="line">                                transforms.Normalize((<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>),</span><br><span class="line">                                (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>))])</span><br><span class="line">traindataset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>,train=<span class="literal">True</span>,transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(dataset=traindataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">testdataset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>,train=<span class="literal">False</span>,transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(dataset=testdataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>我们需要导入torchvision来下载数据集和转换。 然后我们使用变换库将图像转换为张量并进行标准化。 通常批量训练和验证集以提高训练速度并且改组数据也会增加训练和测试数据的学习差异。<br>定义神经网络<br><br>这个模型将有2个隐藏层，输入层将有784个单元，并且在最终层将有10个输出，因为我们有10个不同的类进行分类。 我们将使用交叉熵损失，因为它具有对数性质，可以将我们的输出归一化到接近零或一。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from torch import nn</span><br><span class="line">from torch.functional import F</span><br><span class="line">class FashionNeuralNetwork(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        # Create layers here</span><br><span class="line">        self.layer_input = nn.Linear(784,256)</span><br><span class="line">        self.layer_hidden_one = nn.Linear(256,128)</span><br><span class="line">        self.layer_hidden_two = nn.Linear(128,64)</span><br><span class="line">        self.layer_output = nn.Linear(64,10)</span><br><span class="line">    </span><br><span class="line">   def forward(self, x):</span><br><span class="line">        # Flattened the input to make sure it fits the layer input</span><br><span class="line">        x = x.view(x.shape[0],-1)</span><br><span class="line">        # Pass in the input to the layer and do forward propagation</span><br><span class="line">        x = F.relu(self.layer_input(x))</span><br><span class="line">        x = F.relu(self.layer_hidden_one(x))</span><br><span class="line">        x = F.relu(self.layer_hidden_two(x))</span><br><span class="line">        # Dimension = 1</span><br><span class="line">        x = F.log_softmax(self.layer_output(x),dim=1)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure></p>
<p>该神经网络将使用ReLU作为隐藏层的非线性激活函数，并使用log-softmax激活输出和负对数似然函数用于我们的损失函数。 如果我们查看PyTorch库中的<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss" target="_blank" rel="noopener">交叉熵损失</a>的文档，该标准将nn.LogSoftmax()和nn.NLLLoss()组合在一个单独的类中。 损失可以描述为：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545194731399-7541a6eb-2940-4587-9157-62c90ab37010.png#width=611" alt></p>
<p>请注意，转发传播结束时的线性函数的dim = 1，这意味着输出结果的每一行的概率总和必须等于1.给单个元素的概率最高图像的概率最高 被归类为相应的类索引。<br>我们必须确保模型的输出形状正确性，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetwork()</span><br><span class="line"># Get the images and labels from the test loader</span><br><span class="line">images, labels = next(iter(testloader))</span><br><span class="line"># Get the log probability prediction from our model</span><br><span class="line">log_ps = model(images)</span><br><span class="line"># Normalize the probability by taking the exponent of the log-prob</span><br><span class="line">ps = torch.exp(log_ps)</span><br><span class="line"># Print out the size</span><br><span class="line">print(ps.shape)</span><br></pre></td></tr></table></figure></p>
<p>确保输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([64, 10])</span><br></pre></td></tr></table></figure></p>
<p><a name="o3h0uo"></a></p>
<h4 id="测量我们模型的准确性"><a href="#测量我们模型的准确性" class="headerlink" title="测量我们模型的准确性"></a><a href="#o3h0uo"></a>测量我们模型的准确性</h4><p>由于我们想要一个类的最高概率，我们将使用ps.topk来获得top-k值和top-k索引的元组，例如，如果在4个元素中最高为kth，我们将得到3作为指数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top_p, top_class = ps.topk(1,dim=1)</span><br><span class="line"># Print out the most likely classes for the first 10 examples</span><br><span class="line">print(top_class[:10,:])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195322539-23690b05-a8bf-47b0-92ab-a35a3245d1a2.png#width=122" alt><br>top_class是尺寸为64x1的2D张量，而我们的标签是尺寸为64的1D张量。为了测量标签和模型预测之间的准确度，我们必须确保张量的形状是相同的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># We have to reshape the labels to 64x1 using the view() method</span><br><span class="line">equals = top_class == labels.view(*top_class.shape)</span><br><span class="line">print(equals.shape)</span><br></pre></td></tr></table></figure></p>
<p>比较张量的输出将是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([64, 1])</span><br></pre></td></tr></table></figure></p>
<p>为了计算模型的准确性，我们只需计算模型正确预测的次数。 如果我们的预测与标签相同，则上面的==运算符将逐行检查。 最终结果将是二进制0不相同，1正确预测。 我们可以使用torch.mean计算平均值，但我们需要将equals转换为FloatTensor。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">accuracy = torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line"># Print the accuracy</span><br><span class="line">print(f&apos;Accuracy: &#123;accuracy.item()*100&#125;%&apos;)</span><br></pre></td></tr></table></figure></p>
<p><a name="go1ssu"></a></p>
<h4 id="训练我们的模型"><a href="#训练我们的模型" class="headerlink" title="训练我们的模型"></a><a href="#go1ssu"></a>训练我们的模型</h4><p>由于我们希望损失函数与Logarithm Softmax函数的行为相反，我们将使用负对数似然来计算我们的损失。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">from torch import optim</span><br><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetwork()</span><br><span class="line"># Use Negative Log Likelyhood as our loss function</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line"># Use ADAM optimizer to utilize momentum</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.003)</span><br><span class="line"># Train the model 30 cycles</span><br><span class="line">epochs = 30</span><br><span class="line"># Initialize two empty arrays to hold the train and test losses</span><br><span class="line">train_losses, test_losses = [],[]</span><br><span class="line"># Start the training</span><br><span class="line">for i in range(epochs):</span><br><span class="line">    running_loss = 0</span><br><span class="line">    # Loop through all of the train set forward and back propagate</span><br><span class="line">    for images,labels in trainloader:</span><br><span class="line">        optimizer.zero_grad()                      </span><br><span class="line">        log_ps = model(images)                     </span><br><span class="line">        loss = loss_function(log_ps, labels)       </span><br><span class="line">        loss.backward()                            # Backpropagate</span><br><span class="line">        optimizer.step()                           </span><br><span class="line">        running_loss += loss.item()                </span><br><span class="line">    </span><br><span class="line">    # Initialize test loss and accuracy to be 0 </span><br><span class="line">    test_loss = 0</span><br><span class="line">    accuracy = 0</span><br><span class="line">    </span><br><span class="line">    # Turn off the gradients</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        # Loop through all of the validation set</span><br><span class="line">        for images, labels in testloader:</span><br><span class="line">            log_ps = model(images)                                 </span><br><span class="line">            ps = torch.exp(log_ps)                                 </span><br><span class="line">            test_loss += loss_function(log_ps, labels)             </span><br><span class="line">            top_p, top_class = ps.topk(1,dim=1)                    </span><br><span class="line">            equals = top_class == labels.view(*top_class.shape)   </span><br><span class="line">            accuracy += torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line">    </span><br><span class="line">    # Append the average losses to the array for plotting       </span><br><span class="line">    train_losses.append(running_loss/len(trainloader))</span><br><span class="line">    test_losses.append(test_loss/len(testloader))</span><br></pre></td></tr></table></figure></p>
<p>打印我们的模型<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195544515-f2c011c6-a9ad-4673-a266-508907165f04.png#width=684" alt><br>这证明了我们的假设，即完全说明我们的模型将训练的很好，但不能推广训练数据集之外的图像。 我们可以看到，30个周期的训练损失显著减少，但我们的验证损失在大约36-48％之间波动。 这是过度拟合的标志，这个情况说明，模型学习训练数据集的特定特征和模式，它无法正确分类数据集之外的图像。 这通常很糟糕，因为这意味着如果我们使用推理，模型就无法正确分类。<br><a name="r5sdzs"></a></p>
<h4 id="为了清楚的说明"><a href="#为了清楚的说明" class="headerlink" title="为了清楚的说明"></a><a href="#r5sdzs"></a>为了清楚的说明</h4><p>让我们画图看一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Plot the graph here</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = &apos;retina&apos;</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(train_losses, label=&apos;Training Loss&apos;)</span><br><span class="line">plt.plot(test_losses, label=&apos;Validation Loss&apos;)</span><br><span class="line">plt.legend(frameon=True)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195769635-b5ee1591-723d-4cb7-a10b-2b0a8740d404.png#width=554" alt><br><a name="4gv0rl"></a></p>
<h4 id="过度拟合"><a href="#过度拟合" class="headerlink" title="过度拟合"></a><a href="#4gv0rl"></a>过度拟合</h4><p>从上图中我们可以清楚地看到，我们的模型并没有很好地泛华。 这意味着该模型在对训练数据集之外的图像进行分类方面做得不好。 这真的很糟糕，这意味着我们的模型只学习我们的训练数据集的具体内容，它变得如此个别，以至于它只能识别来自训练集的图像。 如果我们从图表中看到，每个周期的训练损失都会显著减少，但是，我们可以看到验证损失却没发生什么变化。<br><a name="mm70mi"></a></p>
<h4 id="正则"><a href="#正则" class="headerlink" title="正则"></a><a href="#mm70mi"></a>正则</h4><p>这就是正则化的用武之地，其中一种方法是进行L2正则化，也称为<em>early-stopping</em>，这基本上意味着我们将在验证损失最低时停止训练我们的模型。 在这种情况下，我们的验证损失在3-5个时期后达到最佳。 这意味着超过5个周期，我们的模型泛化会变得更糟。<br><br>但是，还有另一种方法可以解决这个问题。 我们可以为我们的模型进行<em>dropout</em>，以进行更多的泛化。 基本上，我们的模型通过在大型重量上滚雪球并使其他要训练的重量不足而贪婪地行动。 通过具有随机丢失，具有较小权重的节点将有机会在循环期间被训练，从而在结束时给出更一般化的分数。 换句话说，它迫使网络在权重之间共享信息，从而提供更好的泛化能力。<br>注意：<br><br>在训练期间，我们希望实行dropout，但是，在验证过程中，我们需要我们模型的全部功能，因为那时我们可以完全测量模型对这些图像进行泛化其准确性。 如果我们使用model.eval()模式，我们将停止使用dropout，并且不要忘记在训练期间使用model.train()再次使用它。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">### Define our new Network with Dropouts</span><br><span class="line">class FashionNeuralNetworkDropout(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        # Create layers here</span><br><span class="line">        self.layer_input = nn.Linear(784,256)</span><br><span class="line">        self.layer_hidden_one = nn.Linear(256,128)</span><br><span class="line">        self.layer_hidden_two = nn.Linear(128,64)</span><br><span class="line">        self.layer_output = nn.Linear(64,10)</span><br><span class="line">        </span><br><span class="line">        # 20% Dropout here</span><br><span class="line">        self.dropout = nn.Dropout(p=0.2)</span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # Flattened the input to make sure it fits the layer input</span><br><span class="line">        x = x.view(x.shape[0],-1)</span><br><span class="line">        # Pass in the input to the layer and do forward propagation</span><br><span class="line">        x = self.dropout(F.relu(self.layer_input(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.layer_hidden_one(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.layer_hidden_two(x)))</span><br><span class="line">        # Dimension = 1</span><br><span class="line">        x = F.log_softmax(self.layer_output(x),dim=1)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure></p>
<p>这个神经网络将与第一个模型非常相似，但是，我们将增加20％的丢失。 现在让我们训练这个模型吧！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from torch import optim</span><br><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetworkDropout()</span><br><span class="line"># Use Negative Log Likelyhood as our loss function</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line"># Use ADAM optimizer to utilize momentum</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.003)</span><br><span class="line"># Train the model 30 cycles</span><br><span class="line">epochs = 30</span><br><span class="line"># Initialize two empty arrays to hold the train and test losses</span><br><span class="line">train_losses, test_losses = [],[]</span><br><span class="line"># Start the training</span><br><span class="line">for i in range(epochs):</span><br><span class="line">    running_loss = 0</span><br><span class="line"># Loop through all of the train set forward and back propagate</span><br><span class="line">    for images,labels in trainloader:</span><br><span class="line">        optimizer.zero_grad()                      </span><br><span class="line">        log_ps = model(images)                     </span><br><span class="line">        loss = loss_function(log_ps, labels)       </span><br><span class="line">        loss.backward()                            # Backpropagate</span><br><span class="line">        optimizer.step()                           </span><br><span class="line">        running_loss += loss.item()                </span><br><span class="line">    </span><br><span class="line">    # Initialize test loss and accuracy to be 0 </span><br><span class="line">    test_loss = 0</span><br><span class="line">    accuracy = 0</span><br><span class="line">    </span><br><span class="line">    # Turn off the gradients</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        # Turn on Evaluation mode</span><br><span class="line">        model.eval()</span><br><span class="line">        # Loop through all of the validation set</span><br><span class="line">        for images, labels in testloader:</span><br><span class="line">            log_ps = model(images)                                 </span><br><span class="line">            ps = torch.exp(log_ps)                                 </span><br><span class="line">            test_loss += loss_function(log_ps, labels)             </span><br><span class="line">            top_p, top_class = ps.topk(1,dim=1)                    </span><br><span class="line">            equals = top_class == labels.view(*top_class.shape)   </span><br><span class="line">            accuracy += torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line"></span><br><span class="line">    # Turn on Training mode again</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    # Append the average losses to the array for plotting       </span><br><span class="line">    train_losses.append(running_loss/len(trainloader))</span><br><span class="line">    test_losses.append(test_loss/len(testloader))</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196342869-4eae3b68-560b-4427-8e2f-34dec5ae5da0.png#width=687" alt><br>这里的目标是使验证损失与我们的训练损失一样低，这意味着我们的模型相当准确。 让我们再次绘制图表，看看正则化后的差异。 即使精度水平仅整体上升0.3％，该模型也没有过度拟合，因为它保持了在训练期间训练的所有节点的平衡。 让我们绘制图表并查看差异：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Plot the graph here</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = &apos;retina&apos;</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(train_losses, label=&apos;Training Loss&apos;)</span><br><span class="line">plt.plot(test_losses, label=&apos;Validation Loss&apos;)</span><br><span class="line">plt.legend(frameon=True)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196385024-ee9585c8-819c-4da5-aaa1-10592b806d57.png#width=555" alt><br><a name="hsnqvc"></a></p>
<h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a><a href="#hsnqvc"></a>推理</h4><p>现在我们的模型可以更好地泛化，让我们用提供模型尝试用训练数据集之外的图像进行预测，并可视化模型的分类。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Make sure to make our model in the evaluation mode</span><br><span class="line">model.eval()</span><br><span class="line"># Get the next image and label</span><br><span class="line">images, labels = next(iter(testloader))</span><br><span class="line">img = images[0]</span><br><span class="line"># Convert 2D image to 1D vector</span><br><span class="line">img = img.view(1, 784)</span><br><span class="line"># Calculate the class probabilities (log-softmax) for img</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    output = model.forward(img)</span><br><span class="line"># Normalize the output</span><br><span class="line">ps = torch.exp(output)</span><br><span class="line"># Plot the image and probabilities</span><br><span class="line">helper.view_classify(img.view(1, 28, 28), ps, version=&apos;Fashion&apos;)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196482739-f2d874ee-fbb1-4c28-915c-d2c72a8db458.png#width=624" alt><br><a name="67g8gr"></a></p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a><a href="#67g8gr"></a>结论</h4><p>这很棒！ 我们可以看到培训损失和验证损失之间的显着平衡。 可以肯定地说，如果我们训练模型进行更多循环并微调我们的超参数，则验证损失将减少。 从上图中我们可以看出，我们的模型随着时间的推移更好地泛化，模型在6-8个时期之后可以获得更好的精度，并且可以肯定地说模型通过实现模型的丢失来防止过度拟合。<br><a name="bc98"></a></p>
<h3 id="Thank-you-so-much-for-your-time-and-please-check-out-this-repository-for-the-full-code"><a href="#Thank-you-so-much-for-your-time-and-please-check-out-this-repository-for-the-full-code" class="headerlink" title="Thank you so much for your time, and please check out this repository for the full code!"></a><a href="#bc98"></a>Thank you so much for your time, and please check out this <a href="https://github.com/diazagasatya/deep_learning_fastai/blob/master/main/Fashion%20MNIST%20-%20Classification%20Problem.ipynb" target="_blank" rel="noopener">repository</a> for the full code!</h3><p>This is my <a href="https://www.diazidabagus.com/" target="_blank" rel="noopener">Portfolio</a> and <a href="https://www.linkedin.com/in/diaz-agasatya-16487b109/" target="_blank" rel="noopener">Linked-In</a> profile :)</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/去除正则化会避免模型过拟合吗？/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类/">迁移学习：使用Fast.AI库对4种北极犬进行分类</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类/" class="archive-article-date">
  	<time datetime="2018-12-19T02:16:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://medium.com/@diazagasatya/transfer-learning-classification-of-4-different-types-of-arctic-dog-using-fast-ai-library-665cb424af5e" target="_blank" rel="noopener">链接</a></p>
<p>该项目的灵感来自Adrian Rosebrock，Francisco Ingham和Jeremy Howard。</p>
<p>在本课程中，我们将从Google Images创建自己的数据集。</p>
<p>我将使用FastAI库中的Resnet34的架构。</p>
<p>在这个特别的项目中，我们将从谷歌下载四种不同类型的北极狗（阿拉斯加雪橇犬，西伯利亚雪橇犬，萨摩耶犬和秋田犬）图像，并建立可以通过这些图像进行分类的最先进模型。 在这个项目中，我们将逐步从Google中为每个品种下载200多张图片。</p>
<p>有很多方法可以为我们的训练数据集找到最有效的谷歌图像，但是，在这个项目中，我们只需打开谷歌图像并记录我们需要的特定品种。</p>
<p>我们需要滚动到页面末尾，然后单击到最底部“显示更多结果”。 （700张图片是Google图片可以显示的最大数量）</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545186372059-c21d0df4-c271-46e8-a15d-5b0ba9d580ef.png#width=826" alt></p>
<p>使用浏览器中的Javascript代码将URL下载到文本文件中。 对于Mac用户，按Cmd Opt J，在Windows / Linux中按Ctrl Shift J打开javascript控制台并运行以下命令：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">urls = <span class="built_in">Array</span>.from(<span class="built_in">document</span>.querySelectorAll(<span class="string">'.rg_di .rg_meta'</span>)).map(<span class="function"><span class="params">el</span>=&gt;</span><span class="built_in">JSON</span>.parse(el.textContent).ou);</span><br><span class="line"><span class="built_in">window</span>.open(<span class="string">'data:text/csv;charset=utf-8,'</span> + <span class="built_in">escape</span>(urls.join(<span class="string">'\n'</span>)));</span><br></pre></td></tr></table></figure></p>
<p>将下载的文件命名为’dogbreed’.txt文件（确保此时暂停广告块），在这种情况下，我们将有4种不同的犬种：阿拉斯加雪橇犬，萨摩耶犬，西伯利亚雪橇犬和秋田犬。<br><a name="uh6vno"></a></p>
<h4 id="使用FastAI库下载图像"><a href="#使用FastAI库下载图像" class="headerlink" title="使用FastAI库下载图像"></a><a href="#uh6vno"></a>使用FastAI库下载图像</h4><p>Fast.AI有一个非常方便的功能，它将通过我们之前在文本文件中提供的URL为我们下载图像。 请注意，我们可以更改要下载的最大图片数量，我们只需要指定文本文件的路径和目标，然后函数将处理其余部分。<br><em>注意：由于某些图像无法从URL打开，因此在训练步骤中可能会产生冲突。 加载的错误图像将被忽略并移至下一个URL。</em><br>folder = ‘alaskan_malamute’<br>file = ‘urls_alaskan_malamute.txt’<br>path = Path(‘data/arctic_dogs’)<br>destination = path/folder<br>destination.mkdir(parents=True, exist_ok=True)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">folder = <span class="string">'alaskan_malamute'</span></span><br><span class="line">file = <span class="string">'urls_alaskan_malamute.txt'</span></span><br><span class="line">path = Path(<span class="string">'data/arctic_dogs'</span>)</span><br><span class="line">destination = path/folder</span><br><span class="line">destination.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># download_images(path/file, destination, max_pics=300)download_images(path/file, destination, max_pics=300, max_workers=0)</span></span><br></pre></td></tr></table></figure>
<p>因为我们想训练模型的所有不同类型的犬种，因此需要做4次下载。 在这种情况下，请将文件夹名称更改为其他四种不同的狗品种，并确保文件名与先前使用javascript命令下载的文本文件的名称相匹配。<br>然后我们通过如下方式删除无法通过链接打开的图像：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classes = [<span class="string">'alaskan_malamute'</span>, <span class="string">'samoyed'</span>, <span class="string">'siberian_husky'</span>, <span class="string">'akita'</span>]</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> classes:</span><br><span class="line">    print(c)</span><br><span class="line">    verify_images(path/c, delete=<span class="literal">True</span>, max_workers=<span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>
<p><a name="69tbgr"></a></p>
<h4 id="让我们来看看我们的数据！"><a href="#让我们来看看我们的数据！" class="headerlink" title="让我们来看看我们的数据！"></a><a href="#69tbgr"></a>让我们来看看我们的数据！</h4><p>我倾向于是每次运行时都有相同的随机图像，因此我们可以使用Numpy随机数种子来执行此操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">data = ImageDataBunch.from_folder(</span><br><span class="line">                      path, </span><br><span class="line">                      train=<span class="string">"."</span>,</span><br><span class="line">                      valid_pct=<span class="number">0.2</span>,</span><br><span class="line">                      ds_tfms=get_transforms(),</span><br><span class="line">                      size=<span class="number">128</span>,</span><br><span class="line">                      num_workers=<span class="number">4</span>).normalize(imagenet_stats)</span><br></pre></td></tr></table></figure></p>
<p>在这个项目中，我们将使用I<a href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder" target="_blank" rel="noopener">mageDataBunch</a>类来创建我们的数据集。 如果您查看文档，我们可以使用from_folder函数，因为我们的图像位于其尊重的文件夹名称（标签）中。 我们只需要传入我们的路径主目录’data / arctic_dogs’，在这种情况下指定我们要为数据集分区的验证集百分比为20％，注意我们从128x128的小尺寸图像开始，我们也是 指定使用4个进程来启动数据收集，并将数据规范化为张量。<br>我们可以使用以下代码显示我们创建的一批数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.show_batch(rows=<span class="number">3</span>, figsize=(<span class="number">10</span>,<span class="number">12</span>))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545191655740-8516dd1a-524f-4ed2-8f27-37c6627a33b7.png#width=728" alt></p>
<p><a name="bmtmoq"></a></p>
<h3 id="让我们训练我们的模型！"><a href="#让我们训练我们的模型！" class="headerlink" title="让我们训练我们的模型！"></a><a href="#bmtmoq"></a>让我们训练我们的模型！</h3><p>让我们为我们的模型使用Resnet34架构，并显示每个训练周期的error_rate。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn = create_cnn(data, models.resnet34, metrics=error_rate)</span><br><span class="line">#Let&apos;s do 4 cycles and see how good is our model</span><br><span class="line">learn.fit_one_cycle(4)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192086154-f8977f95-9463-46db-9d7c-08231e44d674.png#width=438" alt><br>在用resnet34架构的训练了几个周期之后，我们可以看到error_rate的减少。 我们发现错误率大约下降了2％，错误率大约为17％，这使得我们对这些北极狗的分类准确率达到了83％。 但这还不够好！<br><a name="2l6nyi"></a></p>
<h3 id="模型行为的可解释"><a href="#模型行为的可解释" class="headerlink" title="模型行为的可解释"></a><a href="#2l6nyi"></a>模型行为的可解释</h3><p>我们可以使用FastAI的ClassificationInterpretation类来查看哪些类具有最多的错误和错误分类，以便我们可以微调我们的数据，学习速率，训练周期和我们的数据转换本身。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">learn.save(&apos;stage-1-128&apos;)</span><br><span class="line">learn.load(&apos;stage-1-128&apos;)</span><br><span class="line">interpretation = ClassificationInterpretation.from_learner(learn)</span><br><span class="line">#Plot the confusion matrix to see where does the most errors are made</span><br><span class="line">interpretation.plot_confusion_matrix()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192478392-0adfcf19-68e1-40b0-a402-75abc09fd493.png#width=365" alt><br>我们可以清楚地看到，大多数错误都发生在阿拉斯加雪橇犬和西伯利亚雪橇之间，我们的模型训练非常适合预测萨摩耶和秋田犬。<br><a name="gnvyrq"></a></p>
<h3 id="清理数据"><a href="#清理数据" class="headerlink" title="清理数据"></a><a href="#gnvyrq"></a>清理数据</h3><p>我们在这里优化模型的方法是删除与我们的数据集无关的图像。 我们可以在目录中手动删除这些文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Get the top losses, that has the worse error and the indexes of these images</span><br><span class="line">losses, indexes = interpretation.top_losses()</span><br><span class="line"># Get the paths of these highest losses images from our validation data set</span><br><span class="line">top_loss_paths = data.valid_ds.x[indexes]</span><br><span class="line"># Print the paths of these images</span><br><span class="line">print(top_loss_paths)</span><br></pre></td></tr></table></figure></p>
<p>我们需要找到造成这个问题的原因。一般来讲，训练损失应小于验证损失，从而说明我们的模型训练正确。 而通过上面的结果，我们可以得出结论，在我们的模型中有许多可以改进的东西，使它将达到至少90％的准确度。 幸运的是，Fast.AI有一个功能，我们可以绘制模型丢失时使用的学习率。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192670381-3549e2c1-cebd-4213-89e0-07b8a4835007.png#width=826" alt><br><a name="e0e3sq"></a></p>
<h3 id="让我们做迁移学习来优化我们的模型"><a href="#让我们做迁移学习来优化我们的模型" class="headerlink" title="让我们做迁移学习来优化我们的模型"></a><a href="#e0e3sq"></a>让我们做迁移学习来优化我们的模型</h3><p>优化我们的模型的一个技巧是从较小的图像尺寸开始，并将学习的权重转移到更大图像尺寸的新数据集，并在优化学习速率的同时查看错误率的差异。 我们可以解冻我们的模型，并为下一个训练周期寻找最佳学习率。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Let&apos;s find the best learning rate</span><br><span class="line">learn.unfreeze()</span><br><span class="line">learn.lr_find()</span><br><span class="line"># Plot the learning rate</span><br><span class="line">learn.recorder.plot()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192739862-3da424b4-5028-470f-9db8-0a17fc20fc4b.png#width=421" alt><br>我们可以清楚地看到低于1e-03的学习率，损失比较低。 按照惯例，我们可以使用比1e-03小10倍的下一个学习率，在这种情况下1e-04，在反向传播期间给予它更加保守的变化率。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Train the model again using the same convention as before</span><br><span class="line">lr = 1e-04</span><br><span class="line"># Train the model twice with the new learning rate</span><br><span class="line">learn.fit_one_cycle(2, slice(lr))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192875679-aff31201-ba69-4a72-87d6-3d35bb17eab4.png#width=458" alt><br>哇！ 使用新的学习率后，我们可以看到错误率差异减少2％。 现在让我们通过创建大小为256的新数据来开始转移学习，以查看差异。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Create new ImageDataBunch with size 256</span><br><span class="line">data_bigger = ImageDataBunch.from_folder(path,</span><br><span class="line">                                        train=&quot;.&quot;,</span><br><span class="line">                                        valid_pct=.2,</span><br><span class="line">                                        ds_tfms=get_transforms(),</span><br><span class="line">                                        size=256,</span><br><span class="line">                                        num_workers=4).normalize(imagenet_stats)</span><br><span class="line"># Update the learn data to use this bigger size data</span><br><span class="line">learn.data = data_bigger</span><br><span class="line"># Unfreeze() the model and look for learning rates</span><br><span class="line">learn.unfreeze()</span><br><span class="line"># Plot the learning rate graph</span><br><span class="line">lr_find(learn)</span><br><span class="line">learn.recorder.plot()</span><br></pre></td></tr></table></figure></p>
<p>现在是该使用迁移学习方法的时候了。 我们将使用先前训练的权重，并输入具有256x256更大图片大小的新数据集，以查看训练差异。 我们解冻模型并开始寻找此模型的最佳学习率。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192972024-f3b091da-557b-491f-8606-0688b9987dcf.png#width=425" alt><br><a name="607vie"></a></p>
<h3 id="调整学习率"><a href="#调整学习率" class="headerlink" title="调整学习率"></a><a href="#607vie"></a>调整学习率</h3><p>按照惯例，当数据大小为128时，我们可以通过使用新建立的学习率和先前找到的学习率来切片学习率。切片（新学习率，先前学习率/ 5），我们将先前的学习率除以 5找到最大切片的中间点。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">previous_lr = 1e-05</span><br><span class="line">learn.fit_one_cycle(3, slice(1e-04, previous_lr/5))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193040903-02e0f782-47da-48fd-b14c-5c9bc21fd9f1.png#width=445" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.save(&apos;stage-2-transfer&apos;)</span><br></pre></td></tr></table></figure></p>
<p>别忘了保存模型。<br><a name="tkuuxz"></a></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><a href="#tkuuxz"></a>结论</h3><p>我们在这里可以看到显着的差异。 从使用128图像尺寸开始，我们的最佳错误率约为14％。 在实施转移学习方案后，我们将错误率从大约14％降低到9％错误率，使我们对北极狗的分类准确率大约为91％！<br>我们可以看到混淆矩阵，并与我们的第一个模型相比，看到误差的差异：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn.load(&apos;stage-2-transfer&apos;)</span><br><span class="line">interpretation = ClassificationInterpretation.from_learner(learn)</span><br><span class="line">interpretation.plot_confusion_matrix()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193202165-bbca06f0-705b-42cb-ae40-dced1ccbda53.png#width=330" alt><br>我们可以看到，与我们的第一个模型相比，差异是巨大的，这次我们在用阿拉斯加雪橇犬对西伯利亚雪橇犬进行分类时只犯了3个错误。 此前该模型错误地预测了17次，并且显着下降。<br><a name="spxioq"></a></p>
<h3 id="让我们尝试提供图像并查看预测"><a href="#让我们尝试提供图像并查看预测" class="headerlink" title="让我们尝试提供图像并查看预测"></a><a href="#spxioq"></a>让我们尝试提供图像并查看预测</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = open_image(path/&apos;siberian_husky&apos;/&apos;00000117.jpg&apos;)</span><br><span class="line">img</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193277430-3fab9b4b-4a81-4927-907b-18853201e2d4.png#width=400" alt><br>拾取的图像用于输入我们的模型预测。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Lets create a single data bunch and feed our model to predict the dog breed.</span><br><span class="line">classes = [&apos;alaskan_malamute&apos;, &apos;samoyed&apos;, &apos;siberian_husky&apos;, &apos;akita&apos;]</span><br><span class="line"># Create single data ImageDataBunch</span><br><span class="line">single_data = ImageDataBunch</span><br><span class="line">              .single_from_classes(path,</span><br><span class="line">                     classes,</span><br><span class="line">                     tfms=get_transforms(),</span><br><span class="line">                     suze-256).normalize(imagenet_stats)</span><br><span class="line"># Create new learner with the single data </span><br><span class="line">learn = create_cnn(single_data, models.resnet34, metrics=accuracy)</span><br><span class="line"># Load the previous model</span><br><span class="line">learn.load(&apos;stage-2-transfer&apos;)</span><br></pre></td></tr></table></figure>
<p><br>现在让我们开始预测<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the predicted class, the index and the outputs</span><br><span class="line">predicted_class, predicted_index, outputs = learn.predict(img)</span><br><span class="line">predicted_class</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193392253-a737e005-07e9-4f6b-8aa9-495cda876ba7.png#width=239" alt><br>完美！ 我们成功优化了我们的模型，从大约83％的精度到91％。 这是一个显着的增长，如果我们用几个周期再次训练模型，它可能更准确。<br><br>非常感谢您的时间，<a href="https://github.com/diazagasatya/deep_learning_fastai" target="_blank" rel="noopener">请查看此存储库以获取完整代码</a>！</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 Zhos
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br>1、请确保node版本大于6.2<br>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br> npm i hexo-generator-json-content --save<br><br>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://www.zhos.me/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">很惭愧&lt;br&gt;&lt;br&gt;只做了一点微小的工作&lt;br&gt;谢谢大家</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>