<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="A+">
<meta property="og:url" content="http://zhos.me/page/4/index.html">
<meta property="og:site_name" content="A+">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A+">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zhos.me/page/4/">





  <title>A+</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">A+</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">武德</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://zhos.me/2018/12/19/yuque/去除正则化会避免模型过拟合吗？/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhos">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A+">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/19/yuque/去除正则化会避免模型过拟合吗？/" itemprop="url">去除正则化会避免模型过拟合吗？</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-19T12:28:16+08:00">
                2018-12-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://medium.com/@diazagasatya/will-dropout-regularization-prevents-your-model-to-overfit-11afa10cd4e0" target="_blank" rel="noopener">medium</a><br><em>有人可能会争辩说，最好是过拟合你的模型，然后对其进行逆向工程而不是相反。</em><br>在这个项目中，我们可以看到将Dropout正则化实现到神经网络后的准确性和验证损失的差异。 我们将使用PyTorch库从头开始构建一个顺序神经网络，以便在fashion-MNIST数据集中对10个不同的类进行分类。 这个数据集是28x28灰度图像的衣服。 我们将深入研究dropout的方法，并证明它是否能防止过度拟合。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545194059986-5d2850f6-9304-4568-b09c-e84e6bf6c37e.png#width=699" alt><br>该项目的灵感来自：</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Facebook Udacity PyTorch Challenge.</span><br></pre></td></tr></table></figure>
</blockquote>
<p>首先，我们将创建一个没有正则化实现的神经网络，我们的假设是我们可以推断，随着时间的推移，我们的模型在验证集中表现不佳，因为我们用训练集训练我们的模型越多， 通过对测试数据的特定特征进行分类则越好，从而创建不良的泛化模型去推理。<br><a name="dhgofx"></a></p>
<h4 id="让我们导入Fashion-MNIST数据集"><a href="#让我们导入Fashion-MNIST数据集" class="headerlink" title="让我们导入Fashion-MNIST数据集"></a><a href="#dhgofx"></a>让我们导入Fashion-MNIST数据集</h4><p>让我们使用torchvision下载数据集，通常我们将20％的数据集分开用于验证集。 但在这种情况下，我们将直接从torchvision下载数据集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> helper</span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), </span><br><span class="line">                                transforms.Normalize((<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>),</span><br><span class="line">                                (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>))])</span><br><span class="line">traindataset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>,train=<span class="literal">True</span>,transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(dataset=traindataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">testdataset = datasets.FashionMNIST(<span class="string">'~/.pytorch/F_MNIST_data/'</span>, download=<span class="literal">True</span>,train=<span class="literal">False</span>,transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(dataset=testdataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>我们需要导入torchvision来下载数据集和转换。 然后我们使用变换库将图像转换为张量并进行标准化。 通常批量训练和验证集以提高训练速度并且改组数据也会增加训练和测试数据的学习差异。<br>定义神经网络<br><br>这个模型将有2个隐藏层，输入层将有784个单元，并且在最终层将有10个输出，因为我们有10个不同的类进行分类。 我们将使用交叉熵损失，因为它具有对数性质，可以将我们的输出归一化到接近零或一。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from torch import nn</span><br><span class="line">from torch.functional import F</span><br><span class="line">class FashionNeuralNetwork(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        # Create layers here</span><br><span class="line">        self.layer_input = nn.Linear(784,256)</span><br><span class="line">        self.layer_hidden_one = nn.Linear(256,128)</span><br><span class="line">        self.layer_hidden_two = nn.Linear(128,64)</span><br><span class="line">        self.layer_output = nn.Linear(64,10)</span><br><span class="line">    </span><br><span class="line">   def forward(self, x):</span><br><span class="line">        # Flattened the input to make sure it fits the layer input</span><br><span class="line">        x = x.view(x.shape[0],-1)</span><br><span class="line">        # Pass in the input to the layer and do forward propagation</span><br><span class="line">        x = F.relu(self.layer_input(x))</span><br><span class="line">        x = F.relu(self.layer_hidden_one(x))</span><br><span class="line">        x = F.relu(self.layer_hidden_two(x))</span><br><span class="line">        # Dimension = 1</span><br><span class="line">        x = F.log_softmax(self.layer_output(x),dim=1)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure></p>
<p>该神经网络将使用ReLU作为隐藏层的非线性激活函数，并使用log-softmax激活输出和负对数似然函数用于我们的损失函数。 如果我们查看PyTorch库中的<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss" target="_blank" rel="noopener">交叉熵损失</a>的文档，该标准将nn.LogSoftmax()和nn.NLLLoss()组合在一个单独的类中。 损失可以描述为：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545194731399-7541a6eb-2940-4587-9157-62c90ab37010.png#width=611" alt></p>
<p>请注意，转发传播结束时的线性函数的dim = 1，这意味着输出结果的每一行的概率总和必须等于1.给单个元素的概率最高图像的概率最高 被归类为相应的类索引。<br>我们必须确保模型的输出形状正确性，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetwork()</span><br><span class="line"># Get the images and labels from the test loader</span><br><span class="line">images, labels = next(iter(testloader))</span><br><span class="line"># Get the log probability prediction from our model</span><br><span class="line">log_ps = model(images)</span><br><span class="line"># Normalize the probability by taking the exponent of the log-prob</span><br><span class="line">ps = torch.exp(log_ps)</span><br><span class="line"># Print out the size</span><br><span class="line">print(ps.shape)</span><br></pre></td></tr></table></figure></p>
<p>确保输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([64, 10])</span><br></pre></td></tr></table></figure></p>
<p><a name="o3h0uo"></a></p>
<h4 id="测量我们模型的准确性"><a href="#测量我们模型的准确性" class="headerlink" title="测量我们模型的准确性"></a><a href="#o3h0uo"></a>测量我们模型的准确性</h4><p>由于我们想要一个类的最高概率，我们将使用ps.topk来获得top-k值和top-k索引的元组，例如，如果在4个元素中最高为kth，我们将得到3作为指数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top_p, top_class = ps.topk(1,dim=1)</span><br><span class="line"># Print out the most likely classes for the first 10 examples</span><br><span class="line">print(top_class[:10,:])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195322539-23690b05-a8bf-47b0-92ab-a35a3245d1a2.png#width=122" alt><br>top_class是尺寸为64x1的2D张量，而我们的标签是尺寸为64的1D张量。为了测量标签和模型预测之间的准确度，我们必须确保张量的形状是相同的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># We have to reshape the labels to 64x1 using the view() method</span><br><span class="line">equals = top_class == labels.view(*top_class.shape)</span><br><span class="line">print(equals.shape)</span><br></pre></td></tr></table></figure></p>
<p>比较张量的输出将是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([64, 1])</span><br></pre></td></tr></table></figure></p>
<p>为了计算模型的准确性，我们只需计算模型正确预测的次数。 如果我们的预测与标签相同，则上面的==运算符将逐行检查。 最终结果将是二进制0不相同，1正确预测。 我们可以使用torch.mean计算平均值，但我们需要将equals转换为FloatTensor。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">accuracy = torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line"># Print the accuracy</span><br><span class="line">print(f&apos;Accuracy: &#123;accuracy.item()*100&#125;%&apos;)</span><br></pre></td></tr></table></figure></p>
<p><a name="go1ssu"></a></p>
<h4 id="训练我们的模型"><a href="#训练我们的模型" class="headerlink" title="训练我们的模型"></a><a href="#go1ssu"></a>训练我们的模型</h4><p>由于我们希望损失函数与Logarithm Softmax函数的行为相反，我们将使用负对数似然来计算我们的损失。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">from torch import optim</span><br><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetwork()</span><br><span class="line"># Use Negative Log Likelyhood as our loss function</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line"># Use ADAM optimizer to utilize momentum</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.003)</span><br><span class="line"># Train the model 30 cycles</span><br><span class="line">epochs = 30</span><br><span class="line"># Initialize two empty arrays to hold the train and test losses</span><br><span class="line">train_losses, test_losses = [],[]</span><br><span class="line"># Start the training</span><br><span class="line">for i in range(epochs):</span><br><span class="line">    running_loss = 0</span><br><span class="line">    # Loop through all of the train set forward and back propagate</span><br><span class="line">    for images,labels in trainloader:</span><br><span class="line">        optimizer.zero_grad()                      </span><br><span class="line">        log_ps = model(images)                     </span><br><span class="line">        loss = loss_function(log_ps, labels)       </span><br><span class="line">        loss.backward()                            # Backpropagate</span><br><span class="line">        optimizer.step()                           </span><br><span class="line">        running_loss += loss.item()                </span><br><span class="line">    </span><br><span class="line">    # Initialize test loss and accuracy to be 0 </span><br><span class="line">    test_loss = 0</span><br><span class="line">    accuracy = 0</span><br><span class="line">    </span><br><span class="line">    # Turn off the gradients</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        # Loop through all of the validation set</span><br><span class="line">        for images, labels in testloader:</span><br><span class="line">            log_ps = model(images)                                 </span><br><span class="line">            ps = torch.exp(log_ps)                                 </span><br><span class="line">            test_loss += loss_function(log_ps, labels)             </span><br><span class="line">            top_p, top_class = ps.topk(1,dim=1)                    </span><br><span class="line">            equals = top_class == labels.view(*top_class.shape)   </span><br><span class="line">            accuracy += torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line">    </span><br><span class="line">    # Append the average losses to the array for plotting       </span><br><span class="line">    train_losses.append(running_loss/len(trainloader))</span><br><span class="line">    test_losses.append(test_loss/len(testloader))</span><br></pre></td></tr></table></figure></p>
<p>打印我们的模型<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195544515-f2c011c6-a9ad-4673-a266-508907165f04.png#width=684" alt><br>这证明了我们的假设，即完全说明我们的模型将训练的很好，但不能推广训练数据集之外的图像。 我们可以看到，30个周期的训练损失显著减少，但我们的验证损失在大约36-48％之间波动。 这是过度拟合的标志，这个情况说明，模型学习训练数据集的特定特征和模式，它无法正确分类数据集之外的图像。 这通常很糟糕，因为这意味着如果我们使用推理，模型就无法正确分类。<br><a name="r5sdzs"></a></p>
<h4 id="为了清楚的说明"><a href="#为了清楚的说明" class="headerlink" title="为了清楚的说明"></a><a href="#r5sdzs"></a>为了清楚的说明</h4><p>让我们画图看一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Plot the graph here</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = &apos;retina&apos;</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(train_losses, label=&apos;Training Loss&apos;)</span><br><span class="line">plt.plot(test_losses, label=&apos;Validation Loss&apos;)</span><br><span class="line">plt.legend(frameon=True)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545195769635-b5ee1591-723d-4cb7-a10b-2b0a8740d404.png#width=554" alt><br><a name="4gv0rl"></a></p>
<h4 id="过度拟合"><a href="#过度拟合" class="headerlink" title="过度拟合"></a><a href="#4gv0rl"></a>过度拟合</h4><p>从上图中我们可以清楚地看到，我们的模型并没有很好地泛华。 这意味着该模型在对训练数据集之外的图像进行分类方面做得不好。 这真的很糟糕，这意味着我们的模型只学习我们的训练数据集的具体内容，它变得如此个别，以至于它只能识别来自训练集的图像。 如果我们从图表中看到，每个周期的训练损失都会显著减少，但是，我们可以看到验证损失却没发生什么变化。<br><a name="mm70mi"></a></p>
<h4 id="正则"><a href="#正则" class="headerlink" title="正则"></a><a href="#mm70mi"></a>正则</h4><p>这就是正则化的用武之地，其中一种方法是进行L2正则化，也称为<em>early-stopping</em>，这基本上意味着我们将在验证损失最低时停止训练我们的模型。 在这种情况下，我们的验证损失在3-5个时期后达到最佳。 这意味着超过5个周期，我们的模型泛化会变得更糟。<br><br>但是，还有另一种方法可以解决这个问题。 我们可以为我们的模型进行<em>dropout</em>，以进行更多的泛化。 基本上，我们的模型通过在大型重量上滚雪球并使其他要训练的重量不足而贪婪地行动。 通过具有随机丢失，具有较小权重的节点将有机会在循环期间被训练，从而在结束时给出更一般化的分数。 换句话说，它迫使网络在权重之间共享信息，从而提供更好的泛化能力。<br>注意：<br><br>在训练期间，我们希望实行dropout，但是，在验证过程中，我们需要我们模型的全部功能，因为那时我们可以完全测量模型对这些图像进行泛化其准确性。 如果我们使用model.eval()模式，我们将停止使用dropout，并且不要忘记在训练期间使用model.train()再次使用它。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">### Define our new Network with Dropouts</span><br><span class="line">class FashionNeuralNetworkDropout(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        # Create layers here</span><br><span class="line">        self.layer_input = nn.Linear(784,256)</span><br><span class="line">        self.layer_hidden_one = nn.Linear(256,128)</span><br><span class="line">        self.layer_hidden_two = nn.Linear(128,64)</span><br><span class="line">        self.layer_output = nn.Linear(64,10)</span><br><span class="line">        </span><br><span class="line">        # 20% Dropout here</span><br><span class="line">        self.dropout = nn.Dropout(p=0.2)</span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # Flattened the input to make sure it fits the layer input</span><br><span class="line">        x = x.view(x.shape[0],-1)</span><br><span class="line">        # Pass in the input to the layer and do forward propagation</span><br><span class="line">        x = self.dropout(F.relu(self.layer_input(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.layer_hidden_one(x)))</span><br><span class="line">        x = self.dropout(F.relu(self.layer_hidden_two(x)))</span><br><span class="line">        # Dimension = 1</span><br><span class="line">        x = F.log_softmax(self.layer_output(x),dim=1)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure></p>
<p>这个神经网络将与第一个模型非常相似，但是，我们将增加20％的丢失。 现在让我们训练这个模型吧！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from torch import optim</span><br><span class="line"># Instantiate the model</span><br><span class="line">model = FashionNeuralNetworkDropout()</span><br><span class="line"># Use Negative Log Likelyhood as our loss function</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line"># Use ADAM optimizer to utilize momentum</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.003)</span><br><span class="line"># Train the model 30 cycles</span><br><span class="line">epochs = 30</span><br><span class="line"># Initialize two empty arrays to hold the train and test losses</span><br><span class="line">train_losses, test_losses = [],[]</span><br><span class="line"># Start the training</span><br><span class="line">for i in range(epochs):</span><br><span class="line">    running_loss = 0</span><br><span class="line"># Loop through all of the train set forward and back propagate</span><br><span class="line">    for images,labels in trainloader:</span><br><span class="line">        optimizer.zero_grad()                      </span><br><span class="line">        log_ps = model(images)                     </span><br><span class="line">        loss = loss_function(log_ps, labels)       </span><br><span class="line">        loss.backward()                            # Backpropagate</span><br><span class="line">        optimizer.step()                           </span><br><span class="line">        running_loss += loss.item()                </span><br><span class="line">    </span><br><span class="line">    # Initialize test loss and accuracy to be 0 </span><br><span class="line">    test_loss = 0</span><br><span class="line">    accuracy = 0</span><br><span class="line">    </span><br><span class="line">    # Turn off the gradients</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        # Turn on Evaluation mode</span><br><span class="line">        model.eval()</span><br><span class="line">        # Loop through all of the validation set</span><br><span class="line">        for images, labels in testloader:</span><br><span class="line">            log_ps = model(images)                                 </span><br><span class="line">            ps = torch.exp(log_ps)                                 </span><br><span class="line">            test_loss += loss_function(log_ps, labels)             </span><br><span class="line">            top_p, top_class = ps.topk(1,dim=1)                    </span><br><span class="line">            equals = top_class == labels.view(*top_class.shape)   </span><br><span class="line">            accuracy += torch.mean(equals.type(torch.FloatTensor))</span><br><span class="line"></span><br><span class="line">    # Turn on Training mode again</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    # Append the average losses to the array for plotting       </span><br><span class="line">    train_losses.append(running_loss/len(trainloader))</span><br><span class="line">    test_losses.append(test_loss/len(testloader))</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196342869-4eae3b68-560b-4427-8e2f-34dec5ae5da0.png#width=687" alt><br>这里的目标是使验证损失与我们的训练损失一样低，这意味着我们的模型相当准确。 让我们再次绘制图表，看看正则化后的差异。 即使精度水平仅整体上升0.3％，该模型也没有过度拟合，因为它保持了在训练期间训练的所有节点的平衡。 让我们绘制图表并查看差异：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Plot the graph here</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = &apos;retina&apos;</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.plot(train_losses, label=&apos;Training Loss&apos;)</span><br><span class="line">plt.plot(test_losses, label=&apos;Validation Loss&apos;)</span><br><span class="line">plt.legend(frameon=True)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196385024-ee9585c8-819c-4da5-aaa1-10592b806d57.png#width=555" alt><br><a name="hsnqvc"></a></p>
<h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a><a href="#hsnqvc"></a>推理</h4><p>现在我们的模型可以更好地泛化，让我们用提供模型尝试用训练数据集之外的图像进行预测，并可视化模型的分类。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Make sure to make our model in the evaluation mode</span><br><span class="line">model.eval()</span><br><span class="line"># Get the next image and label</span><br><span class="line">images, labels = next(iter(testloader))</span><br><span class="line">img = images[0]</span><br><span class="line"># Convert 2D image to 1D vector</span><br><span class="line">img = img.view(1, 784)</span><br><span class="line"># Calculate the class probabilities (log-softmax) for img</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    output = model.forward(img)</span><br><span class="line"># Normalize the output</span><br><span class="line">ps = torch.exp(output)</span><br><span class="line"># Plot the image and probabilities</span><br><span class="line">helper.view_classify(img.view(1, 28, 28), ps, version=&apos;Fashion&apos;)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545196482739-f2d874ee-fbb1-4c28-915c-d2c72a8db458.png#width=624" alt><br><a name="67g8gr"></a></p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a><a href="#67g8gr"></a>结论</h4><p>这很棒！ 我们可以看到培训损失和验证损失之间的显着平衡。 可以肯定地说，如果我们训练模型进行更多循环并微调我们的超参数，则验证损失将减少。 从上图中我们可以看出，我们的模型随着时间的推移更好地泛化，模型在6-8个时期之后可以获得更好的精度，并且可以肯定地说模型通过实现模型的丢失来防止过度拟合。<br><a name="bc98"></a></p>
<h3 id="Thank-you-so-much-for-your-time-and-please-check-out-this-repository-for-the-full-code"><a href="#Thank-you-so-much-for-your-time-and-please-check-out-this-repository-for-the-full-code" class="headerlink" title="Thank you so much for your time, and please check out this repository for the full code!"></a><a href="#bc98"></a>Thank you so much for your time, and please check out this <a href="https://github.com/diazagasatya/deep_learning_fastai/blob/master/main/Fashion%20MNIST%20-%20Classification%20Problem.ipynb" target="_blank" rel="noopener">repository</a> for the full code!</h3><p>This is my <a href="https://www.diazidabagus.com/" target="_blank" rel="noopener">Portfolio</a> and <a href="https://www.linkedin.com/in/diaz-agasatya-16487b109/" target="_blank" rel="noopener">Linked-In</a> profile :)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://zhos.me/2018/12/19/yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhos">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A+">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/19/yuque/迁移学习：使用Fast.AI库对4种北极犬进行分类/" itemprop="url">迁移学习：使用Fast.AI库对4种北极犬进行分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-19T10:16:20+08:00">
                2018-12-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://medium.com/@diazagasatya/transfer-learning-classification-of-4-different-types-of-arctic-dog-using-fast-ai-library-665cb424af5e" target="_blank" rel="noopener">链接</a></p>
<p>该项目的灵感来自Adrian Rosebrock，Francisco Ingham和Jeremy Howard。</p>
<p>在本课程中，我们将从Google Images创建自己的数据集。</p>
<p>我将使用FastAI库中的Resnet34的架构。</p>
<p>在这个特别的项目中，我们将从谷歌下载四种不同类型的北极狗（阿拉斯加雪橇犬，西伯利亚雪橇犬，萨摩耶犬和秋田犬）图像，并建立可以通过这些图像进行分类的最先进模型。 在这个项目中，我们将逐步从Google中为每个品种下载200多张图片。</p>
<p>有很多方法可以为我们的训练数据集找到最有效的谷歌图像，但是，在这个项目中，我们只需打开谷歌图像并记录我们需要的特定品种。</p>
<p>我们需要滚动到页面末尾，然后单击到最底部“显示更多结果”。 （700张图片是Google图片可以显示的最大数量）</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545186372059-c21d0df4-c271-46e8-a15d-5b0ba9d580ef.png#width=826" alt></p>
<p>使用浏览器中的Javascript代码将URL下载到文本文件中。 对于Mac用户，按Cmd Opt J，在Windows / Linux中按Ctrl Shift J打开javascript控制台并运行以下命令：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">urls = <span class="built_in">Array</span>.from(<span class="built_in">document</span>.querySelectorAll(<span class="string">'.rg_di .rg_meta'</span>)).map(<span class="function"><span class="params">el</span>=&gt;</span><span class="built_in">JSON</span>.parse(el.textContent).ou);</span><br><span class="line"><span class="built_in">window</span>.open(<span class="string">'data:text/csv;charset=utf-8,'</span> + <span class="built_in">escape</span>(urls.join(<span class="string">'\n'</span>)));</span><br></pre></td></tr></table></figure></p>
<p>将下载的文件命名为’dogbreed’.txt文件（确保此时暂停广告块），在这种情况下，我们将有4种不同的犬种：阿拉斯加雪橇犬，萨摩耶犬，西伯利亚雪橇犬和秋田犬。<br><a name="uh6vno"></a></p>
<h4 id="使用FastAI库下载图像"><a href="#使用FastAI库下载图像" class="headerlink" title="使用FastAI库下载图像"></a><a href="#uh6vno"></a>使用FastAI库下载图像</h4><p>Fast.AI有一个非常方便的功能，它将通过我们之前在文本文件中提供的URL为我们下载图像。 请注意，我们可以更改要下载的最大图片数量，我们只需要指定文本文件的路径和目标，然后函数将处理其余部分。<br><em>注意：由于某些图像无法从URL打开，因此在训练步骤中可能会产生冲突。 加载的错误图像将被忽略并移至下一个URL。</em><br>folder = ‘alaskan_malamute’<br>file = ‘urls_alaskan_malamute.txt’<br>path = Path(‘data/arctic_dogs’)<br>destination = path/folder<br>destination.mkdir(parents=True, exist_ok=True)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">folder = <span class="string">'alaskan_malamute'</span></span><br><span class="line">file = <span class="string">'urls_alaskan_malamute.txt'</span></span><br><span class="line">path = Path(<span class="string">'data/arctic_dogs'</span>)</span><br><span class="line">destination = path/folder</span><br><span class="line">destination.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># download_images(path/file, destination, max_pics=300)download_images(path/file, destination, max_pics=300, max_workers=0)</span></span><br></pre></td></tr></table></figure>
<p>因为我们想训练模型的所有不同类型的犬种，因此需要做4次下载。 在这种情况下，请将文件夹名称更改为其他四种不同的狗品种，并确保文件名与先前使用javascript命令下载的文本文件的名称相匹配。<br>然后我们通过如下方式删除无法通过链接打开的图像：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classes = [<span class="string">'alaskan_malamute'</span>, <span class="string">'samoyed'</span>, <span class="string">'siberian_husky'</span>, <span class="string">'akita'</span>]</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> classes:</span><br><span class="line">    print(c)</span><br><span class="line">    verify_images(path/c, delete=<span class="literal">True</span>, max_workers=<span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>
<p><a name="69tbgr"></a></p>
<h4 id="让我们来看看我们的数据！"><a href="#让我们来看看我们的数据！" class="headerlink" title="让我们来看看我们的数据！"></a><a href="#69tbgr"></a>让我们来看看我们的数据！</h4><p>我倾向于是每次运行时都有相同的随机图像，因此我们可以使用Numpy随机数种子来执行此操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">data = ImageDataBunch.from_folder(</span><br><span class="line">                      path, </span><br><span class="line">                      train=<span class="string">"."</span>,</span><br><span class="line">                      valid_pct=<span class="number">0.2</span>,</span><br><span class="line">                      ds_tfms=get_transforms(),</span><br><span class="line">                      size=<span class="number">128</span>,</span><br><span class="line">                      num_workers=<span class="number">4</span>).normalize(imagenet_stats)</span><br></pre></td></tr></table></figure></p>
<p>在这个项目中，我们将使用I<a href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder" target="_blank" rel="noopener">mageDataBunch</a>类来创建我们的数据集。 如果您查看文档，我们可以使用from_folder函数，因为我们的图像位于其尊重的文件夹名称（标签）中。 我们只需要传入我们的路径主目录’data / arctic_dogs’，在这种情况下指定我们要为数据集分区的验证集百分比为20％，注意我们从128x128的小尺寸图像开始，我们也是 指定使用4个进程来启动数据收集，并将数据规范化为张量。<br>我们可以使用以下代码显示我们创建的一批数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.show_batch(rows=<span class="number">3</span>, figsize=(<span class="number">10</span>,<span class="number">12</span>))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545191655740-8516dd1a-524f-4ed2-8f27-37c6627a33b7.png#width=728" alt></p>
<p><a name="bmtmoq"></a></p>
<h3 id="让我们训练我们的模型！"><a href="#让我们训练我们的模型！" class="headerlink" title="让我们训练我们的模型！"></a><a href="#bmtmoq"></a>让我们训练我们的模型！</h3><p>让我们为我们的模型使用Resnet34架构，并显示每个训练周期的error_rate。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn = create_cnn(data, models.resnet34, metrics=error_rate)</span><br><span class="line">#Let&apos;s do 4 cycles and see how good is our model</span><br><span class="line">learn.fit_one_cycle(4)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192086154-f8977f95-9463-46db-9d7c-08231e44d674.png#width=438" alt><br>在用resnet34架构的训练了几个周期之后，我们可以看到error_rate的减少。 我们发现错误率大约下降了2％，错误率大约为17％，这使得我们对这些北极狗的分类准确率达到了83％。 但这还不够好！<br><a name="2l6nyi"></a></p>
<h3 id="模型行为的可解释"><a href="#模型行为的可解释" class="headerlink" title="模型行为的可解释"></a><a href="#2l6nyi"></a>模型行为的可解释</h3><p>我们可以使用FastAI的ClassificationInterpretation类来查看哪些类具有最多的错误和错误分类，以便我们可以微调我们的数据，学习速率，训练周期和我们的数据转换本身。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">learn.save(&apos;stage-1-128&apos;)</span><br><span class="line">learn.load(&apos;stage-1-128&apos;)</span><br><span class="line">interpretation = ClassificationInterpretation.from_learner(learn)</span><br><span class="line">#Plot the confusion matrix to see where does the most errors are made</span><br><span class="line">interpretation.plot_confusion_matrix()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192478392-0adfcf19-68e1-40b0-a402-75abc09fd493.png#width=365" alt><br>我们可以清楚地看到，大多数错误都发生在阿拉斯加雪橇犬和西伯利亚雪橇之间，我们的模型训练非常适合预测萨摩耶和秋田犬。<br><a name="gnvyrq"></a></p>
<h3 id="清理数据"><a href="#清理数据" class="headerlink" title="清理数据"></a><a href="#gnvyrq"></a>清理数据</h3><p>我们在这里优化模型的方法是删除与我们的数据集无关的图像。 我们可以在目录中手动删除这些文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Get the top losses, that has the worse error and the indexes of these images</span><br><span class="line">losses, indexes = interpretation.top_losses()</span><br><span class="line"># Get the paths of these highest losses images from our validation data set</span><br><span class="line">top_loss_paths = data.valid_ds.x[indexes]</span><br><span class="line"># Print the paths of these images</span><br><span class="line">print(top_loss_paths)</span><br></pre></td></tr></table></figure></p>
<p>我们需要找到造成这个问题的原因。一般来讲，训练损失应小于验证损失，从而说明我们的模型训练正确。 而通过上面的结果，我们可以得出结论，在我们的模型中有许多可以改进的东西，使它将达到至少90％的准确度。 幸运的是，Fast.AI有一个功能，我们可以绘制模型丢失时使用的学习率。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192670381-3549e2c1-cebd-4213-89e0-07b8a4835007.png#width=826" alt><br><a name="e0e3sq"></a></p>
<h3 id="让我们做迁移学习来优化我们的模型"><a href="#让我们做迁移学习来优化我们的模型" class="headerlink" title="让我们做迁移学习来优化我们的模型"></a><a href="#e0e3sq"></a>让我们做迁移学习来优化我们的模型</h3><p>优化我们的模型的一个技巧是从较小的图像尺寸开始，并将学习的权重转移到更大图像尺寸的新数据集，并在优化学习速率的同时查看错误率的差异。 我们可以解冻我们的模型，并为下一个训练周期寻找最佳学习率。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Let&apos;s find the best learning rate</span><br><span class="line">learn.unfreeze()</span><br><span class="line">learn.lr_find()</span><br><span class="line"># Plot the learning rate</span><br><span class="line">learn.recorder.plot()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192739862-3da424b4-5028-470f-9db8-0a17fc20fc4b.png#width=421" alt><br>我们可以清楚地看到低于1e-03的学习率，损失比较低。 按照惯例，我们可以使用比1e-03小10倍的下一个学习率，在这种情况下1e-04，在反向传播期间给予它更加保守的变化率。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Train the model again using the same convention as before</span><br><span class="line">lr = 1e-04</span><br><span class="line"># Train the model twice with the new learning rate</span><br><span class="line">learn.fit_one_cycle(2, slice(lr))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192875679-aff31201-ba69-4a72-87d6-3d35bb17eab4.png#width=458" alt><br>哇！ 使用新的学习率后，我们可以看到错误率差异减少2％。 现在让我们通过创建大小为256的新数据来开始转移学习，以查看差异。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Create new ImageDataBunch with size 256</span><br><span class="line">data_bigger = ImageDataBunch.from_folder(path,</span><br><span class="line">                                        train=&quot;.&quot;,</span><br><span class="line">                                        valid_pct=.2,</span><br><span class="line">                                        ds_tfms=get_transforms(),</span><br><span class="line">                                        size=256,</span><br><span class="line">                                        num_workers=4).normalize(imagenet_stats)</span><br><span class="line"># Update the learn data to use this bigger size data</span><br><span class="line">learn.data = data_bigger</span><br><span class="line"># Unfreeze() the model and look for learning rates</span><br><span class="line">learn.unfreeze()</span><br><span class="line"># Plot the learning rate graph</span><br><span class="line">lr_find(learn)</span><br><span class="line">learn.recorder.plot()</span><br></pre></td></tr></table></figure></p>
<p>现在是该使用迁移学习方法的时候了。 我们将使用先前训练的权重，并输入具有256x256更大图片大小的新数据集，以查看训练差异。 我们解冻模型并开始寻找此模型的最佳学习率。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545192972024-f3b091da-557b-491f-8606-0688b9987dcf.png#width=425" alt><br><a name="607vie"></a></p>
<h3 id="调整学习率"><a href="#调整学习率" class="headerlink" title="调整学习率"></a><a href="#607vie"></a>调整学习率</h3><p>按照惯例，当数据大小为128时，我们可以通过使用新建立的学习率和先前找到的学习率来切片学习率。切片（新学习率，先前学习率/ 5），我们将先前的学习率除以 5找到最大切片的中间点。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">previous_lr = 1e-05</span><br><span class="line">learn.fit_one_cycle(3, slice(1e-04, previous_lr/5))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193040903-02e0f782-47da-48fd-b14c-5c9bc21fd9f1.png#width=445" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.save(&apos;stage-2-transfer&apos;)</span><br></pre></td></tr></table></figure></p>
<p>别忘了保存模型。<br><a name="tkuuxz"></a></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><a href="#tkuuxz"></a>结论</h3><p>我们在这里可以看到显着的差异。 从使用128图像尺寸开始，我们的最佳错误率约为14％。 在实施转移学习方案后，我们将错误率从大约14％降低到9％错误率，使我们对北极狗的分类准确率大约为91％！<br>我们可以看到混淆矩阵，并与我们的第一个模型相比，看到误差的差异：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn.load(&apos;stage-2-transfer&apos;)</span><br><span class="line">interpretation = ClassificationInterpretation.from_learner(learn)</span><br><span class="line">interpretation.plot_confusion_matrix()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193202165-bbca06f0-705b-42cb-ae40-dced1ccbda53.png#width=330" alt><br>我们可以看到，与我们的第一个模型相比，差异是巨大的，这次我们在用阿拉斯加雪橇犬对西伯利亚雪橇犬进行分类时只犯了3个错误。 此前该模型错误地预测了17次，并且显着下降。<br><a name="spxioq"></a></p>
<h3 id="让我们尝试提供图像并查看预测"><a href="#让我们尝试提供图像并查看预测" class="headerlink" title="让我们尝试提供图像并查看预测"></a><a href="#spxioq"></a>让我们尝试提供图像并查看预测</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = open_image(path/&apos;siberian_husky&apos;/&apos;00000117.jpg&apos;)</span><br><span class="line">img</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193277430-3fab9b4b-4a81-4927-907b-18853201e2d4.png#width=400" alt><br>拾取的图像用于输入我们的模型预测。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Lets create a single data bunch and feed our model to predict the dog breed.</span><br><span class="line">classes = [&apos;alaskan_malamute&apos;, &apos;samoyed&apos;, &apos;siberian_husky&apos;, &apos;akita&apos;]</span><br><span class="line"># Create single data ImageDataBunch</span><br><span class="line">single_data = ImageDataBunch</span><br><span class="line">              .single_from_classes(path,</span><br><span class="line">                     classes,</span><br><span class="line">                     tfms=get_transforms(),</span><br><span class="line">                     suze-256).normalize(imagenet_stats)</span><br><span class="line"># Create new learner with the single data </span><br><span class="line">learn = create_cnn(single_data, models.resnet34, metrics=accuracy)</span><br><span class="line"># Load the previous model</span><br><span class="line">learn.load(&apos;stage-2-transfer&apos;)</span><br></pre></td></tr></table></figure>
<p><br>现在让我们开始预测<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the predicted class, the index and the outputs</span><br><span class="line">predicted_class, predicted_index, outputs = learn.predict(img)</span><br><span class="line">predicted_class</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545193392253-a737e005-07e9-4f6b-8aa9-495cda876ba7.png#width=239" alt><br>完美！ 我们成功优化了我们的模型，从大约83％的精度到91％。 这是一个显着的增长，如果我们用几个周期再次训练模型，它可能更准确。<br><br>非常感谢您的时间，<a href="https://github.com/diazagasatya/deep_learning_fastai" target="_blank" rel="noopener">请查看此存储库以获取完整代码</a>！</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Zhos</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhos</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
