<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href="http://www.zhos.me">
  <title>A+</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="研究性材料(算法)">
<meta property="og:type" content="website">
<meta property="og:title" content="A+">
<meta property="og:url" content="http://www.zhos.me/page/9/index.html">
<meta property="og:site_name" content="A+">
<meta property="og:description" content="研究性材料(算法)">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A+">
<meta name="twitter:description" content="研究性材料(算法)">
  
    <link rel="alternative" href="/atom.xml" title="A+" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>
</html>
<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Zhos</a></h1>
		</hgroup>
		
		<p class="header-subtitle">ai &amp; bigdata &amp; ml</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/187063598" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Zhos</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>ai &amp; bigdata &amp; ml<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/187063598" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 100%"><a href="/">主页</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-yuque/Mlflow介绍" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/15/yuque/Mlflow介绍/">Mlflow介绍</a>
    </h1>
  

        
        <a href="/2019/03/15/yuque/Mlflow介绍/" class="archive-article-date">
  	<time datetime="2019-03-15T01:40:23.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-03-15</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a name="61a3ec66"></a></p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>MLflow是一个完整的机器学习生命周期的开源平台。这意味着它具有在训练和运行期间监控模型的组件，存储模型的能力，在生产代码中加载模型以及创建管道。<br>MLflow的主要目标是在ML之上提供额外的层，允许数据科学家与几乎任何机器学习库（<a href="https://github.com/h2oai" target="_blank" rel="noopener"><em>h2o，</em></a><a href="https://keras.io/" target="_blank" rel="noopener"><em>keras，</em></a><a href="http://mleap-docs.combust.ml/" target="_blank" rel="noopener"><em>mleap，</em></a><a href="https://pytorch.org/" target="_blank" rel="noopener"><em>pytorch，</em></a><a href="http://scikit-learn.org/stable/" target="_blank" rel="noopener"><em>sklearn和</em></a><a href="https://www.tensorflow.org/" target="_blank" rel="noopener"><em>tensorflow</em></a>）一起工作，同时，它将他们的工作带到另一个层次。<br>MLflow提供三个组件：</p>
<ul>
<li><a href="https://mlflow.org/docs/latest/tracking.html" target="_blank" rel="noopener"><strong>跟踪</strong></a>  - 记录和查询实验：代码，数据，配置和结果。跟踪建模进度非常有用。</li>
<li><a href="https://mlflow.org/docs/latest/projects.html" target="_blank" rel="noopener"><strong>项目</strong></a>  - 在任何平台（<strong>_即_</strong> <a href="https://aws.amazon.com/sagemaker" target="_blank" rel="noopener"><em>Sagemaker</em></a>）上可重复运行的包装格式。</li>
<li><a href="https://mlflow.org/docs/latest/models.html" target="_blank" rel="noopener"><strong>模型</strong></a>  - 将模型发送到各种部署工具的通用格式。<blockquote>
<p><strong>MLflow</strong>是一个管理ML生命周期的开源平台，包括实验，可重复性和部署。<br><a name="e655a410"></a></p>
</blockquote>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1>MLflow的一个特别之处是需要conda的支持，因此为保证后期可用，需要首先安装conda环境。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh</span><br><span class="line">bash Anaconda3-2018.12-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<p>安装完后，添加到环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure>
<p>添加git权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C <span class="string">"ujujzhao@gmail.com"</span></span><br></pre></td></tr></table></figure>
<p>安装mlflow</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./pip install mlflow</span><br></pre></td></tr></table></figure>
<p><a name="c182e73c"></a></p>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><p><a name="c66f9448"></a></p>
<h2 id="使用Tracking-API"><a href="#使用Tracking-API" class="headerlink" title="使用Tracking API"></a>使用Tracking API</h2><p>该<a href="https://mlflow.org/docs/latest/tracking.html" target="_blank" rel="noopener">MLflow跟踪API</a>可以让你从你的数据的科学代码登录度量和工件（文件），看看您运行的历史。您可以通过编写如下的简单Python脚本来尝试它（此示例也包括在内<code>quickstart/mlflow_tracking.py</code>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> mlflow <span class="keyword">import</span> log_metric, log_param, log_artifact</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># Log a parameter (key-value pair)</span></span><br><span class="line">    log_param(<span class="string">"param1"</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Log a metric; metrics can be updated throughout the run</span></span><br><span class="line">    log_metric(<span class="string">"foo"</span>, <span class="number">1</span>)</span><br><span class="line">    log_metric(<span class="string">"foo"</span>, <span class="number">2</span>)</span><br><span class="line">    log_metric(<span class="string">"foo"</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Log an artifact (output file)</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"output.txt"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">"Hello world!"</span>)</span><br><span class="line">    log_artifact(<span class="string">"output.txt"</span>)</span><br></pre></td></tr></table></figure>
<p><a name="a1168828"></a></p>
<h2 id="查看跟踪UI"><a href="#查看跟踪UI" class="headerlink" title="查看跟踪UI"></a>查看跟踪UI</h2><p>默认情况下，无论您在何处运行程序，跟踪API都会将数据写入文件到<code>mlruns</code>目录中。然后，您可以运行MLflow的跟踪UI：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow ui</span><br></pre></td></tr></table></figure></p>
<p>为保证外网能够访问，需添加host命令，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow ui -h 0.0.0.0</span><br></pre></td></tr></table></figure>
<p>其他的命令功能请直接执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow ui --help</span><br></pre></td></tr></table></figure>
<p><a name="1a0ff95a"></a></p>
<h2 id="运行MLflow项目"><a href="#运行MLflow项目" class="headerlink" title="运行MLflow项目"></a>运行MLflow项目<a href="https://mlflow.org/docs/latest/quickstart.html#running-mlflow-projects" target="_blank" rel="noopener"></a></h2><p>MLflow允许您将代码及其依赖项打包为一个可以在其他数据上以可重现的方式运行的_项目_。每个项目都包含其代码和<code>MLproject</code>定义其依赖项的文件（例如，Python环境），以及可以在项目中运行的命令以及它们采用的参数。<br>您可以使用命令轻松运行现有项目，该命令从本地目录或GitHub URI运行项目：<code>mlflow run</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mlflow run tutorial -P alpha=0.5</span><br><span class="line"></span><br><span class="line">mlflow run git@github.com:mlflow/mlflow-example.git -P alpha=5</span><br></pre></td></tr></table></figure>
<p>有一个示例项目<code>tutorial</code>，包括一个<code>MLproject</code>指定其依赖项的文件。如果您尚未配置<a href="https://mlflow.org/docs/latest/tracking.html#tracking-server" target="_blank" rel="noopener">跟踪服务器</a>，则项目会将其Tracking API数据记录在本地<code>mlruns</code>目录中，以便您可以使用这些运行来查看这些运行。<code>mlflow ui</code></p>
<blockquote>
<p>默认情况下，使用<a href="https://conda.io/" target="_blank" rel="noopener">conda</a>安装所有依赖项。要在不使用的情况下运行项目，可以提供选项 。在这种情况下，您必须确保已在Python环境中安装必要的依赖项。<code>mlflow run`</code>–no-conda`</p>
</blockquote>
<p><a name="b7824d5c"></a></p>
<h1 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h1><p>本教程展示了如何使用MLflow端到端：</p>
<ul>
<li>训练线性回归模型</li>
<li>打包以可重用且可重现的模型格式训练模型的代码</li>
<li>将模型部署到一个简单的HTTP服务器中，使您能够对预测进行评分</li>
</ul>
<p>本教程使用数据集根据葡萄酒的“固定酸度”，“pH值”，“残糖”等定量特征预测葡萄酒的质量。该数据集来自UCI的<a href="http://archive.ics.uci.edu/ml/datasets/Wine+Quality" target="_blank" rel="noopener">机器学习库</a>。 <a href="https://mlflow.org/docs/latest/tutorial.html#id4" target="_blank" rel="noopener">[1]</a><br>目录</p>
<ul>
<li><a href="https://mlflow.org/docs/latest/tutorial.html#what-you-ll-need" target="_blank" rel="noopener">你需要什么</a></li>
<li><a href="https://mlflow.org/docs/latest/tutorial.html#training-the-model" target="_blank" rel="noopener">培训模型</a></li>
<li><a href="https://mlflow.org/docs/latest/tutorial.html#comparing-the-models" target="_blank" rel="noopener">比较模型</a></li>
<li><a href="https://mlflow.org/docs/latest/tutorial.html#packaging-the-training-code" target="_blank" rel="noopener">打包培训代码</a></li>
<li><a href="https://mlflow.org/docs/latest/tutorial.html#serving-the-model" target="_blank" rel="noopener">服务模型</a></li>
<li><p><a href="https://mlflow.org/docs/latest/tutorial.html#more-resources" target="_blank" rel="noopener">更多资源</a><br><a name="60691d91"></a></p>
<h2 id="你需要什么"><a href="#你需要什么" class="headerlink" title="你需要什么"></a><a href="https://mlflow.org/docs/latest/tutorial.html#id5" target="_blank" rel="noopener">你需要什么</a><a href="https://mlflow.org/docs/latest/tutorial.html#what-you-ll-need" target="_blank" rel="noopener"></a></h2><p>要运行本教程，您需要：</p>
</li>
<li><p>安装MLflow（通过）<code>pip install mlflow</code></p>
</li>
<li>安装<a href="https://conda.io/docs/user-guide/install/index.html#" target="_blank" rel="noopener">conda</a></li>
<li>克隆（下载）MLflow存储库 <code>git clone https://github.com/mlflow/mlflow</code></li>
<li><code>cd</code>进入<code>examples</code>你的MLflow克隆目录 - 我们将使用这个工作目录来运行教程。我们避免直接从我们的MLflow克隆中运行，因为这样做会导致教程从源代码中使用MLflow，而不是使用MLflow的PyPI安装。<br><a name="a162534b"></a><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练<a href="https://mlflow.org/docs/latest/tutorial.html#id6" target="_blank" rel="noopener">模型</a></h2>首先，训练一个带有两个超参数的线性回归模型：<code>alpha</code>和<code>l1_ratio</code>。</li>
</ul>
<p>代码位于以下<code>examples/sklearn_elasticnet_wine/train.py</code>并在下面复制。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality</span></span><br><span class="line"><span class="comment"># P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.</span></span><br><span class="line"><span class="comment"># Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error, r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> mlflow</span><br><span class="line"><span class="keyword">import</span> mlflow.sklearn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_metrics</span><span class="params">(actual, pred)</span>:</span></span><br><span class="line">    rmse = np.sqrt(mean_squared_error(actual, pred))</span><br><span class="line">    mae = mean_absolute_error(actual, pred)</span><br><span class="line">    r2 = r2_score(actual, pred)</span><br><span class="line">    <span class="keyword">return</span> rmse, mae, r2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">    np.random.seed(<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Read the wine-quality csv file (make sure you're running this from the root of MLflow!)</span></span><br><span class="line">    wine_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">"wine-quality.csv"</span>)</span><br><span class="line">    data = pd.read_csv(wine_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Split the data into training and test sets. (0.75, 0.25) split.</span></span><br><span class="line">    train, test = train_test_split(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The predicted column is "quality" which is a scalar from [3, 9]</span></span><br><span class="line">    train_x = train.drop([<span class="string">"quality"</span>], axis=<span class="number">1</span>)</span><br><span class="line">    test_x = test.drop([<span class="string">"quality"</span>], axis=<span class="number">1</span>)</span><br><span class="line">    train_y = train[[<span class="string">"quality"</span>]]</span><br><span class="line">    test_y = test[[<span class="string">"quality"</span>]]</span><br><span class="line"></span><br><span class="line">    alpha = float(sys.argv[<span class="number">1</span>]) <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0.5</span></span><br><span class="line">    l1_ratio = float(sys.argv[<span class="number">2</span>]) <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> mlflow.start_run():</span><br><span class="line">        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=<span class="number">42</span>)</span><br><span class="line">        lr.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line">        predicted_qualities = lr.predict(test_x)</span><br><span class="line"></span><br><span class="line">        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"Elasticnet model (alpha=%f, l1_ratio=%f):"</span> % (alpha, l1_ratio))</span><br><span class="line">        print(<span class="string">"  RMSE: %s"</span> % rmse)</span><br><span class="line">        print(<span class="string">"  MAE: %s"</span> % mae)</span><br><span class="line">        print(<span class="string">"  R2: %s"</span> % r2)</span><br><span class="line"></span><br><span class="line">        mlflow.log_param(<span class="string">"alpha"</span>, alpha)</span><br><span class="line">        mlflow.log_param(<span class="string">"l1_ratio"</span>, l1_ratio)</span><br><span class="line">        mlflow.log_metric(<span class="string">"rmse"</span>, rmse)</span><br><span class="line">        mlflow.log_metric(<span class="string">"r2"</span>, r2)</span><br><span class="line">        mlflow.log_metric(<span class="string">"mae"</span>, mae)</span><br><span class="line"></span><br><span class="line">        mlflow.sklearn.log_model(lr, <span class="string">"model"</span>)</span><br></pre></td></tr></table></figure>
<p>此示例使用熟悉的pandas，numpy和sklearn API来创建简单的机器学习模型。该<a href="https://mlflow.org/docs/latest/tracking.html" target="_blank" rel="noopener">MLflow跟踪的API</a>记录有关每次训练运行信息，如超参数<code>alpha</code>和<code>l1_ratio</code>，用于训练模型和指标，如均方根误差，用来评估模型。该示例还以MLflow知道如何部署的格式序列化模型。<br>您可以使用默认超参数运行示例，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python  examples/sklearn_elasticnet_wine/train.PY</span><br></pre></td></tr></table></figure>
<p>尝试一些其他的值<code>alpha</code>，并<code>l1_ratio</code>通过将它们作为参数传入<code>train.py</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python examples/sklearn_elasticnet_wine/train.py &lt;alpha&gt; &lt;l1_ratio&gt;</span><br></pre></td></tr></table></figure>
<p>每次运行该示例时，MLflow都会在目录中记录有关实验运行的信息<code>mlruns</code>。</p>
<blockquote>
<p>注意<br>如果您想使用Jupyter笔记本版本<code>train.py</code>，请尝试使用教程笔记本<code>examples/sklearn_elasticnet_wine/train.ipynb</code>。</p>
</blockquote>
<p><a name="9fe72089"></a></p>
<h2 id="比较模型"><a href="#比较模型" class="headerlink" title="比较模型"></a><a href="https://mlflow.org/docs/latest/tutorial.html#id7" target="_blank" rel="noopener">比较模型</a></h2><p>接下来，使用MLflow UI比较您生成的模型。在与包含<code>mlruns</code>运行的目录相同的当前工作目录中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow ui -h 0.0.0.0</span><br></pre></td></tr></table></figure>
<p>在此页面上，您可以看到实验运行列表，其中包含可用于比较模型的指标。<br><img src="https://cdn.nlark.com/yuque/0/2019/png/219582/1552619383275-64d84bcf-39a4-48a9-b35c-64a3282025bf.png#align=left&amp;display=inline&amp;height=367&amp;originHeight=527&amp;originWidth=1070&amp;size=0&amp;status=done&amp;width=746" alt></p>
<p><a name="05c86809"></a></p>
<h2 id="打包培训代码"><a href="#打包培训代码" class="headerlink" title="打包培训代码"></a><a href="https://mlflow.org/docs/latest/tutorial.html#id8" target="_blank" rel="noopener">打包培训代码</a><a href="https://mlflow.org/docs/latest/tutorial.html#packaging-the-training-code" target="_blank" rel="noopener"></a></h2><p>现在您已经拥有了培训代码，您可以对其进行打包，以便其他数据科学家可以轻松地重复使用该模型，或者您可以远程运行培训，例如在Databricks上。</p>
<p>您可以使用<a href="https://mlflow.org/docs/latest/projects.html" target="_blank" rel="noopener">MLflow Projects</a>约定来指定代码的依赖关系和入口点。该<code>tutorial/MLproject</code>文件指定项目具有位于 被调用的<a href="https://conda.io/docs/user-guide/tasks/manage-environments.html#creating-an-environment-file-manually" target="_blank" rel="noopener">Conda环境文件中</a>的依赖<code>conda.yaml</code>项，并且具有一个带有两个参数的入口点：<code>alpha</code>和<code>l1_ratio</code>。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tutorial/MLproject</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name:</span> <span class="string">tutorial</span></span><br><span class="line"></span><br><span class="line"><span class="attr">conda_env:</span> <span class="string">conda.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">entry_points:</span></span><br><span class="line"><span class="attr">  main:</span></span><br><span class="line"><span class="attr">    parameters:</span></span><br><span class="line"><span class="attr">      alpha:</span> <span class="string">float</span></span><br><span class="line"><span class="attr">      l1_ratio:</span> <span class="string">&#123;type:</span> <span class="string">float,</span> <span class="attr">default:</span> <span class="number">0.1</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">"python train.py &#123;alpha&#125; &#123;l1_ratio&#125;"</span></span><br></pre></td></tr></table></figure>
<p>Conda文件依赖项</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tutorial/conda.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name:</span> <span class="string">tutorial</span></span><br><span class="line"><span class="attr">channels:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">defaults</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">numpy=1.14.3</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pandas=0.22.0</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">scikit-learn=0.19.1</span></span><br><span class="line"><span class="attr">  - pip:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">mlflow</span></span><br></pre></td></tr></table></figure>
<p>要运行此项目，请调用<code>mlflow run tutorial -P alpha=0.42</code><br>如果存储库<code>MLproject</code>在根目录中有文件，您也可以直接从GitHub运行项目。本教程在您可以运行的。运行此命令后，MLflow将在具有指定依赖关系的新Conda环境中运行您的训练代码。<a href="https://github.com/mlflow/mlflow-example" target="_blank" rel="noopener">https://github.com/mlflow/mlflow-example</a>存储库中重复。<code>mlflow run git@github.com:mlflow/mlflow-example.git -P alpha=0.42</code></p>
<p><a name="146d11ee"></a></p>
<h2 id="服务模型"><a href="#服务模型" class="headerlink" title="服务模型"></a><a href="https://mlflow.org/docs/latest/tutorial.html#id9" target="_blank" rel="noopener">服务模型</a><a href="https://mlflow.org/docs/latest/tutorial.html#serving-the-model" target="_blank" rel="noopener"></a></h2><p>现在您已使用MLproject约定打包模型并确定了最佳模型，现在是时候使用<a href="https://mlflow.org/docs/latest/models.html" target="_blank" rel="noopener">MLflow模型</a>部署<a href="https://mlflow.org/docs/latest/models.html" target="_blank" rel="noopener">模型了</a>。MLflow模型是用于打包机器学习模型的标准格式，可用于各种下游工具 - 例如，通过REST API实时提供服务或在Apache Spark上进行批量推断。<br>在示例训练代码中，在训练线性回归模型之后，MLflow中的函数将模型保存为运行中的工件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow.sklearn.log_model(lr, <span class="string">"model"</span>)</span><br></pre></td></tr></table></figure>
<p>要查看此工件，您可以再次使用UI。当您单击实验运行列表中的日期时，您将看到此页面。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/219582/1552619764349-39a712fe-a675-4e68-8258-fcfec15858f3.png#align=left&amp;display=inline&amp;height=901&amp;originHeight=1333&amp;originWidth=1104&amp;size=0&amp;status=done&amp;width=746" alt>在底部，您可以看到调用<code>mlflow.sklearn.log_model</code>生成两个文件<code>/Users/mlflow/mlflow-prototype/mlruns/0/7c1a0d5c42844dcdb8f5191146925174/artifacts/model</code>。第一个文件<code>MLmodel</code>是一个元数据文件，告诉MLflow如何加载模型。第二个文件<code>model.pkl</code>是您训练的线性回归模型的序列化版本。<br>在此示例中，您可以将此MLmodel格式与MLflow一起使用，以部署可以提供预测的本地REST服务器。<br>要部署服务器，请运行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow pyfunc serve /Users/mlflow/mlflow-prototype/mlruns/0/7c1a0d5c42844dcdb8f5191146925174/artifacts/model -p 1234</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意<br>用于创建模型的Python版本必须与运行的版本相同。如果不是这种情况，您可能会看到错误 或。<code>mlflow sklearn`</code>UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0x9f in position 1: ordinal not in range(128)<code></code>raise ValueError, “unsupported pickle protocol: %d”`</p>
</blockquote>
<p>部署服务器后，您可以传递一些示例数据并查看预测。以下示例用于<code>curl</code>向<code>split</code>pyfunc服务器发送带有方向的JSON序列化pandas DataFrame 。有关pyfunc模型服务器接受的输入数据格式的更多信息，请参阅 <a href="https://mlflow.org/docs/latest/models.html#pyfunc-deployment" target="_blank" rel="noopener">MLflow部署工具文档</a>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-Type:application/json; format=pandas-split&quot; --data &apos;&#123;&quot;columns&quot;:[&quot;alcohol&quot;, &quot;chlorides&quot;, &quot;citric acid&quot;, &quot;density&quot;, &quot;fixed acidity&quot;, &quot;free sulfur dioxide&quot;, &quot;pH&quot;, &quot;residual sugar&quot;, &quot;sulphates&quot;, &quot;total sulfur dioxide&quot;, &quot;volatile acidity&quot;],&quot;data&quot;:[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]&#125;&apos; http://127.0.0.1:1234/invocations</span><br></pre></td></tr></table></figure>
<p>服务器应该响应输出类似于：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;predictions&quot;: [6.379428821398614]&#125;</span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/03/15/yuque/Mlflow介绍/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/31/yuque/我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？/">我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？</a>
    </h1>
  

        
        <a href="/2019/01/31/yuque/我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？/" class="archive-article-date">
  	<time datetime="2019-01-31T10:12:24.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-01-31</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a name="b4699b6e"></a></p>
<h1 id="我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？"><a href="#我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？" class="headerlink" title="我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？"></a>我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？</h1><p><a href="https://medium.com/@jonathan_hui" target="_blank" rel="noopener">乔纳森惠</a>以下<br>2018年3月28日<br>在本系列中，我们将全面介绍物体检测。在这里的第1部分中，我们介绍了基于区域的物体探测器，包括快速R-CNN，更快的R-CNN，R-FCN和FPN。在第2部分中，我们将研究单射击探测器。在第3部分中，我们将介绍性能和一些实现问题。通过在一个环境中研究它们，我们研究什么是有效的，什么是重要的，哪些可以改进。希望通过研究我们如何到达这里，它将为我们提供更多关于我们前进方向的见解。<br><a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9" target="_blank" rel="noopener">第1部分</a>：我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？<br><a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d" target="_blank" rel="noopener">第2部分</a>：我们从单发物体探测器（SSD，YOLO），FPN和焦点损耗中学到了什么？<br><a href="https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff" target="_blank" rel="noopener">第3部分</a>：设计选择，经验教训和对象检测趋势？<br><a name="43bb065b"></a></p>
<h3 id="滑动窗口探测器"><a href="#滑动窗口探测器" class="headerlink" title="滑动窗口探测器"></a><strong>滑动窗口探测器</strong></h3><p>自AlexNet赢得2012年ILSVRC挑战以来，使用CNN进行分类已经占据了该领域的主导地位。用于物体检测的一种蛮力方法是从左侧和右侧以及从上到下滑动窗口以使用分类来识别物体。为了在不同的观察距离检测不同的物体类型，我们使用不同尺寸和纵横比的窗户。</p>
<p>滑动窗（从右到左，上下）<br>我们根据滑动窗口从图片中剪切出补丁。由于许多分类器仅采用固定大小的图像，因此修补程序会发生扭曲。然而，这不应该影响分类准确性，因为分类器被训练以处理变形图像。</p>
<p>将图像变形为固定大小的图像。<br>将扭曲的图像块馈送到CNN分类器中以提取4096个特征。然后我们应用SVM分类器来识别类和边界框的另一个线性回归量。</p>
<p>滑动窗检测器的系统流程。<br>下面是伪代码。我们创建了许多窗口来检测不同位置的不同对象形状。为了提高性能，一个明显的解决方案是减少_窗口_数量。<br>窗口中的窗口<br>    patch = get_patch（图像，窗口）<br>    结果=检测器（补丁）<a name="68696ce0"></a></p>
<h3 id="选择性搜索"><a href="#选择性搜索" class="headerlink" title="选择性搜索"></a>选择性搜索</h3><p>我们使用区域提议方法来创建用于对象检测的<strong>感兴趣区域（ROI）</strong>，而不是强力方法。在<strong>选择性搜索</strong>（<strong>SS</strong>）中，我们从每个单独的像素开始作为其自己的组。接下来，我们计算每个组的纹理，并组合两个最接近的组。但是为了避免单个区域吞噬其他区域，我们更喜欢先将较小的组分组。我们继续合并区域，直到所有内容组合在一起。在下面的第一行中，我们展示了如何增长区域，第二行中的蓝色矩形显示了我们在合并期间可能实现的ROI。</p>
<p>（图片来源：van de Sande等，ICCV’11）<br><a name="R-CNN"></a></p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><p>R-CNN利用区域提议方法来创建大约2000个<strong>ROI</strong>（<strong>感兴趣</strong>的区域）。区域被扭曲成固定大小的图像并单独馈送到CNN网络。然后是完全连接的层，以对对象进行分类并细化边界框。</p>
<p>使用区域提议，CNN，仿射层来定位对象。<br>这是系统流程。</p>
<p>R-CNN的系统流程<br>R-CNN的投资回报率低得多但质量更高，比滑动窗更快，更准确。<br>投资回报率= <br>ROI中投资回报率的区域提示（图像）<br>    补丁= get_patch（图像，投资回报率）<br>    结果=检测器（补丁）<a name="9d7dcb56"></a></p>
<h4 id="边界框回归量"><a href="#边界框回归量" class="headerlink" title="边界框回归量"></a>边界框回归量</h4><p>区域提案方法计算密集。为了加快这一过程，我们经常选择一种较便宜的区域建议方法来创建ROI，然后使用线性回归量（使用完全连接的层）进一步细化边界框。</p>
<p>使用回归将原始ROI从蓝色细化为红色。<br><a name="02b68898"></a></p>
<h3 id="快速R-CNN"><a href="#快速R-CNN" class="headerlink" title="快速R-CNN"></a>快速R-CNN</h3><p>R-CNN需要许多提议准确并且许多区域彼此重叠。<strong>R-CNN的训练和推理速度很慢。</strong>如果我们有2,000个提案，则每个提案都由CNN单独处理，即我们针对不同的投资回报率重复提取2000次特征。<br>我们不是从头开始为每个图像补丁提取特征，而是使用<strong>特征提取器</strong>（CNN）首先提取整个图像的特征。我们还使用外部区域提议方法（如选择性搜索）来创建ROI，后者与相应的要素图组合以形成用于对象检测的补丁。我们使用<strong>ROI池</strong>将贴片扭曲到固定大小，并将它们馈送到完全连接的层以进行分类和<strong>定位</strong>（检测对象的位置）。通过不重复特征提取，Fast R-CNN显着缩短了处理时间。</p>
<p>在要素图上应用区域建议，并使用ROI池形成固定大小的修补程序。<br>这是网络流程：</p>
<p>在下面的伪代码中，昂贵的特征提取正在逐渐退出for循环，这是因为它针对所有2000个ROI执行而显着提高了速度。快速R-CNN在训练中比R-CNN快10倍，在推理中快150倍。<br>feature_maps = process（image）<br>ROI = <br>ROI中ROI的region_proposal（image）<br>    补丁= roi_pooling（feature_maps，ROI）<br>    结果= detector2（补丁）Fast R-CNN的一个主要特点是整个网络（特征提取器，分类器和边界框回归器）可以通过<strong>多任务损失</strong>（分类丢失和本地化丢失）进行端到端训练。这提高了准确性。<br><strong>投资回报率</strong><br>由于Fast R-CNN使用完全连接的层，因此我们应用<strong>ROI池</strong>来将可变大小的ROI扭曲成预定义的大小形状。<br>让我们通过将8×8特征映射转换为预定义的2×2形状来简化讨论。</p>
<ul>
<li>左下方：我们的功能图。</li>
<li>右上角：我们将ROI（蓝色）与要素图重叠。</li>
<li>左下图：我们将ROI分成目标维度。例如，对于我们的2×2目标，我们将ROI分成4个具有相似或相同大小的部分。</li>
<li>右下角：找到每个部分的最大值，结果是我们的变形特征映射。</li>
</ul>
<p>输入要素图（左上），输出要素图（右下），蓝框是ROI（右上）。<br>因此，我们得到一个2×2特征补丁，我们可以将其输入分类器和盒子回归器。<br><a name="1f096ba3"></a></p>
<h3 id="更快的R-CNN"><a href="#更快的R-CNN" class="headerlink" title="更快的R-CNN"></a>更快的R-CNN</h3><p>快速R-CNN依赖于外部区域提议方法，如选择性搜索。但是，这些算法在CPU上运行并且速度很慢。在测试中，快速R-CNN花费2.3秒进行预测，其中2秒用于生成2000个ROI。<br>feature_maps = process（image）<br>ROIs = region_proposal（image）＃贵！<br>投资回报率中的ROI <br>    补丁= roi_pooling（feature_maps，ROI）<br>    结果= detector2（补丁）更快的R-CNN采用与快速R-CNN类似的设计，除了它用内部深度网络替换区域提议方法，而ROI则来自特征映射。新区域提案网络（<strong>RPN</strong>）更高效，并且在生成ROI时每个映像运行10毫秒。</p>
<p>网络流量与Fast R-CNN相同。<br>网络流程类似，但区域提案现在由卷积网络（RPN）取代。</p>
<p>外部区域提议由内部深层网络取代。<br><strong>区域提案网络</strong><br>区域提议网络（<strong>RPN</strong>）将来自第一个卷积网络的输出特征映射作为输入。它在特征映射上滑动3×3过滤器，以使用像ZF网络这样的卷积网络（下面）进行类别无关区域提议。其他深度网络如VGG或ResNet可用于以速度为代价进行更全面的特征提取。ZF网络输出256个值，这些值被馈送到2个单独的完全连接的层中以预测边界框和2个对象性得分。该<strong>对象性</strong>测量框是否包含对象。我们可以使用回归量来计算单个对象度得分但是为了简单起见，更快的R-CNN使用具有2个可能类的分类器：一个用于“具有对象”类别而一个用于没有（即背景类别）。</p>
<p>对于要素图中的每个位置，RPN进行<strong>k</strong>猜测。因此，RPN每个位置输出4×k坐标和2×k分数。下图显示了具有3×3滤波器的8×8特征图，并且它输出总共8×8×3个ROI（对于k = 3）。右侧图表显示了单个位置提出的3个提案。</p>
<p>在这里，我们得到3个猜测，我们稍后会改进我们的猜测。由于我们只需要一个正确的，如果我们的初步猜测有不同的形状和大小，我们会更好。因此，更快的R-CNN不会提出随机边界框提议。相反，它预测像δx，δy这样的偏移相对于一些称为<strong>锚点的</strong>参考框的左上角。我们限制了那些偏移的值，所以我们的猜测仍然类似于锚点。</p>
<p>为了对每个位置进行k个预测，我们需要以每个位置为中心的k个锚点。每个预测与特定锚相关联，但不同位置共享相同的锚形状。</p>
<p>这些锚是经过精心预先选择的，因此它们是多样的，能够很好地覆盖不同尺度和纵横比的真实物体。这可以通过更好的猜测指导初始训练，并允许每个预测专注于某种形状。这种策略使早期训练更加稳定和轻松。<br>更快的R-CNN使用更多的锚点。它配置了9个锚箱：3种不同的比例，3种不同的宽高比。每个位置使用9个锚点，每个位置生成2×9个对象度分数和4×9个坐标。</p>
<p><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noopener">资源</a></p>
<blockquote>
<p><strong>锚</strong>在不同的论文中也称为&gt; <strong>先验</strong>或&gt; <strong>默认边界框</strong>。<br><a name="89dc102d"></a></p>
</blockquote>
<h3 id="R-CNN方法的性能"><a href="#R-CNN方法的性能" class="headerlink" title="R-CNN方法的性能"></a>R-CNN方法的性能</h3><p>如下图所示，更快的R-CNN甚至更快。</p>
<p><a name="1c4a83c6"></a></p>
<h3 id="基于区域的完全卷积网络（R-FCN）"><a href="#基于区域的完全卷积网络（R-FCN）" class="headerlink" title="基于区域的完全卷积网络（R-FCN）"></a>基于区域的完全卷积网络（R-FCN）</h3><p>假设我们只有一个特征图检测到脸部的右眼。我们可以用它来定位一张脸吗？这应该。由于右眼应位于面部图片的左上角，我们可以使用它来定位面部。</p>
<p>如果我们有专门检测左眼，鼻子或嘴巴的其他特征图，我们可以将结果组合在一起以更好地定位脸部。<br>那么我们为什么要经历所有麻烦呢。在更快的R-CNN中，<em>探测器</em>应用多个完全连接的层来进行预测。拥有2,000个投资回报率，价格昂贵。<br>feature_maps =处理（图像）<br>的ROI = region_proposal（feature_maps）<br>用于在感兴趣区ROI <br>    补丁= roi_pooling（feature_maps，ROI）<br>    class_scores，盒=检测器（贴片）＃昂贵！<br>    class_probabilities = softmax（class_scores）R-FCN通过减少每个ROI所需的工作量来提高速度。上面的基于区域的特征图与ROI无关，并且可以在每个ROI之外计算。剩下的工作要简单得多，因此R-FCN比快速R-CNN更快。<br>feature_maps = process（image）<br>ROIs = region_proposal（feature_maps）          <br>score_maps = compute_score_map（feature_maps）<br>ROI中的ROI <br>    V = region_roi_pool（score_maps，ROI）      <br>    class_scores，box = average（V）＃更简单！<br>    class_probabilities = softmax（class_scores）让我们考虑一个5×5的特征映射<strong>M</strong>，里面有一个蓝色方形对象。我们将方形对象平均分成3×3个区域。现在，我们从M创建一个新的特征图，仅检测正方形的左上角（TL）。新功能图看起来像右下方的那个。仅激活黄色<strong>网格单元</strong> [2,2]。</p>
<p>从左侧创建新的要素图以检测对象的左上角。<br>由于我们将正方形划分为9个部分，我们可以创建9个特征映射，每个特征映射检测对象的相应区域。这些特征图称为<strong>位置敏感分数图，</strong>因为每个图检测（分数）对象的子区域。</p>
<p>生成9个得分图<br>假设下面的虚线红色矩形是建议的ROI。我们将其划分为3×3个区域，并询问每个区域包含对象的相应部分的可能性。例如，左上角ROI区域包含左眼的可能性有多大。我们将结果存储在右图中的3×3投票数组中。例如，vote_array [0] [0]包含关于我们是否找到方形对象的左上角区域的分数。</p>
<p>将ROI应用于要素图以输出3 x 3阵列。<br>将得分图和ROI映射到投票数组的过程称为<strong>位置敏感的</strong> <strong>ROI池</strong>。这个过程非常接近我们之前讨论过的ROI池。我们不会进一步介绍它，但您可以参考未来的阅读部分以获取更多信息。</p>
<p>将ROI的一部分叠加到相应的得分图上以计算V [i] [j]<br>计算位置敏感ROI池的所有值后，类别分数是其所有元素的平均值。</p>
<p>投资回报率池<br>假设我们有<strong>C</strong>类要检测。我们将它扩展为C + 1类，因此我们为背景（非对象）添加了一个新类。每个班级都有自己的3×3分数图，因此总共有（C + 1）×3×3分数图。使用自己的一组得分图，我们预测每个班级的班级得分。然后我们在这些分数上应用softmax来计算每个类的概率。<br>以下是数据流。对于我们的例子，我们下面有k = 3。</p>
<p><a name="f64e8873"></a></p>
<h3 id="我们的旅程到目前为止"><a href="#我们的旅程到目前为止" class="headerlink" title="我们的旅程到目前为止"></a>我们的旅程到目前为止</h3><p>我们从基本的滑动窗口算法开始。<br>窗口中的窗口<br>    patch = get_patch（图像，窗口）<br>    结果=检测器（补丁）然后我们尝试减少窗口的数量，并在for循环之外移动尽可能多的工作。<br>投资回报率= <br>ROI中投资回报率的区域提示（图像）<br>    补丁= get_patch（图像，投资回报率）<br>    结果=检测器（补丁）在<a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d" target="_blank" rel="noopener">第2部分中</a>，我们进一步完全删除了for循环。单发探测器可在单次射击中进行物体探测，无需单独的区域建议步骤。<br><a name="b4412bfb"></a></p>
<h3 id="进一步阅读FPN，R-FCN和Mask-R-CNN"><a href="#进一步阅读FPN，R-FCN和Mask-R-CNN" class="headerlink" title="进一步阅读FPN，R-FCN和Mask R-CNN"></a>进一步阅读FPN，R-FCN和Mask R-CNN</h3><p>FPN和R-FCN都比我们在此描述的更复杂。如需进一步研究，请参阅：</p>
<ul>
<li><a href="https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c" target="_blank" rel="noopener">用于对象检测的特征金字塔网络（FPN）。</a></li>
<li><a href="https://medium.com/@jonathan_hui/understanding-region-based-fully-convolutional-networks-r-fcn-for-object-detection-828316f07c99" target="_blank" rel="noopener">基于区域的完全卷积网络（R-FCN）</a>。</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/01/31/yuque/我们从基于区域的物体探测器（更快的R-CNN，R-FCN，FPN）中学到了什么？/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/Kaggle＃1获胜图像分类挑战方法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/21/yuque/Kaggle＃1获胜图像分类挑战方法/">Kaggle＃1获胜图像分类挑战方法</a>
    </h1>
  

        
        <a href="/2018/12/21/yuque/Kaggle＃1获胜图像分类挑战方法/" class="archive-article-date">
  	<time datetime="2018-12-21T09:03:34.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545383030520-f6dbd874-48b5-4066-bacc-bae58fd00765.png#width=826" alt><br>这篇文章是关于我用于Kaggle竞赛的方法：<a href="https://www.kaggle.com/c/plant-seedlings-classification" target="_blank" rel="noopener">植物幼苗分类。</a>我在排名中排名第一，持续了几个月，最终在最终评估结束时以＃5结束。该方法非常通用，也可用于其他图像识别任务。</p>
<blockquote>
<p><strong>Kaggle</strong>是一个&gt; <a href="https://en.wikipedia.org/wiki/Predictive_modelling" target="_blank" rel="noopener">预测建模</a>和&gt; <a href="https://en.wikipedia.org/wiki/Analytics" target="_blank" rel="noopener">分析</a>竞赛的平台，统计人员和数据挖掘者在竞争中生成预测和描述公司和用户上传的数据集的最佳模型。这种&gt; <a href="https://en.wikipedia.org/wiki/Crowdsourcing" target="_blank" rel="noopener">众包</a>方法依赖于这样一个事实：无数的策略可以应用于任何预测建模任务，并且不可能事先知道哪种技术或分析师最有效。[1]<br>另外，请查看在NLP上获得<strong>Intent Classification</strong>任务的最新<strong>成果</strong>的博客：</p>
</blockquote>
<p><a href="https://medium.com/@shridhar743/know-your-intent-sota-results-in-intent-classification-8e1ca47f364c" target="_blank" rel="noopener">了解您的意图：SoTA结果意图分类<br>此博客文章显示了在三个语料库上获得的最新最新结果：medium.com</a></p>
<hr>
<p><a name="a9de"></a></p>
<h3 id="任务概述"><a href="#任务概述" class="headerlink" title="任务概述"></a><a href="#a9de"></a>任务概述</h3><p>你可以区分杂草和农作物幼苗吗？<br>有效地这样做的能力可以意味着更好的作物产量和更好的环境管理。</p>
<p>所述<strong>奥尔胡斯大学信号处理</strong>组，在具有协作<strong>南丹麦大学</strong>，释放含有属于12种约960独特的植物的图像数据集在几个生长阶段。[1] [2]<br><img src="https://cdn-images-1.medium.com/max/1000/1*g_zIn9WVdJHCN2dfEV0X_A.png#width=" alt><br><em>其中一个样本植物：鹅肠菜样本[3]</em></p>
<p>公开可获得在几个生长阶段属于12种物种的约960种独特植物的图像数据库。它包括带注释的RGB图像，物理分辨率约为每毫米10个像素。</p>
<p>为了使用数据库获得的分类结果的评估标准化，提出了基于F1分数的基准。该<a href="https://vision.eng.au.dk/plant-seedlings-dataset/" target="_blank" rel="noopener">URL</a>提供了数据集[13]</p>
<p>下图是描述数据集中所有12个类的示例：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545383065394-724bbdf8-bb85-4775-8661-8df88480e85d.png#width=826" alt></p>
<p><a name="aed6"></a></p>
<h4 id="将图像分类为各个类的任务，任务分为5个步骤："><a href="#将图像分类为各个类的任务，任务分为5个步骤：" class="headerlink" title="将图像分类为各个类的任务，任务分为5个步骤："></a><a href="#aed6"></a>将图像分类为各个类的任务，任务分为5个步骤：</h4><p><a name="d486"></a></p>
<h3 id="步骤1："><a href="#步骤1：" class="headerlink" title="步骤1："></a><a href="#d486"></a>步骤1：</h3><p>机器学习中的第一个也是最重要的任务是在继续任何算法之前分析数据集。这对于理解数据集的复杂性非常重要，这最终将有助于设计算法。</p>
<p>图像和类的分布如下：<br><img src="https://cdn-images-1.medium.com/max/1000/1*axNbDRk6whrwE29zDafAJQ.png#width=" alt><br>如前所述，共有12个类，总共有4750个图像。然而，如上所述，分布不均匀，并且类别分布从最大654个图像变化到最小221个图像。这清楚地表明数据不平衡，数据需要平衡才能获得最佳结果。我们将在第<strong>3</strong>步中讨论这个问题。</p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*V5C9piJvHcsV-dqLuVpOPQ.png#width=" alt>每班的图像分发</p>
<p>现在，将图像可视化以便更好地理解数据非常重要。因此，显示来自每个类的一些样本图像以便查看图像彼此之间的差异。<br><img src="https://cdn-images-1.medium.com/max/1000/1*phgfJG3mycgz8BGlA9Jj9Q.png#width=" alt><br>从上面的图像中可以理解的是，所有图像看起来都非常相似。所以，我决定使用称为<a href="https://lvdmaaten.github.io/tsne/" target="_blank" rel="noopener">t-Distributed随机邻居嵌入</a>（t-SNE）的可视化技术来看图像<a href="https://lvdmaaten.github.io/tsne/" target="_blank" rel="noopener">的分布</a>。<br>t分布式随机邻域嵌入（t-SNE）是一种降维的技术，特别适用于高维数据集的可视化。该技术可以通过Barnes-Hut近似实现，允许它应用于大型真实世界的数据集。[14]<br><img src="https://cdn-images-1.medium.com/max/1000/1*HK33kGhDF43ZAKrROxoKWA.png#width=" alt>数据集的t-SNE可视化</p>
<p>仔细观察之后，我们很难看出课程的差异。因此，重要的是要了解数据是否很难仅仅为人类区分，或者机器学习模型也很难。所以，我们将为它做一个基本的基准测试。</p>
<p><a name="12da"></a></p>
<h4 id="培训和验证集"><a href="#培训和验证集" class="headerlink" title="培训和验证集"></a><a href="#12da"></a>培训和验证集</h4><p>在开始使用模型基准测试之前，我们需要将数据划分为训练和验证数据集。在原始测试集上测试模型之前，验证集将扮演测试数据集的角色。因此，基本上在训练数据集上训练模型并在验证集上进行测试，然后随着时间的推移可以在验证集上改进模型。一旦我们对验证集的结果感到满意，我们就可以在真实的测试数据集上应用该模型。通过这种方式，我们可以看到模型是否过度拟合或欠拟合我们的验证集，这可以帮助我们更好地拟合模型。</p>
<p>因此，我们通过将80％的图像保留为训练数据集并将20％的图像保持为验证集来划分4750个图像的数据集。</p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*0h-aFSLtqVvTl4XpWWSRMQ.png#width=" alt>培训和验证数据分开<br><a name="1608"></a></p>
<h3 id="第2步："><a href="#第2步：" class="headerlink" title="第2步："></a><a href="#1608"></a>第2步：</h3><p>一旦我们获得了培训和验证集，我们将从数据集的基准测试开始。我们可以看到这是一个分类问题，在给出测试数据集时，我们需要将其分类为12个类中的一个。所以我们将使用<strong>卷积神经网络</strong>来完成任务。<br>如果您是初学者并且需要更好地理解深度学习术语，请访问以下&gt; <a href="https://medium.com/@shridhar743/a-beginners-guide-to-deep-learning-5ee814cf7706" target="_blank" rel="noopener">博客：</a></p>
<p>有几种方法可以创建CNN模型，但对于第一个基准测试，我们将使用<a href="https://keras.io/" target="_blank" rel="noopener">Keras深度学习库</a>。我们还将使用Keras中可用的预训练模型，通过ImageNet数据集进行训练，我们将根据我们的任务对其进行微调。</p>
<p>从头开始训练卷积神经网络几乎实际上是低效的。因此，我们在ImageNet上使用预先训练的CNN模型的权重，使用1000个类，并通过保持一些层冻结并解冻其中一些并对其进行训练来对其进行微调。这是因为顶层学习简单的基本功能，我们不需要训练这些层，它可以直接应用于我们的任务。需要注意的一件重要事情是我们需要检查我们的数据集是否与ImageNet类似，以及我们的数据集有多大。这两个功能将决定我们如何执行微调。要了解更多详情，请阅读<a href="https://medium.com/@karpathy" target="_blank" rel="noopener">Andrej Karpathy</a>的博客：</p>
<p><a href="http://cs231n.github.io/transfer-learning/" target="_blank" rel="noopener">用于视觉识别的CS231n卷积神经网络用于<br>斯坦福类CS231n的课程材料和注释：用于视觉识别的卷积神经网络。cs231n.github.io</a></p>
<p>在我们的例子中，数据集很小但有点类似于ImageNet。因此，我们可以直接使用ImageNet的权重，只需添加一个包含12个类的最终输出层即可查看第一个基准测试。然后我们将解除一些底层的解冻，然后训练这些层。</p>
<p>我们将使用Keras作为初始基准，因为Keras提供了许多预训练模型，我们将使用ResNet50和InceptionResNetV2来完成我们的任务。使用一个简单模型和一个非常高端模型对数据集进行基准测试非常重要，以了解我们是否过度拟合/不适合给定模型上的数据集。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/21/yuque/Kaggle＃1获胜图像分类挑战方法/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/Capsule Networks：一种全新且极具吸引力的AI架构" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/21/yuque/Capsule Networks：一种全新且极具吸引力的AI架构/">Capsule Networks：一种全新且极具吸引力的AI架构</a>
    </h1>
  

        
        <a href="/2018/12/21/yuque/Capsule Networks：一种全新且极具吸引力的AI架构/" class="archive-article-date">
  	<time datetime="2018-12-21T07:02:37.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://heartbeat.fritz.ai/capsule-networks-a-new-and-attractive-ai-architecture-bd1198cc8ad4" target="_blank" rel="noopener">链接</a><br><a name="481b"></a></p>
<h2 id="本文已被翻译成英文并首次发表于Deep-Learning-Turkey-。"><a href="#本文已被翻译成英文并首次发表于Deep-Learning-Turkey-。" class="headerlink" title="本文已被翻译成英文并首次发表于Deep Learning Turkey_。_"></a><a href="#481b"></a><em>本文已被翻译成英文并首次发表于</em><a href="https://medium.com/deep-learning-turkiye/yapay-zekan%C4%B1n-yeni-ve-%C3%A7ekici-mimarisi-kaps%C3%BCl-a%C4%9F%C4%B1na-uygulamal%C4%B1-bir-bak%C4%B1%C5%9F-ef7310e3d847" target="_blank" rel="noopener">Deep Learning Turkey</a>_。_</h2><p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545375946092-dea95dae-971e-4274-a86b-98c17c3ee82a.png#width=826" alt><br><a href="https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed" target="_blank" rel="noopener">卷积神经网络</a>（CNN）在计算机视觉应用中经常是首选，因为它们在对象识别和分类任务上取得了成功。CNN由堆叠在一起的许多神经元组成。计算跨神经元的卷积需要大量计算，因此池化过程通常用于减小网络层的大小。卷积方法可以通过简单的计算学习数据的许多复杂特征。通过对我们的输入执行许多矩阵乘法和求和，我们可以得出我们问题的答案。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545375976729-c04cb9d8-3367-460d-87bb-a85c2e57ac26.png#width=665" alt></p>
<p><strong><em>我总是听到CNN有多棒。什么时候失败？</em></strong></p>
<p>CNN在解决对象识别和分类问题方面取得了巨大成功。但是，它们并不完美。如果CNN显示的方向对象不熟悉，或者对象出现在不习惯的位置，则预测任务可能会失败。</p>
<p>例如，如果您将一张脸倒置，网络将无法再识别眼睛，鼻子，嘴巴以及两者之间的空间关系。同样，如果你改变了脸部的特定区域（即切换眼睛和鼻子的位置），网络将能够识别脸部，但它不再是真实的脸部。CNN学习图像中的统计模式，但是他们没有学习关于什么使事物看起来像脸的基本概念。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545376002462-0627f195-0f85-4cd8-a27c-fbd4ecd9ea94.png#width=826" alt><br>关于为什么CNN无法学习概念的理论，_AI_之_父_<strong>Geoffrey Hinton</strong>专注于用于缩小网络规模和计算要求的池化操作。他感叹道：</p>
<blockquote>
<p><em>“在卷积神经网络中使用的池化操作是一个很大的错误，它运作良好的事实是一场灾难！”</em><br>汇集层正在破坏信息，使网络无法学习更高级别的概念。所以他开始着手开发一种新的架构，这种架构并没有过多地依赖于这种操作。</p>
</blockquote>
<p><strong>结果：胶囊网络</strong><br><a name="9d89"></a></p>
<h3 id="什么是胶囊网络？"><a href="#什么是胶囊网络？" class="headerlink" title="什么是胶囊网络？"></a><a href="#9d89"></a>什么是胶囊网络？</h3><p>Hinton和Sabour借鉴了神经科学的观点，认为大脑被组织成称为<strong><em>胶囊的</em></strong>模块。这些胶囊特别擅长处理物体的特征，如姿势（位置，大小，方向），变形，速度，反照率，色调，纹理等。</p>
<p>理论上，大脑必须有一种机制，用于<strong>_将_</strong>低级视觉信息<strong>_路由_</strong>到它认为最适合处理它的胶囊。已经提出了<strong>胶囊网络</strong>和<strong>动态路由算法</strong>作为卷积神经网络模型不充分的问题的解决方案。</p>
<p><img src="https://cdn-images-1.medium.com/max/750/1*y9RmBVmzKY63CET4LYRcUA.png#width=" alt><br><a href="https://www.wikiart.org/en/pablo-picasso/untitled-1937-8" target="_blank" rel="noopener">Portrait de femme au col d`hermine（奥尔加）</a></p>
<p>胶囊表示图像中存在的特定实体的各种特征。一个非常特殊的特征是图像中存在实例化的实体。实例化的实体是一个参数，如位置，大小，方向，变形，速度，反照率，色调，纹理等。表示其存在的一种显而易见的方法是使用一个单独的逻辑单元，其输出是实体存在的概率[ <a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank" rel="noopener">1</a> ]。为了获得比CNN更好的结果，我们应该使用迭代<strong>路由协议</strong>机制。这些功能称为<strong>实例化参数</strong>。在经典CNN模型中，不能获得图像中对象的这种属性。平均/最大池化层减小了一组信息的大小，同时减小了大小。</p>
<blockquote>
<p><strong>好吧，某处有一个嘴唇，鼻子和眼睛，但卷积神经网络无法决定它应该在哪里以及它在哪里。</strong> &gt; <strong>对于传统的网络，错位的功能不会让它失望！</strong></p>
</blockquote>
<p><a name="65d9"></a></p>
<h3 id="壁球功能"><a href="#壁球功能" class="headerlink" title="壁球功能"></a><a href="#65d9"></a>壁球功能</h3><p><a name="q16xns"></a></p>
<h4 id="壁球功能-1"><a href="#壁球功能-1" class="headerlink" title="壁球功能"></a><a href="#q16xns"></a><img src="https://cdn-images-1.medium.com/max/750/1*b3unKamre_roNMTS7H_6EA.png#width=" alt>壁球功能</h4><p>在深度神经网络中，激活函数是应用于层输出的简单数学运算。它们用于近似存在于数据中的非线性关系。激活层通常作用于标量值 - 例如，对向量中的每个元素进行标准化，使其落在0和1之间。<br>在Capsule Networks中，一种称为<em>squash函数</em>的特殊类型的激活函数用于归一化向量的大小，而不是标量元素本身。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545376097052-2994fe87-934e-4515-9a1b-7187e3ac549d.png#width=826" alt></p>
<p><a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank" rel="noopener">协议路由算法</a><br>这些壁球功能的输出告诉我们如何通过训练学习不同概念的各种胶囊来路由数据。图像中每个对象的属性在路由它们的向量中表示。例如，脸部的激活可以将图像的不同部分路由到理解眼睛，鼻子，嘴巴和耳朵的胶囊。<br><a name="d0f9"></a></p>
<h3 id="胶囊网络在MNIST数据集中的应用"><a href="#胶囊网络在MNIST数据集中的应用" class="headerlink" title="胶囊网络在MNIST数据集中的应用"></a><a href="#d0f9"></a>胶囊网络在MNIST数据集中的应用</h3><p><img src="https://cdn-images-1.medium.com/max/1000/0*EXnVG4QgSdxLBt0g.png#width=" alt><a href="http://www.machinelearningtutorial.net/2018/01/11/dynamic-routing-between-capsules-a-novel-architecture-for-convolutional-neural-networks/" target="_blank" rel="noopener">由胶囊网络执行的角度估计</a></p>
<p><strong><em>现在，下一步至关重要：</em></strong></p>
<p>就像不同层次的深层CNN中的层学习图像的不同语义属性（内容，纹理，样式等）一样，胶囊也可以组织成不同的层次。在一个级别的胶囊进行预测，了解物体的形状，并将它们传递给更高级别的胶囊，这些胶囊可以了解方向。当多个预测一致时，更高级别的预测变得活跃。<a href="https://www.ijcai.org/Proceedings/81-2/Papers/019.pdf" target="_blank" rel="noopener">此过程被描述为动态路由，我现在将更详细地讨论。</a></p>
<p><strong><em>那么，让我们创建一个逐步的胶囊架构来分类MNIST数据集：</em></strong></p>
<p>第一层有一个经典的卷积层。在第二层中，在称为<em>主要胶囊</em>的层中执行卷积处理，其中应用该<code>squash</code>函数。每个主要胶囊接收图像的一个小区域作为输入（称为其感受野），并且它试图检测特定图案的存在和姿势 - 例如，圆圈。</p>
<p>更高层中的胶囊（称为路由胶囊）检测更大和更复杂的对象，例如数字8，由两个圆圈组成。然后他们使用一种新颖的挤压功能来保证这些矢量的长度在0到1之间。</p>
<p>在主胶囊层之前施加标准卷积层，并获得9×9×256的输出。在主胶囊层中应用具有32个通道的新卷积过程，步幅为2.然而，将其与其他卷积过程分开的这个特征是压缩的功能。最后，这给出了主要胶囊的输出。</p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*ih6faUAZq9rhpo8sOFKYSw.gif#width=" alt><a href="https://medium.freecodecamp.org/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc" target="_blank" rel="noopener">初级胶囊的卷积过程</a></p>
<p>这提供了6x6输出。然而，在胶囊层中，实现动态路由算法，使得这些8长度输出DigitCaps向量的32个输出由于具有第三层动态路由的胶囊层而获得（逐协议路由算法） 。逐协议算法包括协议（检测和路由）更新的几次迭代。</p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*k29n44uHy_rrfgKO2qLvGQ.png#width=" alt><a href="https://medium.freecodecamp.org/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc" target="_blank" rel="noopener">Capulel层</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span>  <span class="title">CapsNet</span>（<span class="title">input_shape</span>，<span class="title">n_class</span>，<span class="title">num_routing</span>）：</span></span><br><span class="line"><span class="function">    “””</span></span><br><span class="line"><span class="function">    胶囊网络的<span class="title">MNIST</span>数据集。</span></span><br><span class="line"><span class="function">       ：“<span class="title">input_shape</span>”参数：<span class="title">vdata</span>形状，3<span class="title">d</span>，[<span class="title">w</span>，<span class="title">h</span>，<span class="title">c</span>]</span></span><br><span class="line"><span class="function">       ：“<span class="title">n_class</span>”参数：类的数量</span></span><br><span class="line"><span class="function">       ：“<span class="title">num_routing</span>”参数：动态路由迭代次数</span></span><br><span class="line"><span class="function">       ：功能输出：两个<span class="title">Keras</span>模型，第一个用于训练，第二个用于<span class="title">evalaution</span>。</span></span><br><span class="line"><span class="function">            `<span class="title">eval_model</span>`用于同时进行训练。</span></span><br><span class="line"><span class="function">    “””</span></span><br><span class="line">    X = layers.Input（形状= input_shape）</span><br><span class="line"></span><br><span class="line">    ＃ <span class="number">1</span>层：卷积层（Conv2D）</span><br><span class="line">    器CONV1 = layers.Conv2D（过滤器= <span class="number">256</span>，kernel_size = <span class="number">9</span>，步幅= <span class="number">1</span>，填充= <span class="string">'有效'</span>，活化= <span class="string">' RELU '</span>，名字= <span class="string">' CONV1 '</span>）（x）的</span><br><span class="line"></span><br><span class="line">    ＃ <span class="number">2</span>层：Conv2D壁球活化，[无，num_capsule，dim_capsule]来回整形。</span><br><span class="line">    primarycaps = PrimaryCap（CONV1，dim_capsule = <span class="number">8</span>，n_channels = <span class="number">32</span>，kernel_size = <span class="number">9</span>，步幅= <span class="number">2</span>，填充= <span class="string">'有效'</span>）</span><br><span class="line"></span><br><span class="line">    ＃ <span class="number">3</span>层：胶囊层。运行：动态路由算法。</span><br><span class="line">    digitcaps = CapsuleLayer（num_capsule = n_class，dim_capsule = <span class="number">16</span>，num_routing = num_routing，</span><br><span class="line">                             name = <span class="string">' digitcaps '</span>）（primarycaps）</span><br><span class="line"></span><br><span class="line">    ＃ <span class="number">4</span>层：</span><br><span class="line">    ＃如果你使用Tensorflow，你可以跳过这个会话:)</span><br><span class="line"></span><br><span class="line">    out_caps =长度（名称= <span class="string">' capsnet '</span>）（digitcaps）</span><br></pre></td></tr></table></figure></p>
<p>动态路由在<a href="https://github.com/deeplearningturkiye/kapsul-agi-capsule-network" target="_blank" rel="noopener">capsulelayers.py</a>类<code>CapsuleLayer (layers.Layer)</code>函数中定义。由于该计算步骤，在图像中不存在对象的区域中矢量值较小，而检测区域中的矢量尺寸根据属性而变化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">类 CapsuleLayer（层。层）：</span><br><span class="line">    “””</span><br><span class="line">    胶囊层。它类似于密集层。密集层有`in_num`输入，每个都是标量，输出</span><br><span class="line">    来自前一层的神经元，它有<span class="string">'out_num`输出神经元。CapsuleLayer只是扩展了神经元的输出</span></span><br><span class="line"><span class="string">    从标量到矢量。所以它的输入形状= [None，input_num_capsule，input_dim_capsule]和输出形状= \</span></span><br><span class="line"><span class="string">    [None，num_capsule，dim_capsule]。对于密集层，input_dim_capsule = dim_capsule = 1。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    ：param num_capsule：此图层中的胶囊数</span></span><br><span class="line"><span class="string">    ：param dim_capsule：此层中胶囊的输出向量的维度</span></span><br><span class="line"><span class="string">    ：param routings：路由算法的迭代次数</span></span><br><span class="line"><span class="string">    “””</span></span><br><span class="line"><span class="string">    DEF  __init__（自，num_capsule，dim_capsule，路线= 3，</span></span><br><span class="line"><span class="string">                 kernel_initializer = '</span> glorot_uniform <span class="string">'，</span></span><br><span class="line"><span class="string">                 ** kwargs）：</span></span><br><span class="line"><span class="string">        超级（CapsuleLayer，自我）。__init __（** kwargs）</span></span><br><span class="line"><span class="string">        self .nu​​m_capsule = num_capsule</span></span><br><span class="line"><span class="string">        self .dim_capsule = dim_capsule</span></span><br><span class="line"><span class="string">        自我 .routings =路线</span></span><br><span class="line"><span class="string">        self .kernel_initializer = initializers.get（kernel_initializer）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def  build（self，input_shape）：</span></span><br><span class="line"><span class="string">        assert  len（input_shape）&gt; =  3，“输入Tensor应该有shape = [None，input_num_capsule，input_dim_capsule] ”</span></span><br><span class="line"><span class="string">        self .input_num_capsule = input_shape [ 1 ]</span></span><br><span class="line"><span class="string">        self .input_dim_capsule = input_shape [ 2 ]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        ＃变换矩阵</span></span><br><span class="line"><span class="string">        self .W =  self .add_weight（shape = [ self .nu​​m_capsule，self .input_num_capsule，</span></span><br><span class="line"><span class="string">                                        self .dim_capsule，self .input_dim_capsule]，</span></span><br><span class="line"><span class="string">                                 initializer = self .kernel_initializer，</span></span><br><span class="line"><span class="string">                                 name = '</span> W <span class="string">'）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        self .built =  真的</span></span><br></pre></td></tr></table></figure></p>
<p>你也可以在<a href="https://github.com/deeplearningturkiye/kapsul-agi-capsule-network" target="_blank" rel="noopener">这里</a>找到所有的工作。<br><a name="0fa8"></a></p>
<h3 id="测试性能🏅"><a href="#测试性能🏅" class="headerlink" title="测试性能🏅"></a><a href="#0fa8"></a>测试性能🏅</h3><p>当使用10,000图像测试数据集进行测试时，我们获得了<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">MNIST</a>数据集的<strong>99.61％</strong>准确度，并且获得了<a href="https://www.kaggle.com/zalando-research/fashionmnist" target="_blank" rel="noopener">FASHION MNIST</a>数据集的<strong>92.22％</strong>准确度。是啊！😎<br>对于具有<strong>80％重叠</strong>手写数字的<strong>MultiMNIST</strong>数据集，当数据重叠时，胶囊网络的性能似乎非常好，特别是与CNN模型相比时。<br><img src="https://cdn-images-1.medium.com/max/1000/1*SHDKu_mb0DRp0OwTbWCPtg.jpeg#width=" alt><a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank" rel="noopener">MultiMNIST数据集的胶囊网络输出</a></p>
<p><a name="3689"></a></p>
<h3 id="MNIST的50纪元工作时间⏳"><a href="#MNIST的50纪元工作时间⏳" class="headerlink" title="MNIST的50纪元工作时间⏳"></a><a href="#3689"></a>MNIST的50纪元工作时间⏳</h3><p>与CNN相比，由于其计算复杂性，胶囊网络的训练时间较慢。以下是各种硬件和云服务器上的50纪元培训时间：<br><img src="https://cdn-images-1.medium.com/max/1000/1*tL-IKEmfUiKE0cOmJW-c4g.png#width=" alt><br><img src="https://cdn-images-1.medium.com/max/1000/1*3tX5wuhfLPeinWsdEemi3Q.jpeg#width=" alt><a href="https://thescinder.files.wordpress.com/2017/06/goingtoneedagpuimgflip1.jpg" target="_blank" rel="noopener">当然 ：）</a><br>要使用Google Colab支持，最吸引人的选项，请阅读&gt; <a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d" target="_blank" rel="noopener">Google Colab免费GPU教程！</a></p>
<p><a name="d950"></a></p>
<h3 id="✔️Pros和❌Consof-Capsule-Networks"><a href="#✔️Pros和❌Consof-Capsule-Networks" class="headerlink" title="✔️Pros和❌Consof Capsule Networks"></a><a href="#d950"></a>✔️Pros和❌Consof Capsule Networks</h3><p>与其他最先进的技术相比，✔️Capsule网络在MNIST数据集中取得了最大的成功。</p>
<p>✔️使用较小的数据集成功。（通过强制模型学习胶囊中的特征变体，它可以用更少的训练数据更有效地推断可能的变体。）</p>
<p>✔️逐协议算法允许我们区分重叠图像中的对象。</p>
<p>✔️使用激活矢量更容易解释图像。</p>
<p>✔️Capsule网络维护对象的等效性，色调，姿势，反照率，纹理，变形，速度和位置等信息。</p>
<hr>
<p>与现有技术模型相比，❌CIFAR10在数据集方面没有成功。</p>
<p>❌尚未在非常大的数据集上进行测试。</p>
<p>❌由于协议路由算法，训练模型需要更多时间。</p>
<p>具有不同路由算法的胶囊网络模型的应用表明它是一个需要更多实验并且仍在开发的主题。</p>
<blockquote>
<p><a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec6b.pdf" target="_blank" rel="noopener">“卷积神经网络注定失败” Geoffrey Hinton</a><br><a name="cd5c"></a></p>
</blockquote>
<h3 id="另一个例子"><a href="#另一个例子" class="headerlink" title="另一个例子"></a><a href="#cd5c"></a>另一个例子</h3><p><img src="https://cdn-images-1.medium.com/max/750/1*KSQA6cFQK6EiZ0oerCx7BQ.png#width=" alt><br><img src="https://cdn-images-1.medium.com/max/750/1*ifzv7ASKL7TyJU-4GZblbw.png#width=" alt><a href="https://hackernoon.com/capsule-networks-are-shaking-up-ai-heres-how-to-use-them-c233a0971952" target="_blank" rel="noopener">卷积神经网络的重要安全问题举例</a></p>
<p><strong>在上面示出的示例中，当仅改变Kim Kardashian的图像的方向时，预测准确度显着下降。</strong>在右边的图像中，我们可以很容易地判断出一只眼睛和她的嘴是不正确放置的，这不是一个人的假设。然而，我们看到了0.90的预测分数。</p>
<p>受过良好训练的CNN在这种方法上存在一些障碍。除了容易被具有不正确位置的特征的图像欺骗之外，当以不同方向观看图像时CNN也容易混淆。</p>
<p>毫无疑问，CNN可能受到<a href="https://heartbeat.fritz.ai/introduction-to-generative-adversarial-networks-gans-35ef44f21193" target="_blank" rel="noopener">对抗性攻击的</a>影响。这是一个可能导致安全问题的重要约束，特别是当我们将潜在模式嵌入到对象中以使其看起来像其他东西时。但是，正如我们所知，<em>我们可以通过Capsule Networks解决这个问题！</em></p>
<p><strong>✨胶囊网络的模型是值得和有前途的！</strong></p>
<hr>
<p>📝 <strong>我们关于胶囊网络的学术论文：</strong><a href="https://ieeexplore.ieee.org/document/8404385/" target="_blank" rel="noopener">使用胶囊网络识别手语</a>听力和语言障碍者继续通过唇读或手和脸的运动（即手语）进行交流。胶囊网络可以帮助确保残疾人不仅可以充分参与生活，还可以通过与他人的健康和有效沟通来提高生活质量。</p>
<p><em>在这项工作中; Capsule Networks 以</em><strong><em>94.2％的</em></strong><em>验证准确度识别手语的数字。</em></p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*Lzr1bVSB5UXVf6RXQwVbZg.png#width=" alt><a href="https://github.com/ardamavi/Sign-Language-Digits-Dataset" target="_blank" rel="noopener">手语数字数据集，Arda Mavi ve Zeynep Dikle</a></p>
<hr>
<p><a name="9d62"></a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a><a href="#9d62"></a>参考</h3><p>[1] Sabour，S.，Frosst，N. ve Hinton，GE，“ <a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank" rel="noopener">胶囊之间的动态路由</a> ”，arXiv preprint arXiv：1710.09829,2017。<br>[2] Hinton，GE，Krizhevsky A. ve Wang，SD“ <a href="http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf" target="_blank" rel="noopener">转换自动编码器</a>。”国际人工神经网络会议。斯普林格，柏林，海德堡，2011年。<br>[3] <a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec6b.pdf" target="_blank" rel="noopener">CSC2535：2013高级机器学习认真对待逆向图形</a>，Geoffrey Hinton多伦多大学计算机科学系，2013年。<br>[4] MNIST数据集的胶囊网络实现（土耳其语解释，深度学习Türkiye，<a href="https://github.com/deeplearningturkiye/kapsul-agi-capsule-network" target="_blank" rel="noopener">kapsul-agi-capsule-network</a>。<br>[5] <a href="https://ieeexplore.ieee.org/document/8404385/" target="_blank" rel="noopener">使用胶囊网络识别手语</a>，<a href="https://www.linkedin.com/in/fuatbeser/" target="_blank" rel="noopener">FuatBeşer</a>，<a href="http://www.ayyucekizrak.com/" target="_blank" rel="noopener">MerveAyyüceKIZRAK</a>，<a href="http://www.yildiz.edu.tr/~bbolat/" target="_blank" rel="noopener">BülentBOLAT</a>，<a href="http://www.yildiz.edu.tr/~tulay/" target="_blank" rel="noopener">TülayYILDIRIM</a>，<a href="https://github.com/ayyucekizrak/Kapsul-Aglari-ile-Isaret-Dili-Tanima" target="_blank" rel="noopener">https：//github.com/ayyucekizrak/Kapsul-Aglari-ile-Isaret-Dili-Tanima</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/21/yuque/Capsule Networks：一种全新且极具吸引力的AI架构/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/F-35是1.4万亿美元的国家灾难" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/21/yuque/F-35是1.4万亿美元的国家灾难/">F-35是1.4万亿美元的国家灾难</a>
    </h1>
  

        
        <a href="/2018/12/21/yuque/F-35是1.4万亿美元的国家灾难/" class="archive-article-date">
  	<time datetime="2018-12-21T05:34:55.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://medium.com/war-is-boring/the-f-35-is-a-terrible-fighter-bomber-and-attacker-and-unfit-for-aircraft-carriers-c6e36763574b" target="_blank" rel="noopener">链接</a></p>
<p>JSF是一个可怕的战斗机，轰炸机和攻击者 - 并且不适合航空母舰。<br>F-35在战斗准备就绪之前还有很长的路要走。 这是现任退休运营测试与评估总监迈克尔吉尔摩在上一份年度报告中的离职信息。<br>联合攻击战斗机计划已经消耗了超过1000亿美元和近25年。 要完成基本开发阶段，至少需要10亿美元和两年多。 吉尔莫尔告诉国会，五角大楼和公众，即使有大量的时间和金钱投入，“所有变种的运作适用性仍然低于服务部门的预期。”<br>Gilmore详细介绍了该计划存在的一系列遗留问题，有时甚至是恶化问题，包括数百个关键性能缺陷和维护问题。 他还提出了一个严肃的问题，即空军的F-35A能否在空对空或空对地任务中取得成功，海军陆战队的F-35B是否可以进行基本的近距离空中支援，以及海军是否能够 F-35C适用于航空母舰。<br>事实上，他发现“如果在战斗中使用，F-35飞机将需要支持来定位和避开现代威胁地面雷达，获取目标，并且由于未解决的性能缺陷和有限的武器运输可用性而使敌方战斗机编队“。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545370645879-05f3b68c-3916-4631-a30e-605fbcaa9402.png#align=left&amp;display=inline&amp;height=39&amp;originHeight=39&amp;originWidth=60&amp;status=done&amp;width=60" alt><br>在一份公开声明中，F-35联合计划办公室试图驳回吉尔摩的报告，声称“所有这些问题都是日本知识产权组织，美国服务机构，我们的国际合作伙伴和我们的行业所熟知的。”<br>JPO对众多问题的承认是可以接受的，但没有迹象表明该办公室有任何计划 - 包括成本和进度重新估算 - 以解决目前已知问题而不偷工减料。<br>显然，他们还没有计划应对并为将来四年即将进行的更加严格，发展和运营测试中发现的无数未知问题提供补救。这样的计划是必不可少的，应该由实际解决问题的速度而不是不切实际的现有时间表来推动。<br>如何解决Gilmore发现的众多问题，以及我们如何才能最好地推进历史上最昂贵的武器计划，这个计划一直无法达到自己非常适度的承诺？<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545370694304-542d261f-be35-40fe-8a8e-ba5df980e909.png#align=left&amp;display=inline&amp;height=495&amp;originHeight=829&amp;originWidth=1250&amp;status=done&amp;width=826" alt><br><a name="31d1d5ab"></a></p>
<h4 id="电子化用于证明成本合理-而不是提供能力"><a href="#电子化用于证明成本合理-而不是提供能力" class="headerlink" title="电子化用于证明成本合理 - 而不是提供能力"></a><a href="#w1qwta"></a>电子化用于证明成本合理 - 而不是提供能力</h4><p>F-35正在向美国人民出售，其中很大一部分就是其任务系统，喷气式飞机上的大量精密电子设备。仔细阅读有关F-35的任何关于W-35的正式文章将会发现它们几乎总是指出它能够收集大量信息。<br>这些信息应该通过其板载传感器和数据链接到外部网络源，然后由F-35的计算机系统合并，以便为飞行员识别和显示特定威胁，目标和伴随力图片 - 即“情境”意识。”<br>这个过程旨在让飞行员主宰战场。然而，基于这些系统在开发测试期间的实际测试性能，电子设备实际上会干扰飞行员的生存和普及能力。<br>总的来说，F-35的传感器，计算机和软件的问题，包括制造虚假目标和报告不准确的位置，已经非常严重，以至于爱德华兹空军基地的测试团队将他们评为“红色”，这意味着他们无法进行战斗。他们期待的任务。<br>一个系统，即光电目标系统（EOTS），被飞行员挑选出来，其分辨率和范围都低于目前在传统飞机上使用的系统。 EOTS是旨在帮助F-35从足够远的地方探测和摧毁敌方战斗机以使斗狗成为过去的系统之一。它安装在靠近飞机机头的地方，包括一台电视摄像机，一个红外搜索和跟踪系统，以及一个激光测距仪和指示器。<br>这些传感器在计算机控制下旋转，以在广泛的视野范围内跟踪目标，并在飞行员的头盔遮阳板显示器上显示图像。<br>但是EOTS的局限性，包括图像随着湿度的降低，迫使飞行员飞行的距离比使用早期系统时更接近目标只是为了获得足够清晰的图像来发射导弹或射击。<br>该报告说，问题非常严重，以至于F-35飞行员可能需要飞得如此接近才能获得他们必须机动的目标才能获得导弹射击所需的距离。因此，该系统的局限性可以迫使攻击性的F-35妥协意外，让敌人机动到第一次机会。<br><em>投降惊喜的元素并让对手先射击是我们想要迫使敌人做的事情，而不是我们自己。</em><br><br><br>另一个经常被吹捧的功能是分布式孔径系统（DAS），该功能应该赋予F-35卓越的态势感知能力。 DAS是将显示器供给臭名昭着的600,000美元头盔系统的主要传感器之一，它也未能实现炒作。<br>DAS传感器是分布在F-35机身周围的六个摄像机或“眼睛”，它们向头盔遮阳板投射到飞行员想要观察的任何方向的外部视图，包括向下或向后。同时，头盔遮阳板显示飞行仪表以及从传感器和任务系统得出的目标和威胁符号。<br>但由于过多的错误目标，不稳定的“抖动”图像和信息过载等问题，飞行员正在关闭一些传感器和计算机输入，而是依靠简化的显示器或更传统的仪表板。<br>在这里，系统再次比它应该取代的系统好一点。<br>在一些重要的武器交付准确性测试中，试飞员也对头盔有困难。一些飞行员将头盔中的显示描述为“操作上无法使用且可能不安全”，因为“符号杂乱”使地面目标模糊不清。<br>在试图对目标射击短程AIM-9X空对空导弹时，飞行员报告说，他们对目标的看法被头盔护目镜上显示的符号所阻挡。飞行员还报告说，这些符号在试图追踪目标时不稳定。<br>然后是由于“虚假轨道”导致飞行员实际上看到双重的问题。将各种车载仪器产生的所有信息并将其合并为飞行员的连贯图像存在问题，该过程称为传感器融合。<br>飞行员报告说，不同的仪器，如飞机的雷达和EOTS，正在检测相同的目标，但编制信息的计算机正在将单个目标显示为两个。<br>飞行员试图通过关闭一些传感器来解决这个问题，使多余的目标消失。 DOT＆E表示，这是“不可接受的战斗，违反了将多个传感器的贡献融合到一个准确的轨道和清晰的显示中以获得态势感知以及识别和接触敌方目标的基本原则。”<br>虽然问题出在一个平面上，但是当几架飞机试图通过网络共享数据时，情况会更糟。 F-35具有多功能高级数据链路（MADL），旨在使飞机能够与其他F-35共享信息，以便为所有飞行员提供战斗空间的共同图像。它通过获取每个平面生成的所有数据并将其组合到一个共享的世界视图中来实现这一点。</p>
<p><em>但是，这个系统也会产生错误或分裂的目标图像。 使问题更加复杂的是，系统有时也会完全丢弃目标图像，导致驾驶舱内部存在混淆。</em><br><br><br>所有这些意味着系统意味着让飞行员更好地了解周围的世界可以完全相反。 根据该报告，这些系统“继续降低战斗空间意识并增加飞行员的工作量。 这些缺陷的解决方法对于飞行员来说是耗时的，并且会减少高效和有效的任务执行。“<br>F-35助推器表示这是重要的网络 - 实际上重要的是网络无法正常工作。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545370927968-ab261e3d-8341-4999-a9c1-d24ef08dfa74.png#align=left&amp;display=inline&amp;height=497&amp;originHeight=1200&amp;originWidth=1800&amp;status=done&amp;width=826" alt><br><a name="80d6dbbc"></a></p>
<h4 id="作为战士无效"><a href="#作为战士无效" class="headerlink" title="作为战士无效"></a><a href="#xp62pu"></a>作为战士无效</h4><p>F-35从一开始就打算成为一架多用途飞机。这份最新的报告清楚地描述了迄今为止它在各种角色中如何叠加，包括与它应该取代的每架飞机相比。这个消息并不令人鼓舞。<br>F-35作为空对空战斗机的缺点已经有了很好的记录。<br>它在视觉范围（WVR）中的模拟空战中失去了名称，它的雷达隐身没有任何优势，在2015年初的F-16中，其中一架F-35应该取代作为空中战斗机。 F-35在空对空机动中反复丢失，尽管该测试被操纵，因为所使用的F-16是较重的双座版本并且进一步装载了重型拖曳外部燃料坦克阻碍其机动性。<br>F-35助推器认为飞机的低雷达标志将使其远离WVR情况，但空战的历史是无法完全避免WVR的攻击。导弹故障，雷达干扰的影响以及其他难以预测的因素往往会一次又一次地迫使WVR参与。<br>这份最新报告证实F-35并不像传统战斗机那样机动。<br><em>所有三种变型“在跨音速下都表现出令人反感或不可接受的飞行质量，其中飞机上的空气动力正在迅速变化。”</em><br><br><br>一个这样的问题被称为机翼下降，其中喷气机的翼尖在急转弯时突然下降，这可能导致飞机旋转并可能发生碰撞。<br>在声屏障正下方的跨音速是战斗机飞行包线的最关键点。这些是历史上大多数空战发生的速度。正是在这些速度下，F-35需要最灵活才能成为有效的战斗机。</p>
<p>该计划试图通过改变F-35的飞行软件而不是通过重新设计导致问题的实际飞行表面来解决机动性能问题。<br>该软件称为控制法则，将飞行员的操纵杆命令转换为飞机的行为。人们可以预期飞行员对飞机的某些力量会导致飞机的等效响应。由于软件的变化，有时并非如此。</p>
<p>例如，如果飞行员使用尖锐的杆移动以转动飞机，控制法软件现在可以更温和地转向以防止诸如 - 包括 - 挖掘等问题。 F-35辩护人试图通过声称F-35从未打算用于近距离空中斗狗来解雇这些问题，空军强烈要求飞机配备短距离空对空炮。</p>
<p>作为空对空战斗机，F-35的作战能力非常有限，因为目前软件版本只能使用两枚导弹，而且它们必须是雷达引导的先进中程空中飞行器。空中导弹（AMRAAMs）;如果它想要保持其隐形特征，它将来不会超过四个。</p>
<p>F-35作为空对空战斗机的能力目前进一步受到限制，因为AMRAAM并未针对近距离视距作战进行优化。最终，升级的软件版本将允许飞机携带除AMRAAM之外的导弹，但不会很快。这意味着F-35进入的任何战斗最好都是短暂的，因为它很快就会耗尽弹药。<br>它的枪也可用于近距离战斗，但它目前还没有工作，因为在战斗中有效使用它的软件还没有完成。</p>
<p>F-35A中的大炮位于飞机侧面的一扇小门后面，在大炮发射前瞬间快速打开 - 这一特性旨在使飞机保持隐身状态。测试飞行表明，这扇门能够捕捉到飞过飞机表面的空气，将F-35的机头从瞄准点拉开，导致“超出精度规格”的误差。</p>
<p>工程师们正在对F-35的控制法进行更多修改，以纠正门引起的误差。进行这些更改并执行随后的“回归”重新测试以确认更改的有效性会延迟实际的枪支准确度测试。在这些测试发生之前，没有人能够知道F-35A的大炮是否能够真正击中目标。</p>
<p>F-35B和F-35C都将使用外置式枪架，而不是像空军型号那样的内部版本。由于两种型号机身形状的差异，海军陆战队和海军将使用不同型号的枪荚。两者都在地面上进行了试验，但飞行测试看看吊舱对喷气式飞机空气动力学的影响才刚刚开始。</p>
<p>DOT＆E警告说，就像F-35A上的枪门一样，可能会发现意外的飞行控制问题。必须设计对这些的修复，然后进行测试。只有这样，程序才能开始更全面的飞行中精度测试，这对于确定枪荚是否准确是必要的。</p>
<p>开发测试延迟以及解决测试可能发现的问题的过程非常严重，以至于该计划可能没有有效的初始操作测试和评估枪支。这不仅可以进一步延迟预定的测试，而且更重要的是，可以防止飞机很快到达战士。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371080991-45289738-757c-42c0-b9aa-d61c7a02c077.png#align=left&amp;display=inline&amp;height=521&amp;originHeight=1256&amp;originWidth=1800&amp;status=done&amp;width=826" alt></p>
<p><a name="a825e04e"></a></p>
<h4 id="作为拦截轰炸机无效"><a href="#作为拦截轰炸机无效" class="headerlink" title="作为拦截轰炸机无效"></a><a href="#55vqcv"></a>作为拦截轰炸机无效</h4><p>F-35将具有极其有限的拦截有用性的几个主要原因 - 空军和海军陆战队的“初始作战能力”声明尽管如此。<br>例如，欧洲，俄罗斯，中国甚至伊朗的国防公司多年来一直在努力开发和生产打败隐形飞机的系统。他们取得了一些成功。<br>我们在1999年清楚地看到了这一点，当时一支塞尔维亚导弹部队击落了一架F-117隐形战斗机，该战斗机配备了过时的苏联时代SA-3地对空导弹，这是1961年首次部署的系统。塞尔维亚防空人员发现他们可以通过使用导弹电池的长波搜索雷达探测隐形飞机。<br>然后，利用观察员和导弹自己的制导雷达，塞尔维亚部队能够追踪，瞄准并杀死一架隐身的F-117。<br>为了表明这不是侥幸，塞尔维亚地空导弹击中并损坏了另一架F-117，以至于它再也没有在科索沃空战中飞行过。<br>这些搜索雷达不受现代隐形飞机的特殊形状和涂层的影响，可以轻松检测到今天的隐形飞机，包括F-35。自第二次世界大战以来，俄罗斯人从未停止过制造这种雷达，并且现在在公开市场上以低至1000万美元的价格销售现代化，高度移动的卡车式数字长波雷达。中国和伊朗人也开始采用类似的雷达系统。<br>比长波探测雷达更难对付的更简单的系统是无源探测系统（PDS），用于探测和跟踪飞机发射的射频（RF）信号 - 雷达信号，UHF和VHF无线电信号，识别-friend-or-foe（IFF）信号，Link-16等数据链路信号和TACAN等导航转发器信号。<br>现代PDS的一个很好的例子是VERA-NG，这是一种捷克系统，在国际上销售，使用三个或更多的间隔良好的接收天线来检测和跟踪和识别战斗机和轰炸机发出的射频信号。系统的中央分析模块计算到达接收器的信号的时间差，以识别，定位和跟踪多达200架飞机发射雷达信号。<br>VERA-NG只是世界上使用的众多PDS中的一种 - 俄罗斯人，中国人和其他人也生产PDS，这些PDS已经广泛使用了好几年。<br>从对手采用PDS的角度来看，PDS的优点在于雷达隐身与其探测和跟踪飞机的能力无关。如果飞机必须使用其雷达，无线电，数据链路或导航系统来完成其任务，PDS很有可能通过这些发射来检测，跟踪和识别它。<br>世界上每架飞机都容易受到PDS，隐身和非隐身的影响，而F-35也不例外。<br>F-35的主要空对空武器AIM-120是超视距雷达导弹 - 因此，F-35必须使用大型雷达发射高功率信号才能探测到空中目标然后引导导弹到他们身边。同样，飞机必须采用高功率地面测绘雷达信号来远距离寻找地面目标。<br>此外，如果飞机的系统必须与地层中的其他飞机通信或与AWACS等非机载支持飞机通信，则必须使用其无线电和数据链路。因此，F-35可能易受被动跟踪系统的检测。这些无源探测系统中的一些比搜索雷达便宜得多 - 而且它们在电子方面几乎检测不到。<br>DOT＆E报告还列出了限制拦截有用性的几个主要原因。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371153712-4fb2550d-f06c-468e-ac83-a79ccc95ec77.png#align=left&amp;display=inline&amp;height=39&amp;originHeight=39&amp;originWidth=60&amp;status=done&amp;width=60" alt><br>其中一个原因是F-35的Block 2B（USMC）和Block 3i（USAF）软件阻止它检测到许多威胁和目标，同时严重限制它可携带的武器种类。<br>例如，F-35目前只能携带几种型号的大型制导直接攻击炸弹。这些都不能像电力导弹那样从远处发射。相反，它们落在从飞机到目标的弹道轨道上，这意味着它们只能在目标视野中以相对较短的距离释放。<br>目前，F-35飞行员“将被迫飞得更近，以接近地面目标，并且根据敌方防空系统的威胁程度和可接受的任务风险，它可能仅限于接触仅由短程防御的地面目标防空，或根本没有防空。“<br>F-35可携带的少量武器类型也限制了其在战斗中的灵活性。目前的软件一次只能支持一种炸弹，DOT＆E表示只有在攻击一个或两个类似目标时才有用。因此，例如，当一架F-35飞机装载的炸弹装载用于摧毁地面目标的炸弹时，它们将无法摧毁任何硬化或沙坑目标，因为它们不会需要更重的炸弹。<br>预计F-35将携带更多种类的武器，因为更多的软件，炸弹架和测试验证这些武器已经开发出来 - 但我们直到2021年才知道哪些武器实际上是适合作战的。此外，为了携带除两个大型制导炸弹之外的东西，它将不得不使用外部武器和机架，大大降低了飞机本已令人失望的射程和机动性 - 当然，或多或少地消除了隐身。<br>能够穿透严密防御的空域以摧毁敌方领土深处的固定目标，这是F-35经常被引用的理由。当然，F-35的有限射程 - 低于传统的F-16战斗机 - 意味着它不可能在俄罗斯和中国等大国的家乡内完成空军所谓的“深度打击”。<br>2016年的DOT＆E报告描述了一些官方的拖延行动，推迟了F-35的穿透力测试。例如，该计划现在才开始接收模拟敌方雷达系统的关键地面雷达模拟器设备，这些设备是在高度竞争的近邻情景中对F-35的有效性进行有力测试所需的。<br>它只接收该设备，因为它是由DOT＆E寻求和采购的，当时很明显服务和JSF计划办公室不会寻求足以复制F-35预计能够复制近端威胁的测试基础设施反击。这种设备的交付工作已经开始，但要到2018年初才能完成。初级专业人员没有计划或预算进行发展性飞行试验。<br>军方在内华达州内利斯空军基地的西部测试区进行隐形飞机的开发和操作测试。测试是针对地面雷达模拟器设备和地对空导弹发射器进行的。正在测试的飞机飞过这些阵列以查看飞机的机载传感器 - 特别是其电子战系统和地面测绘雷达 - 与通过数据链路提供的机外情报相结合，可以检测到威胁并做出适当的响应，例如通过警告飞行员，干扰信号或发射防御抑制导弹。<br>问题是一个复杂的问题，因为雷达信号显示SAM的存在，例如，从而允许飞机瞄准SAM或避免它，不一定是独特的，并且通常非常类似雷达的信号，不立即对飞机的威胁。<br>F-35无法携带足够的武器轰炸一切。它的传感器和传感器融合系统必须能够区分构成真正威胁的敌方SAM雷达与可能在探测范围内的许多无害雷达之间的区别 - 通用空中监视雷达，短程，低空防空针对武器而非飞机的雷达，甚至是附近的民用空中交通管制和气象雷达系统。<br>同样瘫痪，直到地面雷达模拟器设备到位，F-35程序将无法正确开发，验证和更新F-35的任务关键型机载软件文件，称为任务数据负载（MDL）。 MDL是指定所有目标和威胁位置的巨大文件，以及它们各自的电子和/或红外签名以及所有相关的映射数据。</p>
<p><em>如果没有准确，最新的MDL，F-35就无法找到目标或逃避和抵御威胁 - 它也无法实现据称是其主要优势的网络和传感器融合功能。</em><br><br><br>如果没有MDL，F-35就无法开战。 MDL还需要不断更新有关每个F-35任务收集的威胁，目标和信号等信息。 F-35飞行员只有在配备必要的地面雷达模拟器设备的测试范围内进行测试后，才能确保他们所需的MDL能够正常工作。<br>必须通过中央重编程实验室使用相关作战命令的海量数据输入为每个战区或冲突区创建新的和完整的MDL。例如，在英格兰境外运营的F-35将拥有与日本F-35不同的档案。今天只存在一个这样的重编程实验室，并且由于JPO管理不善，它最近才被安排接受必要的升级以产生经过验证的MDL。<br>实验室需要15个月才能生成完整的MDL。如果在一个新的，未曾预料到的战区中突然需要F-35战斗机，那些F-35将无法至少执行15个月的战斗任务。<br>由于重编程实验室尚未建立全套必要的地面雷达模拟器设备，DOT＆E表示，最早的重编程实验室将能够为IOT和E生产经过验证的MDL，将于2018年6月完成。<br>这是在2017年8月计划的IOT＆E开始后近一年 - 也就是海军陆战队宣布F-35B最初具备运营能力两年后。 DOT＆E进一步表示，F-35 MDL适合战斗“将不会进行测试和优化，以确保F-35能够在2020年前检测，定位和识别现代部署的威胁。”<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371288913-2328d482-bb99-4e2b-97f9-48d44b5c6a9f.png#align=left&amp;display=inline&amp;height=497&amp;originHeight=1200&amp;originWidth=1800&amp;status=done&amp;width=826" alt><br><a name="514d2da6"></a></p>
<h4 id="作为近距离空中支援平台无效"><a href="#作为近距离空中支援平台无效" class="headerlink" title="作为近距离空中支援平台无效"></a><a href="#ekgawy"></a>作为近距离空中支援平台无效</h4><p>F-35有很多不足之处，在远离战场的情况下执行空对地拦截任务，但在其他预定的空对地作用中更为严重，直接支持部队，近距离空中支援（CAS）。</p>
<p>DOT＆E得出结论认为，F-35目前的配置“还没有证明CAS能力与第四代飞机的能力相当。”鉴于空军部长最近的声明，该服务打算重新努力，这一说法特别令人不安。在2021年取消CAS战斗证明的A-10。</p>
<p>CAS是另一项主要任务，缺乏有效的大炮将极大地限制F-35的战斗实用性。<br>对于许多CAS任务来说，有效的大炮是必不可少的，在这些任务中，任何大小的炸弹，无论是导弹还是非制导炸弹都会对地面上的友军造成危险，或者担心附带损害，例如在城市环境中。</p>
<p>当我们的部队被距离只有几米远的敌人伏击或超支时，大炮更加重要，在“危险关闭”的情况下，只有最准确的火力才能帮助我们的方面杀死或驱散敌人。</p>
<p>在最近的兰德研究中接受采访的地面指挥官表示，他们更倾向于使用A-10的炮火甚至是导弹弹药，因为80％的炮弹在瞄准点的20英尺半径范围内发射，提供了精确的精确度。危险关闭情况绝对需要。大炮对于击中移动目标也是最有用的，因为大炮爆发可以在预期移动时引导目标。</p>
<p><em>目前舰队中的三架F-35型号都不能在战斗中使用大炮。 事实上，他们都没有接近完成他们的发展飞行测试 - 更不用说他们的操作适用性测试 - 对于机身安全性，准确性和目标杀伤力。</em><br><br><br>更糟糕的是，根据初步的测试经验，似乎所有三种F-35版本的头盔式瞄准具的严重不准确性使得大炮在空对空作战中无效 - 这也会使CAS无效 - 而且头盔的准确性问题可能在技术上是固有的，也是无法治愈的。</p>
<p>请注意，CAS的炮弹精度要求比空战要严格得多：在友军部队附近射击时，即使是轻微的精确度问题也会产生悲剧性后果。如前所述，海军陆战队的F-35B和海军的F-35C的炮舱可能会增加另一个不准确的来源 - 也可能是无法治愈的 - 并且仍未经CAS测试。</p>
<p>F-35大炮对CAS的战斗适用性直到3F区块IOT＆E结束时才会知道，这在2021年之前是不可能的。未能完全实现这些CAS测试 - 由于JPO管理不善和测试资源延迟，这种可能性很大 - 肯定会危害美军的生命。</p>
<p>除了关键的大炮不准确性问题之外，飞行员头盔显示器中符号杂乱的引起误差的混乱在CAS角色中尤其危险。 DOT＆E表示，由于符号杂乱模糊目标，难以读取关键信息和pipper [aimpoint]稳定性，目前的系统“在操作上无法使用，并且可能无法完成计划的测试。”</p>
<p>即使头盔显示的符号没有遮挡飞行员看到目标的能力，F-35的顶篷也可能。喷气式飞机的顶篷是一种厚的丙烯酸材料，具有低可观察的涂层，以保护隐形。这使得顶篷不太透明，并且根据DOT＆E似乎扭曲了飞行员的视野。</p>
<p>在F-35的每个版本中进一步限制加农炮的有效性是它携带的25毫米炮弹的数量–F-35A为182，B和C为220.这对于CAS来说是非常不足的，特别是与由A-10运载的超过1,100个30毫米炮弹。虽然A-10有足够的炮弹用于10到20次攻击，但F-35的任何变种只有两次，也许四次传球。</p>
<p>更有效地使用任何CAS武器，大炮或其他装置，更有限制的是，F-35无法飞得低而且速度慢，无法找到典型的难以看见的CAS目标并安全地将其识别为敌人或友军，即使是在提示 由地面或空中观察员。</p>
<p>由于其小而重载的机翼，F-35无法在寻找隐藏和伪装目标所需的低速下充分操纵 - 并且完全没有装甲和高度易燃，它将遭受来自小型步枪和轻型机枪的灾难性损失在低海拔和所需的低速度下不可避免地命中。与此形成鲜明对比的是，A-10专门设计用于出色的低速和低速机动性，并且在设计上具有前所未有的生存能力，可以抵御那些枪支，甚至可以抵抗肩射式导弹。</p>
<p>空军官员经常认为，缺乏有效的枪支或无法操纵低速和慢速在未来的战争中无关紧要，因为空军打算以不同的方式进行CAS，即在高海拔地区使用较小的精确弹药。但F-35将不会被清除至少携带这些武器五年。</p>
<p>与此同时，F-35现在只能携带两枚制导炸弹，而这些炸弹则为500磅或更大。这些模型都不适用于友军部队附近。根据军方的风险估算表，在250米（820英尺）处，500磅重的炸弹有10％的几率使友军失去能力。这意味着在那个泡沫中，敌人可以在没有近距离空中支援的情况下进行机动。<br>250磅重的小直径炸弹II现在处于低速生产状态，并在F-15E上使用;然而，即便如此，在“危险关闭”的交火中，在友军部队附近使用它太大了，在F-35上使用它所需的软件和炸弹机架将无法在2021年之前完成战斗。<br>近距离空中支援不仅仅是对目标投掷炸弹的飞机。为了真正有效，CAS任务需要飞行员和在地面作战的部队之间进行详细的战术协调。几十年来，这已经通过无线电通信有效地完成，并且近年来，运营中的飞机已经通过称为可变消息格式和链路-16的网络系统上的语音和数据的数字通信链路进行了升级。<br>在飞行测试中，F-35的数字数据链路遇到了很大的困难，包括丢失的信息或以错误格式传输的信息。这迫使飞行员和地面控制器通过无线电通过语音重复信息来在系统周围工作。在近距离的交火中，当秒数计算时，这是部队无法承受的危险延误。<br>F-35防守队员总是迅速指出近乎对等的对手防空系统所谓的致命能力，作为在CAS中使用F-35以及禁止轰炸的必要性的理由。空军上校Mike Pietrucha介绍了一个更健全的战术和历史观点，指出在一个重防空威胁领域飞行CAS任务的情景充其量不太可能。<br>繁琐，缓慢，物流密集的“高威胁”导弹系统不太可能被近邻敌人进行现代机动战争拖累。正如他们在第二次世界大战期间面对的那样，韩国，越南，沙漠风暴，我们的近距离支持飞行员更有可能面对较轻的轻型和移动防空（机枪，轻型高射炮和人类携带的寻热导弹）以及过去15多年的战争。<br>在宣布F-35 IOC时，海军陆战队员 - 曾经将CAS作为独特海军遗产的一部分而获奖 - 而空军显然认为这些F-35 CAS限制是可以接受的。<br>但是，看到近距离空中支援作为F-35计划的事后补救被视为可耻是可耻的。为了提供足够的CAS，纳税人的资金将更好地用于维持经过战斗验证的A-10，直到测试和部署更加有效且更实惠的后续工作。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371489499-d230ab6a-88c6-49b8-9ed0-fa5750183844.png#align=left&amp;display=inline&amp;height=496&amp;originHeight=1197&amp;originWidth=1800&amp;status=done&amp;width=826" alt><br><a name="26f381ec"></a></p>
<h4 id="海军的F-35不适合航母作战"><a href="#海军的F-35不适合航母作战" class="headerlink" title="海军的F-35不适合航母作战"></a><a href="#hnuaxl"></a>海军的F-35不适合航母作战</h4><p>海军F-35变型必须具备的最重要特征之一是它必须能够从航空母舰上运行。否则，设计飞机的专业海军版本有什么意义？但海军自己的飞行员说F-35C并不适用于这些船只。<br>发展测试显示，弹射器发射期间发生了大量的抽搐 - 称为“过度垂直振荡” - “使F-35C在操作上不适合航母作战，”在最新一套船舶试验期间在美国乔治华盛顿号航空母舰上进行训练的舰队飞行员表示“。<br>从承载的甲板上起飞的飞机需要大力提升以达到提升和起飞所需的速度，这是通过安装在驾驶舱内的弹射器实现的。<br>在喷气式飞机发射之前，飞行员增加发动机推力。为了防止喷气式飞机在发射前从船的前部滚落，它们会被挡住杆挡住。当推力被压下时，推力会压缩齿轮的支柱。根据2017年1月泄露给内部防御的海军报告，当释放后退杆并且发射喷射时，F-35C的支柱被卸下，导致机头上下弹跳，震动飞行员。<br>这里的严重程度可以在这里清楚地看到：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371535128-4beffe90-8534-40a6-aaad-ca44e7de7567.png#align=left&amp;display=inline&amp;height=330&amp;originHeight=330&amp;originWidth=660&amp;status=done&amp;width=660" alt><br>这个问题对飞行员来说很危险。头盔式显示器非常重，目前重量为5.1磅，当它与弹射器发射时产生的力相结合时，额外的重量会使飞行员的头部前后晃动。在70％的F-35弹射器发射中，飞行员报告头部和颈部出现中度至重度疼痛。<br>发射也会影响头盔的对齐。飞行员报告说难以读取头盔内的重要信息，他们必须在进入空中后重新调整它。飞行员说，这是不安全的，因为它发生在任何飞行的最关键阶段之一。飞行员试图通过收紧身体安全带来抵抗振荡，但这会在紧急情况下难以触及紧急开关和弹射手柄，从而产生新的问题。</p>
<p>F-35的项目经理克里斯托弗·波格丹中将表示，他将尝试对F-35C的前起落架支柱进行短期调整以解决问题，但实际上可能需要长期修复，例如重新设计整个前起落架组件。这种情况不太可能在2019年之前开始 - 同年海军已表示有意宣布F-35C准备战斗。</p>
<p>到那时，海军很可能在舰队中拥有36架F-35C，其中每架都需要更换前起落架，但需要确定成本。</p>
<p>F-35C的问题不仅限于飞行的开始。就像喷气式飞机需要从航空母舰起飞一样，它也需要在着陆期间停止帮助。这是通过横跨甲板的电缆实现的。当一架喷气式飞机降落时，飞机上的一个挂钩抓住其中一根电缆，该电缆使用船内的液压发动机吸收能量并使喷气机停止运转。</p>
<p><em>他的测试团队发现F-35C的制动装置上的钩点磨损速度比预期快三倍。 虽然它应该至少持续15次着陆，但在测试中持续时间最长的一个钩点是5。 据报道，该计划正在考虑重新设计制动装置以使其更加坚固。</em><br><br><br>F-35C还有待解决的另一个结构性问题涉及机翼。在试飞期间，工程师发现机翼末端的强度不足以支撑AIM-9X短程空对空导弹的重量。 F-35C的机翼两端折叠，以便在飞机载体的甲板和机库的拥挤范围内节省空间。当导弹经过机翼折叠时，当飞机难以操纵和着陆时，重量超过结构限制。<br>根据DOT＆E的说法，在问题得到解决之前，“F-35C对于导弹运输和就业将具有有限的飞行范围，这将对机动，[和]近距离接合产生不利影响。”这甚至比F-35的其他固有机动限制。问题非常严重，波格丹将军承认F-35C将需要一个完全重新设计的外翼。<br>发射和恢复飞机只是海军航空挑战的一部分。维护人员还必须能够在海上保持喷气式飞机的飞行性。机组必须能够执行的关键维护功能之一是发动机拆卸和安装（R＆I）。 2016年8月，Crews在乔治华盛顿号航空母舰上进行了第一次R＆I概念验证演示。<br>机组人员需要55个小时来完成发动机交换，这比在传统飞机上执行相同操作所花费的时间要长得多。例如，F / A-18上的发动机可以在六到八个小时内更换。 DOT＆E指出，为了安全起见，机组人员花时间执行所有必要步骤，并指出随着机组人员获得更多经验，未来的迭代可能会更快一些。<br>也就是说，机组人员充分利用了整个机库海湾空间，这是他们乘坐飞机机翼时不会有的东西。这可能加快了演示期间的过程。</p>
<p>更换F-35中的发动机比F / A-18更复杂。工作人员必须拆除几个皮肤面板和一个称为尾钩支架的大型结构件，以便拆卸发动机，从而在维护机库中需要更多空间。这些部件以及与之相关的所有管子和电线必须妥善储存，以防止损坏，同时还要占用额外的空间。</p>
<p>维护人员必须在存在全空气翼的情况下执行此过程，以便了解系统是否在操作上合适。并且该过程必须变得非常有效，以产生战斗所需的出击率。</p>
<p>在乔治华盛顿试验期间发现的另一个问题涉及F-35C计算机生成的大量数据文件的传输。</p>
<p>F-35计划依赖于自动后勤信息系统（ALIS），这是庞大而复杂的计算机系统，所有F-35都用于任务规划，维护诊断，维护计划，零件订购等。为了正常工作，系统必须在船上和船外通过网络移动大量数据。</p>
<p>在华盛顿试验期间，机组人员必须通过船舶的卫星网络传输中等大小的200 MB ALIS文件。花了两天时间。带宽限制和不稳定的连接极大地阻碍了数据的传输。许多这样的变速器 - 甚至更大的变速器 - 将需要支持整个机翼。<br>此外，舰队经常在“排放控制”或无线电静音期间运行，以避免将其位置泄露给敌人，进一步阻碍了保持F-35飞行所需的数据传输。</p>
<p>乔治华盛顿的审判产生了大量令人讨厌的新闻报道。至少在公开场合，海军声称成功了。然而，有证据表明海军对该计划不太兴奋，因为上面讨论过这类问题，当然还有成本 - 服务购买F-35C的速度很慢。</p>
<p>虽然空军准备在2017年购买44架新的F-35，但海军只会买两架。海军还在其2017年无资金优先顺序（“愿望”）名单中要求另外增加14架F / A-18，并再增加两架F-35C。此外，这是服务没有急于过早宣布战斗准备的唯一变种。<br>五角大楼的一些领导人表示，海军的变种是唯一一个受特朗普政府下令审查的威胁，而国防部长詹姆斯马蒂斯目前正在进行审查。这可能证明是该计划的一部分，其中寻求F-35的可行替代方案。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371695072-55a96b06-342b-48ae-9d76-cf8961517f70.png#align=left&amp;display=inline&amp;height=497&amp;originHeight=1200&amp;originWidth=1800&amp;status=done&amp;width=826" alt><br><a name="e5652373"></a></p>
<h3 id="关于F-35唯一隐形的东西-价格标签"><a href="#关于F-35唯一隐形的东西-价格标签" class="headerlink" title="关于F-35唯一隐形的东西 - 价格标签"></a><a href="#w1shub"></a>关于F-35唯一隐形的东西 - 价格标签</h3><p>自大选以来，人们对F-35的进一步采购和可负担性表示了很多看法。唐纳德·特朗普总统在就职典礼前对一系列推文中的价值提出了质疑，但当他宣布洛克希德·马丁从最新一批F-35的价格中削减6亿美元时，他希望该计划能够大幅改变。 。<br>洛克希德·马丁公司及其在日本特许厅内的合作伙伴已表示价格会降低，这主要是由于制造业的效率提高。<br>从表面上看，这对美国纳税人来说似乎是一个巨大的发展，但现在任何“节省下来”的钱最终都会花费更多，因为我们购买了一堆未经测试的原型，后来需要进行大量昂贵的改造。如果洛克希德·马丁公司和联合计划办公室能够在计划完成测试和评估过程之前批准对400架F-35进行为期三年的“大量购买”，那么这个问题就更加复杂了。<br>报刊上报的价格通常基于空军常规起飞变型F-35A的成本 - 这三种变型中成本最低。此外，这个成本数字只是对未来成本的估计，假设从现在开始，F-35的一切都将完美运行 - 这不太可能，因为该计划进入其技术最具挑战性的测试阶段。<br>正如最新的DOT＆E报告显示，在F-35准备战斗之前，该计划还有很长的路要走。<br>联合计划办公室最近声称F-35A的价格在2016财年合同中每个都低于1亿美元。然而，在2016财年的立法中，国会为每架F-35A拨款1.196亿美元。<br>即使这个数字也不能说明整个故事 - 它只包括采购成本，而不是将F-35A带到最新批准的配置所需的成本，以及用于容纳和操作F-35A的额外军事建筑成本。<br>当然，1.196亿美元的价格标签不包括开发和测试F-35A的任何研发费用。海军陆战队F-35B和海军F-35C的2016年仅生产成本分别为1.664亿美元和1.852亿美元。<br>首先，它们不包括修复最近，当前和未来测试中发现的设计缺陷所需的成本 - 这不是一笔不大的金钱。它们也不包括计划的现代化努力的成本，例如飞机的第4座，将来将被纳入所有F-35A。政府问责办公室估计，该计划将在未来六年内至少花费30亿美元用于现代化工作。<br>据GAO称，例如，到目前为止所解决的一些问题的修改费用为4.267亿美元。这些飞机中的每一架都已经过修改，将来需要更多。空军已经承认必须改装交付给它和运营舰队的所有108架F-35A。随着已知问题得到修复并且发现新问题，这些成本将继续增长，并且它们是每架飞机成本的组成部分。<br>随着程序从测试的简单部分 - 开发或实验室测试 - 转移到未来几年的关键作战（运行）测试期，将会发现更多问题。<br>一个很好的例子发生在2016年底，当时工程师在F-35的油箱内发现了碎片。经过仔细检查，他们发现包裹在冷却剂管线周围的绝缘材料已经解体，因为分包商未能使用适当的密封剂。并且，当GAO估计将花费4.267亿美元来修复已经在仓库中的F-35A中的一些已知问题时，尚未发现冷却剂管线绝缘问题。<br>必须在已经生产和购买的飞机机队中设计，测试和实施对此问题和其他问题的修复。<br>其次，JPO，洛克希德马丁公司和五角大楼所使用的不完整的单位成本估算 - 他们所谓的“飞行”单位成本 - 不包括购买支持设备（工具，ALIS计算机，培训模拟器，初始备件）需要使F-35A机队能够运行。从字面上看，国防部的“飞行”成本并没有购买能够进行飞行操作的系统。<br>五角大楼已经承诺购买346架F-35，因为该计划已进入美国国防部委婉地称之为“低速初始生产”。<br>798喷气式飞机服务将在2018年至2021年期间大约450架次购买的798架喷气式飞机将占总采购量的近33％……所有这些都在该计划完成初步运行测试之前，并且发现了什么按预定工作，什么没有吨。<br>值得注意的是，真正的问题发现过程只会在2019年按计划开始运行测试时开始，或者更有可能在2020年或2021年开始，当时运营代表性飞机实际上已准备好进行测试。空军已经开始修改的108架飞机只是冰山一角，这个数字不包括数百架海军陆战队和海军飞机的类似修改。<br>拟议的“大宗购买”提出了许多其他问题。也许Gilmore所提出的最相关的问题是：<br>Block Buy是否与政府主张的“购买前飞行”方法一致，以及“美国法典”第10篇中规定的运营测试要求的理由，还是被视为“全额” “IOT＆E之前的决定是否已经完成并向国会报告，不符合法律规定？<br>只要符合某些标准，联邦法律允许多年合同购买政府财产。国会通常每年批准大多数武器购买计划，以确保对计划进行适当的监督，并保持对承包商表现令人满意的激励。<br>根据Title 10 U.S.C.，Section 2306b，对于有资格进行多年采购的计划，合同必须促进国家安全，应该节省大量资金，减少几率，并且设计稳定。 F-35似乎在前三个标准中至少有两个失败，并且肯定是第四个失败了。<br>关于F-35成本问题的一个重要部分是购买大型飞机是否合理，并担心以后修复尚未发现的问题的成本。这肯定是增加成本的好方法，但在临时中隐藏它。</p>
<p><em>实际操作F-35机队的成本仍然存在。 美国国防部估计，该计划50年的所有培训和运营运营 - 假设每架飞机的寿命为30年 - 将为1万亿美元，使购买和运营F-35的成本至少达到1.4万亿美元。</em><br><br><br>操作F-35的成本非常高，因为飞机与其他飞机相比非常复杂。根据空军自己的数据，2016财年，每架F-35飞机平均飞行163小时，每小时飞行4426美元。<br>为了进行比较，在同一年，机队中的每架F-16飞机平均飞行258小时，每飞行小时20,398美元。 A-10平均每小时飞行358小时，每小时17,227美元。虽然这些时间从未经过独立审核，而且无法确定它们是否完整，但现有数据表明F-35的飞行成本是飞机的两倍以上。<br>五角大楼隐藏F-35真正成本的一个更重要的方式是它推迟到第4区块开发和交付应该在第3区提供的许多关键能力。目前已计划但未包括根据政府问责局的数据，在F-35的官方成本估算中 - 或者甚至作为一个完整的单独收购计划 - 是一个由四部分组成的Block 4升级，至少耗资30亿美元。<br>此外，DOT＆E报告称“有17个记录的失败，无法满足规范要求，程序承认并打算寻求合同规范变更，以便结束SDD [系统开发和演示]。”<br>这意味着F-35计划无法提供17种关键作战能力，而且计划办公室正试图给洛克希德·马丁公司提供交付通行证，直到后期的高级开发过程。<br>虽然没有人公开声明现在不会包括哪17种战斗能力，但它们都是F-35应该拥有的所有功能，并且美国人民正在为此付出全价。因此，我们将来会支付更多的钱来升级现在购买的F-35，以便他们能够执行我们已经支付的功能。<br>2016年F-35A的1.196亿美元单位成本严重低估，多年来不会充分了解额外成本。那些假装2016年成本低于1亿美元的人只是在欺骗公众。</p>
<p><a name="67732f9d"></a></p>
<h3 id="战斗力有效"><a href="#战斗力有效" class="headerlink" title="战斗力有效"></a><a href="#q9x6ix"></a>战斗力有效</h3><p>在每一流的空军中，出战优秀的战斗机飞行员要求他们每月至少飞行30个小时来磨练和提高他们的战斗技能。这就是F-35缺乏战斗力的最大原因：由于飞机前所未有的复杂性和相应的可靠性和维护负担，飞行员根本无法经常飞行以获得足够的实际飞行时间来发展他们需要的战斗技能。<br>如果飞行员无法获得足够的飞行时间，飞行员技能就会萎缩。即使拥有卓越的技术，训练有素的飞行员也不会受到训练有素的飞行员在飞行不太复杂的飞机上的影响。<br>飞行时间不足也会造成危险的安全状况，威胁到飞行员的训练生命。海军陆战队在过去一年中遭遇了九次严重的飞机坠毁事故，造成14人死亡。该军团的顶级飞行员最近表示，撞车事故的飙升主要是由于飞行员没有足够的飞行时间。<br>这种趋势将随着F-35而恶化。鉴于其固有的复杂性和相关的成本，F-35极不可能经常飞行以获得成功的飞行员。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545371909219-5c3e7d63-0c79-41a3-a751-dc3afbf49136.png#align=left&amp;display=inline&amp;height=497&amp;originHeight=1200&amp;originWidth=1800&amp;status=done&amp;width=826" alt><br><a name="1a41eab4"></a></p>
<h3 id="F-35可以在需要的时候到达吗？"><a href="#F-35可以在需要的时候到达吗？" class="headerlink" title="F-35可以在需要的时候到达吗？"></a><a href="#ebawca"></a>F-35可以在需要的时候到达吗？</h3><p>即使这是一个很大的中频，F-35也可以像洛克希德·马丁所说的那样在战斗中表现出来 - 更不用说F-16，A-10和F-18的替代品应该如何表现 - 如果喷气式飞机不能满足他们需要的地方，那么该计划仍然毫无价值。<br>有几个因素导致难以及时部署F-35中队。一个是F-35的任务规划系统，它是ALIS网络的一部分。在完成战斗任务的细节 - 例如目标，预测的敌方雷达位置，要飞行的路线和武器装载 - 之后，需要将数据编程到飞机中。将该信息加载到墨盒上，然后将墨盒插入喷嘴中。<br>F-35飞行员在Offboard Mission Support（OMS）系统上对这些弹药筒进行编程。<br>DOT＆E发现的问题是，飞行员一直认为用于支持任务规划的系统“繁琐，无法使用，并且不适合操作使用。”他们报告说，构建任务计划文件所需的时间太长，以至于扰乱了超过一架飞机的任务计划周期。</p>
<p><em>这意味着当几架F-35接收任务时，如果分配了大量的计划时间，他们就无法足够快地完成所有飞行前过程以按时启动。</em><br><br><br>2016年2月和3月，空军在加利福尼亚的爱德华兹空军基地向爱达荷州的山地空军基地进行了部署演示，对F-35计划进行了重大测试。这是该服务首次尝试使用更新ALIS的版本 - 基于地面的计算机系统，用于诊断机械问题，订购和跟踪更换零件，并指导维修人员进行维修。<br>无论何时中队部署，都必须在部署F-35的任何地方建立一个ALIS枢纽。 Crews建立了一个ALIS标准操作单元（SOU），它由几个计算机设备组成。技术人员将使用这些设置一个小型主机，然后必须将其插入全球范围的ALIS网络。<br>工作人员花了几天时间让ALIS在本地基础网络上工作。经过大量的故障排除后，IT人员发现他们必须在Internet Explorer上更改多个设置，以便ALIS用户可以登录系统。这包括降低安全设置，DOT＆E以值得称道的轻描淡写的方式指出这是“可能与所需的网络安全和网络保护标准不兼容的行为”。<br>ALIS数据必须在中队所在的任何地方。在飞机被允许执行飞行任务之前，机组人员必须将数据从本垒站的中队主ALIS计算机传输到部署的ALIS SOU。在Mountain Home部署期间，此过程花了三天时间。这比之前的演示要快，但洛克希德·马丁为演习提供了8位额外的ALIS管理员。<br>目前还不清楚承包商或空军是否会在未来的部署中包含这种级别的支持。当演习结束时中队重新部署回爱德华兹时，管理员花了四天时间将所有数据传回主ALIS计算机。这种延迟将限制F-35在危机时刻快速部署的能力。</p>
<p><em>即使喷气机能够定位足够的时间来应对危机，长时间上传时间等问题也可能使它们在空中需要时保持在地面上。固定在地面上的飞机是目标，而不是资产。</em></p>
<p>另一个耗时的过程涉及向每个ALIS标准操作单元添加新飞机。每次将F-35从一个基座移动到ALIS已经启动的另一个基座时，必须将其导入该系统。这需要24小时。因此，当F-35部署到新基地时，整个一天会在处理数据时丢失。并且一次只能上传一架飞机。<br>如果整个中队（通常是12架飞机）需要被引导，整个过程将需要将近两周时间，迫使指挥官慢慢将他的F-35飞机投入战斗。<br>该计划的关键任务软件也出现延误。如前所述，F-35需要广泛的任务数据负载（MDL），以便飞机的传感器和任务系统正常运行。 MDL在某种程度上包括有关敌人和友好雷达系统的信息。他们发送喷气式传感器的搜索参数，以便他们正确识别威胁。这些需要更新以包含最新信息。它们也适用于每个主要地理区域。<br>MDL都在佛罗里达州埃格林空军基地的美国重编程实验室进行编程，然后发送给所有相关的中队。该实验室是整个F-35计划中最重要的组成部分之一。据DOT＆E称，该实验室必须能够“快速创建，测试和优化MDL，并在代表现实情景的压力条件下验证其功能，以确保F-35任务系统的正常运行和飞机的运行效率。战斗以及F-35与Block 3F的IOT＆E。“<br>官员们在2012年确定了该实验室管理层的严重缺陷。纳税人在2013年至2016年期间花费了4500万美元来解决这些问题。尽管有警告和额外资金，但实验室的开发仍然受到管理不善的困扰，这种管理不能阻止在当前的基本作战配置中“有效地创建，测试和优化运营飞机的MDL”。<br>需要升级实验室以支持F-35上使用的每个软件版本。该实验室目前配置为支持块2B和3i软件版本。 F-35的第一个完全战斗版软件将是Block 3F。该实验室需要进行重大更改以支持此版本，这对于战斗测试是必要的，更重要的是，完全战斗准备就绪。<br>实验室远远落后于一些必要的设备甚至尚未购买。例如，该设施还依赖于前面提到的专用射频发生器来重新创造潜在对手可能对F-35使用的那种信号。实验室将使用它们来测试MDL，然后将它们发送到机队飞机上，以确保喷气式飞机的传感器能够正确识别它们。<br>在急于假装初始作战能力的情况下，空军和海军陆战队实际上已经制造出一架完全未准备好面对敌人的飞机。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545372059027-ed5f34d0-f86c-471f-bcce-9c165524ebe0.png#align=left&amp;display=inline&amp;height=431&amp;originHeight=1040&amp;originWidth=1800&amp;status=done&amp;width=826" alt></p>
<p><a name="1845d1d2"></a></p>
<h4 id="F-35可靠性问题"><a href="#F-35可靠性问题" class="headerlink" title="F-35可靠性问题"></a><a href="#shztbe"></a>F-35可靠性问题</h4><p>即使一架F-35中队能够到达需要的地方，在需要它的时候，如果它不能飞行任务会有什么好处呢？这是F-35计划中最持久的问题之一。</p>
<p>该车队的可靠性记录非常糟糕 - 它未能实现许多临时可靠性目标，并且在2016年之前仍然如此。随着该计划进入最重要的运行测试阶段，真正担心飞机会不能经常飞行以满足测试时间表。还有人担心喷气式飞机在召唤战斗服务时能够多久飞行一次。<br>“可用性”衡量飞机在现场执行至少一次指定任务的频率。由于大多数飞机在1991年在波斯湾的沙漠风暴行动中取得了成功，这些服务努力维持其飞机可持续作战行动的80％可用率。这与测试机队为满足这一需求所需的速度相同。 IOT＆E时间表。<br>到目前为止，F-35计划甚至无法实现其60％可用性的临时目标。</p>
<p>2016年度车队平均可用率为52％。这是近几年来的一次改善，但DOT＆E警告称“增长既不稳定也不连续。”而且增长曲线落后于进度。将用于运行测试的飞机需要配备专门的仪器来测量性能。目前有17架喷气式飞机驻扎在加州爱德华兹空军基地。 2016年前9个月，该测试车队的平均可用率为48％。</p>
<p>有几个因素拖累了F-35机队的可用率。许多飞机不得不被送回仓库进行大修，这是该程序高并发水平的结果。例如，15 F-35A需要被送回以纠正制造缺陷，其中喷射燃料箱内的泡沫绝缘材料使铸造碎屑劣化成燃料。<br>其他大修是必要的，因为存在基本的设计缺陷，包括不满足寿命要求的主要结构部件，还有一些是由于飞机首次建造时已知缺乏的战斗能力设计的持续改进所驱动。 ”</p>
<p>即使飞机没有进行大修，它们也不会飞得太多。在可用的飞机中，它们可以分为两类：任务能力和完全任务能力。使命能力的飞机是那些准备进行至少一种任务的飞机，即使它只是一项训练任务;具有完全任务能力的飞机是准备执行飞机宣布能够执行的所有任务的飞机。后者是战斗准备飞机的真正衡量标准。</p>
<p>Mission Capable和Full Mission Capable F-35的可用率在去年有所下降。 2016财年的机队任务能力率为62％，低于2015财年的65％[DG3]。完全任务能力率仅为29％，而前一年为46％。</p>
<p>Gilmore的报告引用了分布式孔径系统，电子战系统，电光靶向系统和雷达等主要作战系统的失效，这是导致能力下降的最高驱动因素。值得注意的是，这些系统据说为F-35提供了独特的作战能力，这就是将F-35保持在地面上的系统 - 没有任何能力。<br>根据最近发布的年度运营成本图表，平均而言，2016年空军的F-35飞机每周只能飞行两架次。相比之下，F-16平均每周近三架次，A-10机队平均近四架次。 F-35需要大量的维护才能实现。</p>
<p>虽然官方发布的公开声明说维护人员在喷气式飞机上工作是多么容易，但DOT＆E报告描绘了不同的画面。</p>
<p>供应链问题已经迫使维护者蚕食飞机;从一架飞机上取下部件安装在另一架飞机上，以确保至少有一架飞机飞行。食人化具有增加进行修复的总时间的效果，因为它增加了从供体喷射器剥离部件的额外步骤，而不仅仅是从盒子中取出新的或修复过的部件。它还需要将部件安装两次：首先是在修复的喷射器中，然后是在拆卸的喷射器中。</p>
<p>对于2016财年，维护人员不得不拆掉几乎每10架次飞行一次的部件，这远远超过了计划中每100架次不超过8次拆分行动的不起眼的目标。</p>
<p>随着产量的增加，供应问题可能会减少，但基本设计问题将持续存在。 一个典型的例子是F-35隐形涂层固有的独特维护要求。 对隐形飞机进行一些修理需要更长的时间，因为需要时间去除低可观察到的材料，修复破损的物体，然后修复隐形皮肤。<br>这些修复通常涉及使用需要时间进行化学固化的粘合剂。 其中一些材料可能需要长达168小时 - 一整周 - 才能完全干燥。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545372168522-b9bd672b-4a02-4ff4-b2f7-1b713cb14d88.png#align=left&amp;display=inline&amp;height=498&amp;originHeight=1201&amp;originWidth=1800&amp;status=done&amp;width=826" alt></p>
<p><a name="fafd408e"></a></p>
<h3 id="官员隐瞒F-35问题和纳税人延误的真相"><a href="#官员隐瞒F-35问题和纳税人延误的真相" class="headerlink" title="官员隐瞒F-35问题和纳税人延误的真相"></a><a href="#rt9ngs"></a>官员隐瞒F-35问题和纳税人延误的真相</h3><p>当洛克希德·马丁在17年前首次赢得合同时，预计F-35将在2008年开始运行测试。一旦他们未能达到这一目标，2017年应该是战斗测试过程开始的重要一年。我们现在知道，这个过程几乎肯定会被推迟到2019年……甚至2020年。<br>DOT＆E报告的第一页列出了F-35的13个未解决的主要问题，这些问题将阻止该计划于2017年8月开始进行战斗测试。但你不会从负责官员的公开评论中得知这些问题。该程序。<br>在2月份众议院军事委员会小组委员会作证时，尽管DOT＆E报告在不到一个月前发布，但官员却没有向国会提出任何这些问题。<br>F-35的挑战规模在今年的DOT＆E分析中很容易量化。根据该报告，F-35仍然有276个“至关重要的”缺陷 - 这些必须在开发过程结束之前修复，因为它们可能“导致IOT＆E或战斗期间的操作任务失败”。<br>在276个中，有72个被列为“优先级1”，这些服务关键缺陷会阻止服务在固定之前部署喷气式飞机。<br>关于F-35在战斗中的缺点已经有很多，但基本机身仍然存在结构性问题。这方面的一个例子是喷气机的垂直尾翼和机身之间的连接接头失效。这是一个长期存在的问题，因为在原始设计中发现了缺点。<br>工程师在2010年的早期结构测试中发现用于加固接头的套管过早磨损。该接头在2014年进行了重新设计并纳入新飞机。        2016年9月，检查员发现重新设计的接头在经过250小时的飞行测试后失败了 - 远远低于JSF合同中规定的8,000个工作小时数。<br>2016年F-35任务系统的测试继续落后于计划。项目经理确定并预算基线测试点，或“在特定飞行测试条件下的性能离散测量”。<br>这些用于确定系统是否符合合同规范。测试团队还会出于各种原因添加非基线测试点，以全面评估整个系统。示例包括添加测试点以准备稍后的更复杂的测试，在软件更新后重新测试系统以确保新软件不会改变先前的结果，或“发现测试点”，这些测试点被添加以识别在其他测试期间发现问题的根本原因。<br>该计划为2016年F-35的任务系统预算了3,578个测试点。测试团队无法完成所有测试，完成3,041，同时还在全年增加了250个未预算的测试点。<br>尽管计划有所下滑，但F-35计划办公室已表示希望跳过许多所需的测试点，而是依赖测试以前飞行的数据 - 测试飞机使用早期软件版本 - 作为升级系统软件工作的证据。但DOT＆E警告说，较新的软件版本可能表现不同，使早期的结果没有实际意义。程序管理员基本上想要宣布开发测试过程并继续进行操作测试，即使他们还没有完成所有必要的步骤。<br>这是一个风险很大的举动。 DOT＆E警告说遵循这个计划。</p>
<p><em>“可能会导致IOT&amp;E失败，导致需要进行额外的后续运行测试，最重要的是，将Block 3F运送到能力严重不足的现场 - 如果需要F-35，该部门必须具备的能力 与当前威胁作斗争。“</em><br><br><br>程序办公室似乎在试图测试许多可能使F-35如此不可或缺的能力方面拖延了下来。<br>一个例子是开发验证模拟器（VSim）需要多长时间。洛克希德·马丁公司的工程师在2001年负责创建VSim设施，该设施旨在成为一个超现实的，经过全面测试验证的“人在环，任务系统软件在环仿真，旨在满足Block 3F IOT＆E的运行测试要求。“<br>也就是说，它旨在在虚拟现实中测试那些复杂而严谨的场景，这些场景在现实生活中不可能或太危险，而不是真正的战争。<br>承包商远远落后于建设计划，JPO在2015年放弃了VSim。相反，海军航空系统司令部的任务是建立一个政府运行的联合仿真环境（JSE）来执行VSim的任务。承包商应该提供飞机和传感器模型，但到目前为止“F-35模型的谈判尚未成功。”<br>这阻碍了该计划设计虚拟世界，其中F-35和敌方飞机和防御装置在现实世界中相互作用，造成进一步的延误。<br>没有经过适当准备的JSE，F-35无法完全测试。必须根据飞行试验期间收集的真实数据设计模拟，否则模拟只会测试承包商所说的喷气机可以做什么。<br>例如，真正的F-35必须飞越一个测试范围，我们的敌人使用相同的雷达系统是活跃的，以便它可以收集有关喷气式飞机的机载传感器如何反应的数据。该数据用于验证仿真软件。这是一个非常复杂的过程需要时间。正如DOT＆E报道的那样，“此前的努力已经花费了数年时间，因此NAVAIR不太可能及时按计划完成项目，以支持物联网和E。”<br>该计划还制定计划，以便在计划最需要时减少测试人员和测试飞机的数量。这些计划将使测试飞机的数量从18个减少到9个，测试人员从1,768减少到600。<br>吉尔摩尔在空军国际奥委会声明后不久报道该计划将无法在必要的最终配置中生产足够的F-35以进行操作测试。<br>“由于在开发测试期间需要很长的程序延迟和发现，因此需要进行大量修改，以便将装配过程中连接到飞行测试仪器的OT飞机纳入所需的生产代表配置中，”报告指出。<br>接着说，对23架飞机进行了超过155次改装，专门用于即将进行的战斗（“作战”）测试，其中一些甚至尚未签约，这意味着IOT和E的开始将更进一步延迟。</p>
<p><em>联合计划办公室不仅没有遵守其同意的运行测试计划，而且未能资助和测试进行测试所必需的设备。 这包括没有资金用于飞行测试数据采集记录和遥测舱，这是一种安装在F-35上的仪器，用于模拟飞机的武器。</em><br><br><br>这对于报告和分析每个模拟武器射击的结果至关重要。 在飞机在接合和武器测试期间飞行的条件下，在吊舱功能和安全性被清除之前，不能进行此类测试。<br>五角大楼和承包商是否会继续忽视有关F-35在测试中的表现以及看似无休止的延误的令人不快的信息，并试图在美国人民和他们的心中产生错误的印象，还有待观察。政策制定者。<br>在最近特朗普总统和五角大楼之间的交流中，似乎没有人在日本特别行政区引导总统注意除波格丹将军以外的任何人。 很明显，他没有和任何批评该计划的人谈过，比如Gilmore。 根据这份报告的结果，如果他有，那么很难看出任何人都可以诚实地说F-35是“太棒了”。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545372354038-3b796934-db9d-4360-a02c-bc95e017fa8c.png#align=left&amp;display=inline&amp;height=419&amp;originHeight=702&amp;originWidth=1250&amp;status=done&amp;width=826" alt></p>
<p><a name="abf376ae"></a></p>
<h4 id="向前进"><a href="#向前进" class="headerlink" title="向前进"></a><a href="#solnez"></a>向前进</h4><p>DOT＆E的最新报告更加证明F-35计划将在未来几年继续大量耗费时间和资源，并将为我们的武装部队提供一台二战战斗机，其执行任务不如它本来要取代的“传统”飞机。上天捍卫国家的男男女女应该得到更好的待遇。<br>尽管在华盛顿有传统智慧，但服务并不一定要坚持使用F-35。其他选项确实存在。<br>1.为了填补空对空中的近期空洞，启动一项计划，对所有可用的F-16A和F-18进行翻新和升级，使用寿命更长的机身和更高的推力F-110-GE- 132（F-16）和F-404-GE-402（F-18）发动机。使用功能更强大的现成电子系统升级其电子系统。</p>
<p>这将使我们的战斗机在空对空作战中比后来的F-16和F-18型号或F-35更有效。如果需要增加力量，从boneyard添加机身。最重要的是，将飞行员训练时间提高到每月30小时的最低可接受水平，部分原因是现在不购买欠发达的F-35而节省了资金。</p>
<p>2.为了填补近距离空中支援部队中更为严重的近期空洞，完成空军拒绝重新训练的100架A-10的重绕，然后通过整修/扩大现有的仅272架A-10的力量。将boneyard中所有可用的A-10重新调整为A-10C标准。</p>
<p>3.立即进行三个新的竞争性原型飞行计划，设计和建造一个更致命，更生存的近距离空中支援飞机，以取代A-10，并设计和建造两个不同的空对空战斗机，这些战斗机更小，更具战斗力 - 比F-16，F-22和F-18更有效。对所有配备雷达导弹和隐身对抗措施的合格敌人进行测试。<br>这些程序应该遵循20世纪70年代轻型战斗机和A-X计划的模式，特别是在实弹，现实情景竞争飞越测试方面。这些计划产生了F-16和A-10两架无可争议的高效飞机，每架飞机都比当时五角大楼的首选飞机便宜。他们在不到10年的时间内进行了测试，但不超过25年。</p>
<p>4.绝对最低限度，F-35测试程序已经到位，JPO和Gilmore同意必须执行以便在进一步生产之前理解这架飞机能够胜任和不能胜任的事情。这意味着暂停进一步的F-35生产，直到这些测试完成并诚实地报告给国防部长，总统和国会。</p>
<p><a name="54bbba80"></a></p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a><a href="#9mgopz"></a>结论</h4><p>F-35计划办公室已达到关键决策点。 现在需要采取大胆行动来挽救联合攻击战斗机这样的国家灾难。</p>
<p>政府应继续审查F-35计划。 但官员们不应该只是与将军和高管交谈，因为他们没有动力去讲述真相，因为他们在确保程序存活方面有着既得的经济利益 - 无论能力如何。</p>
<p>正如本报告所示，他们并没有讲述整个故事。 从其他观点来看，还有更多人在食物链中走下坡路。 他们是拥有真实故事的人。 而且，正如上述建议所示，仍有选择。</p>
<p>对于该计划进行重大改变还为时不晚，正如其维护者所声称的那样。</p>
<p>Dan Grazier是政府监督项目的Jack Shanahan研究员，这篇文章最初出现在那里。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/21/yuque/F-35是1.4万亿美元的国家灾难/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/Pytorch：如何以及何时使用Module，Sequential，ModuleList和ModuleDict" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/20/yuque/Pytorch：如何以及何时使用Module，Sequential，ModuleList和ModuleDict/">Pytorch：如何以及何时使用Module，Sequential，ModuleList和ModuleDict</a>
    </h1>
  

        
        <a href="/2018/12/20/yuque/Pytorch：如何以及何时使用Module，Sequential，ModuleList和ModuleDict/" class="archive-article-date">
  	<time datetime="2018-12-20T07:28:04.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-20</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>分享，重用和分解模型复杂性的有效方法</p>
<p>更新到 Pytorch 4.1版本</p>
<p>你可以找到代码 <a href="https://github.com/FrancescoSaverioZuppichini/Pytorch-how-and-when-to-use-Module-Sequential-ModuleList-and-ModuleDict" target="_blank" rel="noopener">here</a></p>
<p>Pytorch是一个开源的深度学习框架，提供了创建ML模型的智能方法。 即使文档制作完好，我仍然发现大多数人仍然能够编写错误的而不是有组织的PyTorch代码。</p>
<p>今天，我们将看到如何使用PyTorch的三个主要构建块：Module，Sequential和ModuleList。 我们将从一个例子开始，迭代地我们将使它变得更好。<br><br><br><br>所有这四个类都包含在torch.nn中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># nn.Module</span></span><br><span class="line"><span class="comment"># nn.Sequential</span></span><br><span class="line"><span class="comment"># nn.Module</span></span><br></pre></td></tr></table></figure>
<p><a name="puggyn"></a></p>
<h2 id="模块：主要构建块"><a href="#模块：主要构建块" class="headerlink" title="模块：主要构建块"></a><a href="#puggyn"></a>模块：主要构建块</h2><p>Module是主要的构建块，它定义了所有神经网络的基类，你必须将它子类化。<br><br><br><br>让我们创建一个经典的CNN分类器作为示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_c, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.bn2(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line"></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = F.sigmoid(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (fc1): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">  (fc2): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这是一个非常简单的分类器，其编码部分使用两层3x3 convs + batchnorm + relu和一个带有两个线性层的解码部分。 如果您不是PyTorch的新手，您可能以前看过这种类型的编码，但有两个问题。<br><br><br><br>如果我们想要添加一个图层，我们必须在<strong>init</strong>和forward函数中再次编写大量代码。 此外，如果我们有一些我们想要在另一个模型中使用的公共块，例如 3x3 conv + batchnorm + relu，我们必须再写一次。</p>
<p><a name="kpmyrn"></a></p>
<h2 id="Sequential：堆叠和合并图层"><a href="#Sequential：堆叠和合并图层" class="headerlink" title="Sequential：堆叠和合并图层"></a><a href="#kpmyrn"></a>Sequential：堆叠和合并图层</h2><p><a name="di8wcs"></a></p>
<h2 id><a href="#" class="headerlink" title></a><a href="#di8wcs"></a></h2><p>Sequential是一个模块的容器，可以堆叠在一起并同时运行。<br><br><br><br>你可以注意到我们必须将自己的一切存储起来。 我们可以使用Sequential来改进我们的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv_block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_c, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv_block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv_block1(x)</span><br><span class="line">        x = self.conv_block2(x)</span><br><span class="line"></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (conv_block1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): BatchNorm2d(<span class="number">32</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): ReLU()</span><br><span class="line">  )</span><br><span class="line">  (conv_block2): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): ReLU()</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): Sigmoid()</span><br><span class="line">    (<span class="number">2</span>): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>你觉得好多了？<br><br><br><br>您是否注意到conv_block1和conv_block2看起来几乎相同？ 我们可以创建一个重新生成nn.Sequential的函数来简化代码！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(in_f, out_f, *args, **kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_f, out_f, *args, **kwargs),</span><br><span class="line">        nn.BatchNorm2d(out_f),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>然后我们可以在我们的模块中调用此函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv_block1 = conv_block(in_c, <span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv_block2 = conv_block(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv_block1(x)</span><br><span class="line">        x = self.conv_block2(x)</span><br><span class="line"></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (conv_block1): Sequential(</span><br><span class="line">    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    (2): ReLU()</span><br><span class="line">  )</span><br><span class="line">  (conv_block2): Sequential(</span><br><span class="line">    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    (2): ReLU()</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">    (1): Sigmoid()</span><br><span class="line">    (2): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Even cleaner! Still <code>conv_block1</code> and <code>conv_block2</code> are almost the same! We can merge them using <code>nn.Sequential</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.encoder = nn.Sequential(</span><br><span class="line">            conv_block(in_c, <span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            conv_block(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): Sequential(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">    (1): Sigmoid()</span><br><span class="line">    (2): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><code>self.encoder</code> now holds booth <code>conv_block</code>. We have decoupled logic for our model and make it easier to read and reuse. Our <code>conv_block</code> function can be imported and used in another model.</p>
<p><a name="h5bzub"></a></p>
<h2 id="Dynamic-Sequential-create-multiple-layers-at-once"><a href="#Dynamic-Sequential-create-multiple-layers-at-once" class="headerlink" title="Dynamic Sequential: create multiple layers at once"></a><a href="#h5bzub"></a>Dynamic Sequential: create multiple layers at once</h2><p>What if we can to add a new layers in <code>self.encoder</code>, hardcoded them is not convinient:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.encoder = nn.Sequential(</span><br><span class="line">            conv_block(in_c, <span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            conv_block(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            conv_block(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            conv_block(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line"></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>Would it be nice if we can define the sizes as an array and automatically create all the layers without writing each one of them? Fortunately we can create an array and pass it to <code>Sequential</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.enc_sizes = [in_c, <span class="number">32</span>, <span class="number">64</span>]</span><br><span class="line">        </span><br><span class="line">        conv_blocks = [conv_block(in_f, out_f, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(self.enc_sizes, self.enc_sizes[<span class="number">1</span>:])]</span><br><span class="line">        </span><br><span class="line">        self.encoder = nn.Sequential(*conv_blocks)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): Sequential(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">    (1): Sigmoid()</span><br><span class="line">    (2): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Let’s break it down. We created an array <code>self.enc_sizes</code> that holds the sizes of our encoder. Then we create an array <code>conv_blocks</code> by iterating the sizes. Since we have to give booth a in size and an outsize for each layer we <code>zip</code>ed the size’array with itself by shifting it by one.</p>
<p>Just to be clear, take a look at the following example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sizes = [<span class="number">1</span>, <span class="number">32</span>, <span class="number">64</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> in_f,out_f <span class="keyword">in</span> zip(sizes, sizes[<span class="number">1</span>:]):</span><br><span class="line">    print(in_f,out_f)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 32</span><br><span class="line">32 64</span><br></pre></td></tr></table></figure>
<p>Then, since <code>Sequential</code> does not accept a list, we decompose it by using the <code>*</code> operator.</p>
<p>Tada! Now if we just want to add a size, we can easily add a new number to the list. It is a common practice to make the size a parameter.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, enc_sizes, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.enc_sizes = [in_c, *enc_sizes]</span><br><span class="line">        </span><br><span class="line">        conv_blokcs = [conv_block(in_f, out_f, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(self.enc_sizes, self.enc_sizes[<span class="number">1</span>:])]</span><br><span class="line">        </span><br><span class="line">        self.encoder = nn.Sequential(*conv_blokcs)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, [<span class="number">32</span>,<span class="number">64</span>, <span class="number">128</span>], <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): Sequential(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (2): Sequential(</span><br><span class="line">      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">    (1): Sigmoid()</span><br><span class="line">    (2): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>We can do the same for the decoder part</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dec_block</span><span class="params">(in_f, out_f)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Linear(in_f, out_f),</span><br><span class="line">        nn.Sigmoid()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, enc_sizes, dec_sizes,  n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.enc_sizes = [in_c, *enc_sizes]</span><br><span class="line">        self.dec_sizes = [<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, *dec_sizes]</span><br><span class="line"></span><br><span class="line">        conv_blokcs = [conv_block(in_f, out_f, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(self.enc_sizes, self.enc_sizes[<span class="number">1</span>:])]</span><br><span class="line">        </span><br><span class="line">        self.encoder = nn.Sequential(*conv_blokcs)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        dec_blocks = [dec_block(in_f, out_f) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(self.dec_sizes, self.dec_sizes[<span class="number">1</span>:])]</span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(*dec_blocks)</span><br><span class="line">        </span><br><span class="line">        self.last = nn.Linear(self.dec_sizes[<span class="number">-1</span>], n_classes)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, [<span class="number">32</span>,<span class="number">64</span>], [<span class="number">1024</span>, <span class="number">512</span>], <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): Sequential(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): Sequential(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Linear(in_features=25088, out_features=1024, bias=True)</span><br><span class="line">      (1): Sigmoid()</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Linear(in_features=1024, out_features=512, bias=True)</span><br><span class="line">      (1): Sigmoid()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (last): Linear(in_features=512, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>We followed the same pattern, we create a new block for the decoding part, linear + sigmoid, and we pass an array with the sizes. We had to add a <code>self.last</code> since we do not want to activate the output</p>
<p>Now, we can even break down our model in two! Encoder + Decoder</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, enc_sizes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv_blokcs = nn.Sequential(*[conv_block(in_f, out_f, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(enc_sizes, enc_sizes[<span class="number">1</span>:])])</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> self.conv_blokcs(x)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dec_sizes, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dec_blocks = nn.Sequential(*[dec_block(in_f, out_f) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(dec_sizes, dec_sizes[<span class="number">1</span>:])])</span><br><span class="line">        self.last = nn.Linear(dec_sizes[<span class="number">-1</span>], n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.dec_blocks()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, enc_sizes, dec_sizes,  n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.enc_sizes = [in_c, *enc_sizes]</span><br><span class="line">        self.dec_sizes = [<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, *dec_sizes]</span><br><span class="line"></span><br><span class="line">        self.encoder = MyEncoder(self.enc_sizes)</span><br><span class="line">        </span><br><span class="line">        self.decoder = MyDecoder(dec_sizes, n_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.flatten(<span class="number">1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, [<span class="number">32</span>,<span class="number">64</span>], [<span class="number">1024</span>, <span class="number">512</span>], <span class="number">10</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): MyEncoder(</span><br><span class="line">    (conv_blokcs): Sequential(</span><br><span class="line">      (0): Sequential(</span><br><span class="line">        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (2): ReLU()</span><br><span class="line">      )</span><br><span class="line">      (1): Sequential(</span><br><span class="line">        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (2): ReLU()</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): MyDecoder(</span><br><span class="line">    (dec_blocks): Sequential(</span><br><span class="line">      (0): Sequential(</span><br><span class="line">        (0): Linear(in_features=1024, out_features=512, bias=True)</span><br><span class="line">        (1): Sigmoid()</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (last): Linear(in_features=512, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Be aware that <code>MyEncoder</code> and <code>MyDecoder</code> could also be functions that returns a <code>nn.Sequential</code>. I prefer to use the first pattern for models and the second for building blocks.</p>
<p>By diving our module into submodules it is easier to <strong>share</strong> the code, <strong>debug</strong> it and <strong>test</strong> it.</p>
<p><a name="8xg9py"></a></p>
<h2 id="ModuleList-when-we-need-to-iterate"><a href="#ModuleList-when-we-need-to-iterate" class="headerlink" title="ModuleList : when we need to iterate"></a><a href="#8xg9py"></a>ModuleList : when we need to iterate</h2><p><code>ModuleList</code> allows you to store <code>Module</code> as a list. It can be useful when you need to iterate through layer and store/use some information, like in U-net.</p>
<p>The main difference between <code>Sequential</code> is that <code>ModuleList</code> have not a <code>forward</code> method so the inner layers are not connected. Assuming we need each output of each layer in the decoder, we can store it by:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sizes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([nn.Linear(in_f, out_f) <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(sizes, sizes[<span class="number">1</span>:])])</span><br><span class="line">        self.trace = []</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x)</span><br><span class="line">            self.trace.append(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = MyModule([<span class="number">1</span>, <span class="number">16</span>, <span class="number">32</span>])</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">model(torch.rand((<span class="number">4</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">[print(trace.shape) <span class="keyword">for</span> trace <span class="keyword">in</span> model.trace]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 16])</span><br><span class="line">torch.Size([4, 32])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[None, None]</span><br></pre></td></tr></table></figure>
<p><a name="f7epth"></a></p>
<h2 id="ModuleDict-when-we-need-to-choose"><a href="#ModuleDict-when-we-need-to-choose" class="headerlink" title="ModuleDict: when we need to choose"></a><a href="#f7epth"></a>ModuleDict: when we need to choose</h2><p>What if we want to switch to <code>LearkyRelu</code> in our <code>conv_block</code>? We can use <code>ModuleDict</code> to create a dictionary of <code>Module</code> and dynamically switch <code>Module</code> when we want</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(in_f, out_f, activation=<span class="string">'relu'</span>, *args, **kwargs)</span>:</span></span><br><span class="line">    </span><br><span class="line">    activations = nn.ModuleDict([</span><br><span class="line">                [<span class="string">'lrelu'</span>, nn.LeakyReLU()],</span><br><span class="line">                [<span class="string">'relu'</span>, nn.ReLU()]</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_f, out_f, *args, **kwargs),</span><br><span class="line">        nn.BatchNorm2d(out_f),</span><br><span class="line">        activations[activation]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(conv_block(<span class="number">1</span>, <span class="number">32</span>,<span class="string">'lrelu'</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">print(conv_block(<span class="number">1</span>, <span class="number">32</span>,<span class="string">'relu'</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (2): LeakyReLU(negative_slope=0.01)</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (2): ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a name="c51cxn"></a></p>
<h2 id="Final-implementation"><a href="#Final-implementation" class="headerlink" title="Final implementation"></a><a href="#c51cxn"></a>Final implementation</h2><p>Let’s wrap it up everything!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(in_f, out_f, activation=<span class="string">'relu'</span>, *args, **kwargs)</span>:</span></span><br><span class="line">    activations = nn.ModuleDict([</span><br><span class="line">                [<span class="string">'lrelu'</span>, nn.LeakyReLU()],</span><br><span class="line">                [<span class="string">'relu'</span>, nn.ReLU()]</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_f, out_f, *args, **kwargs),</span><br><span class="line">        nn.BatchNorm2d(out_f),</span><br><span class="line">        activations[activation]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dec_block</span><span class="params">(in_f, out_f)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Linear(in_f, out_f),</span><br><span class="line">        nn.Sigmoid()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, enc_sizes, *args, **kwargs)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv_blokcs = nn.Sequential(*[conv_block(in_f, out_f, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, *args, **kwargs) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(enc_sizes, enc_sizes[<span class="number">1</span>:])])</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> self.conv_blokcs(x)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dec_sizes, n_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dec_blocks = nn.Sequential(*[dec_block(in_f, out_f) </span><br><span class="line">                       <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> zip(dec_sizes, dec_sizes[<span class="number">1</span>:])])</span><br><span class="line">        self.last = nn.Linear(dec_sizes[<span class="number">-1</span>], n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.dec_blocks()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCNNClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_c, enc_sizes, dec_sizes,  n_classes, activation=<span class="string">'relu'</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.enc_sizes = [in_c, *enc_sizes]</span><br><span class="line">        self.dec_sizes = [<span class="number">32</span> * <span class="number">28</span> * <span class="number">28</span>, *dec_sizes]</span><br><span class="line"></span><br><span class="line">        self.encoder = MyEncoder(self.enc_sizes, activation=activation)</span><br><span class="line">        </span><br><span class="line">        self.decoder = MyDecoder(dec_sizes, n_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.encoder(x)</span><br><span class="line">        </span><br><span class="line">        x = x.flatten(<span class="number">1</span>) <span class="comment"># flat</span></span><br><span class="line">        </span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MyCNNClassifier(<span class="number">1</span>, [<span class="number">32</span>,<span class="number">64</span>], [<span class="number">1024</span>, <span class="number">512</span>], <span class="number">10</span>, activation=<span class="string">'lrelu'</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">MyCNNClassifier(</span><br><span class="line">  (encoder): MyEncoder(</span><br><span class="line">    (conv_blokcs): Sequential(</span><br><span class="line">      (0): Sequential(</span><br><span class="line">        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (2): LeakyReLU(negative_slope=0.01)</span><br><span class="line">      )</span><br><span class="line">      (1): Sequential(</span><br><span class="line">        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (2): LeakyReLU(negative_slope=0.01)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (decoder): MyDecoder(</span><br><span class="line">    (dec_blocks): Sequential(</span><br><span class="line">      (0): Sequential(</span><br><span class="line">        (0): Linear(in_features=1024, out_features=512, bias=True)</span><br><span class="line">        (1): Sigmoid()</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (last): Linear(in_features=512, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a name="8gyuvn"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a><a href="#8gyuvn"></a>Conclusion</h2><p>So, in summary.</p>
<ul>
<li><p>Use <code>Module</code> when you have a big block compose of multiple smaller blocks</p>
</li>
<li><p>Use <code>Sequential</code> when you want to create a small block from layers</p>
</li>
<li><p>Use <code>ModuleList</code> when you need to iterate through some layers or building blocks and do something</p>
</li>
<li><p>Use <code>ModuleDict</code> when you need to parametise some blocks of your model, for example an activation function</p>
</li>
</ul>
<p>That’s all folks!</p>
<p>Thank you for reading</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/20/yuque/Pytorch：如何以及何时使用Module，Sequential，ModuleList和ModuleDict/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/XGBoost不是黑魔法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/20/yuque/XGBoost不是黑魔法/">XGBoost不是黑魔法</a>
    </h1>
  

        
        <a href="/2018/12/20/yuque/XGBoost不是黑魔法/" class="archive-article-date">
  	<time datetime="2018-12-20T05:48:34.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-20</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/xgboost-is-not-black-magic-56ca013144b4" target="_blank" rel="noopener">链接</a></p>
<blockquote>
<p>而不是对缺失值进行估算并不总是正确的选择</p>
</blockquote>
<p><br>现在很容易在数据科学任务中获得不错的结果：只需要对流程有一个大致的了解，Python的基本知识和10分钟的时间来实例化XGBoost并适应模型。好的，如果这是你的第一次，那么你可能会花几分钟通过pip收集所需的包，但就是这样。这种方法的唯一问题是它运作得很好🤷🏻♂️：几年前我在大学竞赛中排名前5位，只是通过一些基本的特征工程将数据集提供给XGBoost，表现优于团队非常复杂的架构和数据管道。 XGBoost最酷的特征之一就是它如何处理缺失值：决定每个样本，这是最好的方法来判断它们。对于我在过去几个月中遇到的许多项目和数据集，此功能非常有用;为了更加值得以我的名义撰写的数据科学家的头衔，我决定深入挖掘，花几个小时阅读原始论文，试图了解XGBoost究竟是什么以及它如何处理它以某种神奇的方式缺少价值。<br><a name="9864342e"></a></p>
<h4 id="从决策树到XGBoost"><a href="#从决策树到XGBoost" class="headerlink" title="从决策树到XGBoost"></a><a href="#7vdtxk"></a>从决策树到XGBoost</h4><p>决策树可能是机器学习中最简单的算法：树的每个节点都是对特征的测试，每个分支代表测试的结果; leaves包含模型的输出，无论是离散标签还是实数。 决策树可能被描述为一个功能：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285357509-9eb19212-1f84-4151-925f-695f322ba1a9.png#align=left&amp;display=inline&amp;height=64&amp;originHeight=78&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br>函数f根据从根到叶子的路径，根据树结构T分配m大小的样本x所遵循的权重w。<br>现在想象一下，不只有一棵决策树而且还有K; 最终产生的输出不再是与叶子相关的权重，而是与每棵树产生的叶子相关的权重之和。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285385079-d2797243-1542-4e33-8215-bde9adc10d39.png#align=left&amp;display=inline&amp;height=104&amp;originHeight=126&amp;originWidth=1000&amp;status=done&amp;width=826" alt></p>
<p>这些结构不是固定的，并且与网络结构不变的经典梯度下降框架中发生的不同，并且在每个步骤更新权重时，在每次迭代时添加新函数（树）以改善模型的性能。 为了避免过度拟合和/或非常复杂的结构，误差由两部分组成：第一部分对在第k次迭代中获得的模型的优度进行评分，第二部分在相关权重的大小中惩罚复杂性。 叶子和发达的树木的深度和结构。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285422201-bef8962d-373e-4670-8789-f8fffb46cbc2.png#align=left&amp;display=inline&amp;height=126&amp;originHeight=152&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br>然后使用二阶梯度统计简化该目标函数，并且 - 不输入太多细节 - 可以直接用于以封闭形式计算与固定树结构相关联的最佳叶子权重。 权重可以直接与错误相关联，因此与所使用的固定结构的优点相关联（3）。<br>训练XGBoost是一个迭代过程，它在每个步骤计算第k个树的最佳可能分割，该第k个树枚举路径中该点仍然可用的所有可能结构。 所有可能的分裂的详尽列举非常适合本文的范围，但在实践中是不可行的，并且它被一个近似版本所取代，该版本不会尝试所有可能的分裂，而是根据百分位数列举相关的分裂。 每个功能分布。<br><a name="3ca234a7"></a></p>
<h3 id="XGBoost和缺失值：魔术发生的地方"><a href="#XGBoost和缺失值：魔术发生的地方" class="headerlink" title="XGBoost和缺失值：魔术发生的地方"></a><a href="#e5q4ag"></a>XGBoost和缺失值：魔术发生的地方</h3><p>一旦树结构被训练，就不难考虑测试集中是否存在缺失值：它足以将默认方向附加到每个决策节点。如果缺少样本的特征并且决策节点在该特征上分裂，则路径采用分支的默认方向并且路径继续。但是为每个分支分配默认方向更复杂，这可能是本文中最有趣的部分。<br>已经解释的拆分查找算法可以稍微调整一下，不仅返回每一步的最佳拆分，而且还返回分配给新插入的决策节点的默认方向。给定一个特征集I，枚举所有可能的分割，但是现在相应的丢失不会被计算一次而是两次，每个默认方向一次丢失该特征的缺失值。两者中最好的是根据特征m的值j进行分割时分配的最佳默认方向。最佳分割仍然是最大化计算分数的分割，但现在我们已经为其附加了默认方向。<br>这种算法被称为稀疏感知的分裂发现，它是XGBoost背后的许多魔力所在。最后不要太复杂。稀疏性感知方法仅保证在已经遍历的分裂的情况下平均采用默认方向导致最佳可能结果，并不保证已经遍历的分裂（可能通过采用默认方向来解决）是最好的考虑整个样本。如果样本中缺失值的百分比增加，则内置策略的性能可能会恶化很多。</p>
<blockquote>
<p><em>好的，默认方向是最佳选择，只要它到达当前位置，但考虑到当前样本的所有特征，无法保证当前位置是最佳情况。</em></p>
</blockquote>
<p>克服此限制意味着处理同时考虑其所有特征的样本，并直接处理同一实现中可能同时存在多个缺失值。<br><a name="14ec9de9"></a></p>
<h3 id="改变缺失值并改善表现"><a href="#改变缺失值并改善表现" class="headerlink" title="改变缺失值并改善表现"></a><a href="#z5afml"></a>改变缺失值并改善表现</h3><p>为了击败XGBoost内置策略，我们必须同时考虑样本的所有功能，并以某种方式处理可能存在的缺失值。 这种方法的一个很好的例子是K-Nearest Neighbors（KNN），它具有ad-hoc距离度量以正确处理缺失值。 一般而言，KNN是众所周知的算法，其将K（例如，3,10,50，……）最接近的样本检索到所考虑的样本。 它可以用于对看不见的输入进行分类或者用于估算缺失值，在分配给目标值的情况下，考虑K个最近邻居的均值或中值。 这种方法需要距离度量（或相应地，相似性度量）来实际对训练集中的所有样本进行排序并检索最相似的K.<br>要超越XGBoost内置默认策略，我们需要两件事：</p>
<ul>
<li>考虑缺失值的距离指标（感谢AirBnb的这篇<a href="https://medium.com/airbnb-engineering/overcoming-missing-values-in-a-random-forest-classifier-7b1fc1fc03ba" target="_blank" rel="noopener">文章</a>的灵感）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_with_miss</span><span class="params">(a,b,l=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span>(len(a) != len(b)):</span><br><span class="line">        <span class="keyword">return</span> np.inf</span><br><span class="line">    ls = l * np.ones(len(a))</span><br><span class="line">    msk = ~ (np.isnan(a) | np.isnan(b))</span><br><span class="line">    res = np.sum((np.abs(a-b)[msk]))+np.sum((ls[~msk]))</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<ul>
<li>规范化数据集以获得有意义的距离，获得了不同域之间特征之间的差异（XGBoost并不严格要求，但KNN估算需要它！）。</li>
</ul>
<p>使用K个最接近样本的所述特征的中值来估算特征的缺失值，并且在非特定情况下，在K个检索的邻居中不发现至少一个非缺失值，整个列的中值 用来。<br><a name="cd474133"></a></p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><a href="#kp0eey"></a>实验结果</h3><p>我使用scikit-learn中免费提供的三个众所周知的数据集（两个分类和一个回归）进行了一些测试。 通过k-fold交叉验证比较三种不同的插补策略，测量了性能：</p>
<ul>
<li><p>XGBoost算法中内置的默认值</p>
</li>
<li><p>一个简单的列中位插值</p>
</li>
<li><p>一个KNN，如前一段所述</p>
</li>
</ul>
<p>对于KNN案例，我已经绘制了针对考虑的缺失值百分比获得的最佳性能，其中k与（要考虑的邻居的数量）和λ（当至少一个特征缺失时要添加到距离的常数） 两个样本）。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285831963-0ba52730-2b35-4d6a-9581-f84258cd72e8.png#align=left&amp;display=inline&amp;height=206&amp;originHeight=249&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br>使用稀疏性感知KNN来估算缺失值与其他两种方法的表现一致。 差异的程度当然是数据集依赖的。 作为第一个天真的结论：数据集的质量越低，更好的插补策略的影响越大。 如图2所示，内置策略最终具有接近于平凡的列中值插值的性能。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285859844-3faa8e2e-ebc5-4521-adb5-28b05b251281.png#align=left&amp;display=inline&amp;height=183&amp;originHeight=222&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br>看看k和λ如何影响最终结果以及如何引入惩罚因素不仅仅是纸上谈兵，这是非常有趣的。 距离度量不仅丢弃缺失值而且还为每一个增加权重对于用该方法获得的性能是至关重要的，即使其值与缺失值的增加百分比不直接相关。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545285901042-1590c9c8-9d75-42b3-b76d-3810e74a8f62.png#align=left&amp;display=inline&amp;height=247&amp;originHeight=299&amp;originWidth=1000&amp;status=done&amp;width=826" alt><br>测试表明，根据经验，缺失值的数量越多，为更好的插补而考虑的邻居数量越多。 再次，一个非常直观的结论。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/20/yuque/XGBoost不是黑魔法/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/认识和实现：批量标准化" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/认识和实现：批量标准化/">认识和实现：批量标准化</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/认识和实现：批量标准化/" class="archive-article-date">
  	<time datetime="2018-12-19T14:43:17.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b" target="_blank" rel="noopener">链接</a><br>在本文中，我将回顾Ioffe和Svegedy的批量规范化的有用性。 我还将在Keras中实现批量标准化，并在训练性能方面取得实质性进展。<br><a name="worndf"></a></p>
<h3 id="批量归一化的直观解释"><a href="#批量归一化的直观解释" class="headerlink" title="批量归一化的直观解释"></a><a href="#worndf"></a>批量归一化的直观解释</h3><p><a name="iegmed"></a></p>
<h3 id="训练中的问题"><a href="#训练中的问题" class="headerlink" title="训练中的问题"></a><a href="#iegmed"></a>训练中的问题</h3><p>问题1：随着网络训练，早期层的权重发生变化，因此后期层的输入变化很大。 每层必须根据每批输入的不同分布重新调整其权重。 这减缓了模型训练。 如果我们可以在分布中使层输入更相似，那么网络可以专注于学习类之间的差异。<br>不同批次分布的另一个影响是消失的梯度。 消失的梯度问题是一个大问题，特别是对于S形激活函数。 如果g（x）表示sigmoid激活函数，则为| x | 增加，g’（x）趋于零。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230849299-89520b64-5633-46b5-a7ab-8343e37bce6d.png#width=731" alt><br>问题2.当输入分布变化时，神经元输出也会变化。 这导致神经元输出偶尔波动到S形函数的可饱和区域。 在那里，神经元既不能更新自己的权重，也不能将梯度传递回先前的层。 我们如何保持神经元输出不变为可饱和区域？</p>
<p>如果我们可以将神经元输出限制在零附近的区域，我们可以确保每个层在反向传播期间都会传回一个实质的梯度。 这将导致更快的训练时间和更准确的结果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230974089-30772f12-78be-446d-ac94-1f658676b64c.png#width=731" alt><br><a name="laeagu"></a></p>
<h4 id="批量标准作为解决方案。"><a href="#批量标准作为解决方案。" class="headerlink" title="批量标准作为解决方案。"></a><a href="#laeagu"></a>批量标准作为解决方案。</h4><p>批量标准化减轻了不同层输入的影响。 通过归一化神经元的输出，激活函数将仅接收接近零的输入。 这确保了非消失的梯度，解决了第二个问题。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231047448-2503dee7-466f-4472-a4d3-d4051a58af2f.png#width=747" alt><br>批量归一化将层输出转换为单位高斯分布。 当这些输出通过激活功能馈送时，层激活也将变得更加正常分布。<br>由于一层的输出是下一层的输入，因此层输入现在具有明显较小的批次间差异。 通过减少层输入的变化分布，我们解决了第一个问题。<br><a name="6w4qpz"></a></p>
<h3 id="数学解释"><a href="#数学解释" class="headerlink" title="数学解释"></a><a href="#6w4qpz"></a>数学解释</h3><p>通过批量归一化，我们为每个激活函数寻找以零为中心的单位方差分布。 在训练期间，我们采用激活输入x并将其减去批次均值μ以实现零中心分布。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231155587-c517033a-5650-4858-8dc8-fe71e96bb8f0.png#width=204" alt><br>接下来，我们取x并将其除以批量方差和一个小数，以防止除以零σ+ε。 这可确保所有激活输入分布都具有单位差异。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231189951-b72be3c8-1a47-42a5-bd6d-04e2ba9a6006.png#width=215" alt><br>最后，我们将x hat进行线性转换以缩放并移动批量标准化的输出。 尽管在反向传播期间网络发生了变化，但仍能确保保持这种正常化效果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231250609-5da7503e-4334-4d00-9e24-61689bab04a2.png#width=231" alt><br>在测试模型时，我们不使用批处理均值或方差，因为这会破坏模型。 （提示：单个观察的平均值和方差是多少？）相反，我们计算训练群体的移动平均值和方差估计值。 这些估计值是培训期间计算的所有批次平均值和方差的平均值。<br><a name="kg00mo"></a></p>
<h3 id="批量标准化的好处"><a href="#批量标准化的好处" class="headerlink" title="批量标准化的好处"></a><a href="#kg00mo"></a>批量标准化的好处</h3><p>批量标准化的好处如下。<br>1.有助于防止具有可饱和非线性（sigmoid，tanh等）的网络中的消失梯度<br>通过批量标准化，我们确保任何激活函数的输入不会变为可饱和区域。 批量归一化将这些输入的分布转换为单位高斯（零中心和单位方差）。<br>2.规范模型<br>也许。 Ioffe和Svegeddy提出了这一主张，但没有就此问题进行广泛撰写。 也许这是归一化层输入的结果？<br>3.允许更高的学习率<br>通过在训练期间防止梯度消失的问题，我们可以设置更高的学习率。 批量标准化还降低了对参数标度的依赖性。 较大的学习速率可以增加层参数的规模，这导致梯度在反向传播期间回传时放大。 我需要阅读更多关于此的内容。<br><a name="5qelzv"></a></p>
<h3 id="在Keras实施"><a href="#在Keras实施" class="headerlink" title="在Keras实施"></a><a href="#5qelzv"></a>在Keras实施</h3><p>引入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import keras</span><br><span class="line">from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.image as mpimg</span><br><span class="line"></span><br><span class="line">from keras.models import Model, Sequential</span><br><span class="line">from keras.layers import Input</span><br><span class="line"></span><br><span class="line">from keras.callbacks import ModelCheckpoint, EarlyStopping</span><br><span class="line">from keras.layers import BatchNormalization</span><br><span class="line">from keras.layers import GlobalAveragePooling2D</span><br><span class="line">from keras.layers import Activation</span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D, Dense</span><br><span class="line">from keras.layers import MaxPooling2D, Dropout, Flatten</span><br><span class="line"></span><br><span class="line">import time</span><br></pre></td></tr></table></figure></p>
<p>数据加载和预处理<br>在这笔记本中，我们使用Cifar 100数据集，因为它具有相当的挑战性，并且不会永远用于训练。 唯一的预处理是零中心和图像变化发生器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">from keras.datasets import cifar100</span><br><span class="line">from keras.utils import np_utils</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode=&apos;fine&apos;)</span><br><span class="line"></span><br><span class="line">#scale and regularize the dataset</span><br><span class="line">x_train = (x_train-np.mean(x_train))</span><br><span class="line">x_test = (x_test - x_test.mean())</span><br><span class="line"></span><br><span class="line">x_train = x_train.astype(&apos;float32&apos;)</span><br><span class="line">x_test = x_test.astype(&apos;float32&apos;)</span><br><span class="line"></span><br><span class="line">#onehot encode the target classes</span><br><span class="line">y_train = np_utils.to_categorical(y_train)</span><br><span class="line">y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">        shear_range=0.2,</span><br><span class="line">        zoom_range=0.2,</span><br><span class="line">        horizontal_flip=True)</span><br><span class="line"></span><br><span class="line">train_datagen.fit(x_train)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow(x_train,</span><br><span class="line">                                     y = y_train,</span><br><span class="line">                                    batch_size=80,)</span><br></pre></td></tr></table></figure></p>
<p><a name="kl8xlg"></a></p>
<h3 id="在Keras中构建模型"><a href="#在Keras中构建模型" class="headerlink" title="在Keras中构建模型"></a><a href="#kl8xlg"></a>在Keras中构建模型</h3><p>我们的架构将包括堆叠的3x3卷积，然后是最大池化和dropout。 每个网络中有5个卷积块。 最后一层是一个完全连接的层，有100个节点和softmax激活。<br>我们将构建4个不同的卷积网络，每个网络都具有sigmoid或ReLU激活以及批量标准化或不标准化。 我们将比较每个网络的验证损失。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">def conv_block_first(model, bn=True, activation=&quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    The first convolutional block in each architecture. Only    separate so we can specify the input shape.</span><br><span class="line">    &quot;&quot;&quot;    </span><br><span class="line">   #First Stacked Convolution</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;, input_shape =   x_train.shape[1:]))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line">    #Second Stacked Convolution</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(MaxPooling2D())</span><br><span class="line">    model.add(Dropout(0.15))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def conv_block(model, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Generic convolutional block with 2 stacked 3x3 convolutions, max pooling, dropout, </span><br><span class="line">    and an optional Batch Normalization.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(MaxPooling2D())</span><br><span class="line">    model.add(Dropout(0.15))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def conv_block_final(model, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    I bumped up the number of filters in the final block. I made this separate so that I might be able to integrate Global Average Pooling later on. </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Conv2D(100,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(100,3, padding = &quot;same&quot;))</span><br><span class="line">    if bn:</span><br><span class="line">        model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(activation))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def fn_block(model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    I&apos;m not going for a very deep fully connected block, mainly so I can save on memory.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.add(Dense(100, activation = &quot;softmax&quot;))</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def build_model(blocks=3, bn=True, activation = &quot;sigmoid&quot;):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Builds a sequential network based on the specified parameters.</span><br><span class="line">    </span><br><span class="line">    blocks: number of convolutional blocks in the network, must be greater than 2.</span><br><span class="line">    bn: whether to include batch normalization or not.</span><br><span class="line">    activation: activation function to use throughout the network.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model = conv_block_first(model, bn=bn, activation=activation)</span><br><span class="line"></span><br><span class="line">    for block in range(1,blocks-1):</span><br><span class="line">        model = conv_block(model, bn=bn, activation = activation)</span><br><span class="line"></span><br><span class="line">    model = conv_block_final(model, bn=bn, activation=activation)</span><br><span class="line">    model = fn_block(model)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">def compile_model(model, optimizer = &quot;rmsprop&quot;, loss = &quot;categorical_crossentropy&quot;, metrics = [&quot;accuracy&quot;]):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Compiles a neural network.</span><br><span class="line">    </span><br><span class="line">    model: the network to be compiled.</span><br><span class="line">    optimizer: the optimizer to use.</span><br><span class="line">    loss: the loss to use.</span><br><span class="line">    metrics: a list of keras metrics.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    model.compile(optimizer = optimizer,</span><br><span class="line">                 loss = loss,</span><br><span class="line">                 metrics = metrics)</span><br><span class="line">    return model</span><br><span class="line">#COMPILING THE 4 MODELS</span><br><span class="line">sigmoid_without_bn = build_model(blocks = 5, bn=False, activation = &quot;sigmoid&quot;)</span><br><span class="line">sigmoid_without_bn = compile_model(sigmoid_without_bn)</span><br><span class="line"></span><br><span class="line">sigmoid_with_bn = build_model(blocks = 5, bn=True, activation = &quot;sigmoid&quot;)</span><br><span class="line">sigmoid_with_bn = compile_model(sigmoid_with_bn)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">relu_without_bn = build_model(blocks = 5, bn=False, activation = &quot;relu&quot;)</span><br><span class="line">relu_without_bn = compile_model(relu_without_bn)</span><br><span class="line"></span><br><span class="line">relu_with_bn = build_model(blocks = 5, bn=True, activation = &quot;relu&quot;)</span><br><span class="line">relu_with_bn = compile_model(relu_with_bn)</span><br></pre></td></tr></table></figure></p>
<p><a name="c4xpfd"></a></p>
<h3 id="模特训练"><a href="#模特训练" class="headerlink" title="模特训练"></a><a href="#c4xpfd"></a>模特训练</h3><p>没有批量标准化的Sigmoid<br>训练陷入困境。 有100个课程，这个模型从未达到比随机猜测更好的性能（10％准确度）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history1 = sigmoid_without_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        epochs=20,</span><br><span class="line">        verbose=0,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231717659-060d4678-06bf-4045-abc1-cd7ce7cb6c77.png#width=743" alt><br><a name="m0uloq"></a></p>
<h3 id="具有批量标准化的Sigmoid"><a href="#具有批量标准化的Sigmoid" class="headerlink" title="具有批量标准化的Sigmoid"></a><a href="#m0uloq"></a>具有批量标准化的Sigmoid</h3><p>与没有批量标准化不同，该模型在训练期间开始实施。 这可能是批量标准化减轻消失梯度的结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history2 = sigmoid_with_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        verbose=0,</span><br><span class="line">        epochs=20,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231810973-aebf7896-6c50-4d6c-8372-702891142c6f.png#width=724" alt><br><a name="w5h1ml"></a></p>
<h3 id="没有批量标准化的ReLU"><a href="#没有批量标准化的ReLU" class="headerlink" title="没有批量标准化的ReLU"></a><a href="#w5h1ml"></a>没有批量标准化的ReLU</h3><p>在没有批量规范的情况下实施ReLU导致一些初始收益，然后收敛到非最优的局部最小值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history3 = relu_without_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        epochs=20,</span><br><span class="line">        verbose=0,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231864866-451c1cd9-d6ae-4f7e-9aa2-1da0b34f889b.png#width=737" alt><br>具有批量标准化的ReLU<br>与sigmoid模型一样，批量标准化提高了该网络的训练能力。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history4 = relu_with_bn.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=2000,</span><br><span class="line">        verbose=0,</span><br><span class="line">        epochs=20,</span><br><span class="line">        validation_data=(x_test, y_test),</span><br><span class="line">        callbacks = [model_checkpoint])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231931611-3c026d90-61b0-41df-b4dc-7a538bf01ce6.png#width=730" alt><br><a name="e5gkmq"></a></p>
<h3 id="比较架构"><a href="#比较架构" class="headerlink" title="比较架构"></a><a href="#e5gkmq"></a>比较架构</h3><p>我们在这里清楚地看到批量标准化的好处。 没有批量标准化的ReLU和S形模型都无法保持训练性能提升。 这可能是渐变消失的结果。 具有批量标准化的体系结构训练得更快，并且比没有批量标准化的体系结构表现更好。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545231970491-afc0113d-a1fb-4218-90d5-7104d35cb98b.png#width=724" alt><br><a name="0457"></a></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a><a href="#0457"></a>Conclusion</h3><p>结论<br>批量标准化减少了训练时间并提高了神经网络的稳定性。 此效果适用于sigmoid和ReLU激活功能。 原帖可以在我的<a href="https://www.harrisonjansma.com/" target="_blank" rel="noopener">网站</a>上找到，代码可以在我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/tree/master/07-28-18-Implementing-Batch-Norm" target="_blank" rel="noopener">GitHub</a>上找到。<br><a name="f6b6"></a></p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a><a href="#f6b6"></a>Resources</h3><ul>
<li><p>Original paper by Ioffe and Szegedy. <a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">here.</a></p>
</li>
<li><p>Insert a batch normalization before or after nonlinearities? <a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="noopener">Usage explanation</a></p>
</li>
<li><p>For an explanation of the math and implementation in TensorFlow. <a href="https://towardsdatascience.com/pitfalls-of-batch-norm-in-tensorflow-and-sanity-checks-for-training-networks-e86c207548c8" target="_blank" rel="noopener">Pitfalls of Batch Norm</a></p>
</li>
<li><p>Also this post <a href="https://towardsdatascience.com/how-to-use-batch-normalization-with-tensorflow-and-tf-keras-to-train-deep-neural-networks-faster-60ba4d054b73" target="_blank" rel="noopener">How to use Batch Normalization with TensorFlow and tf.keras</a></p>
</li>
</ul>
<p><a name="3277"></a></p>
<h3 id="Further-reading"><a href="#Further-reading" class="headerlink" title="Further reading"></a><a href="#3277"></a>Further reading</h3><p>Below are some more recent research papers that extend Ioffe and Svegedy’s work.<br><a href="https://arxiv.org/abs/1702.03275v2" target="_blank" rel="noopener">[1]</a> How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)<br><a href="https://arxiv.org/abs/1702.03275v2" target="_blank" rel="noopener">[2]</a> Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models<br><a href="https://arxiv.org/abs/1607.06450v1" target="_blank" rel="noopener">[3]</a> Layer Normalization<br><a href="https://arxiv.org/abs/1602.07868v3" target="_blank" rel="noopener">[4]</a> Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks<br><a href="https://arxiv.org/abs/1803.08494v3" target="_blank" rel="noopener">[5]</a> Group Normalization</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/认识和实现：批量标准化/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/不要在卷积网络中使用Dropout" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/">不要在卷积网络中使用Dropout</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/" class="archive-article-date">
  	<time datetime="2018-12-19T14:04:13.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16" target="_blank" rel="noopener">链接</a></p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545228300354-eac11f1e-9363-4b7f-a68d-3b8e81fd80e0.png#width=747" alt><br>如果您想知道如何使用dropout，这里有您要的答案。</p>
<p>我注意到有很多资源可以用来学习深度学习的内容和原因。 不幸的是，当需要制作模型时，他们很少有资源来解释何时以及如何。<br>我正在为试图实施深度学习的其他数据科学家撰写本文。 因此，您不必像我一样通过研究文章和Reddit讨论。<br>在本文中，您将了解为什么dropout在卷积体系结构中不再受欢迎。</p>
<p><a name="drs4ub"></a></p>
<h4 id="DROPOUT"><a href="#DROPOUT" class="headerlink" title="DROPOUT"></a><a href="#drs4ub"></a>DROPOUT</h4><p>如果你正在读这篇文章，我认为你已经了解了什么是dropout，以及它在正则化神经网络方面的作用。 如果您想要复习，请阅读Amar Budhiraja的这篇文章。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545228517714-8daebec1-a6f7-4fcc-b4a8-8c826e025c76.png#width=747" alt><br>通常，当我们的网络存在过度拟合的风险时，我们只需要实现正规化。 如果网络太大，如果您训练时间过长，或者您没有足够的数据，则会发生这种情况。<br>如果在卷积网络末端有完全连接的层，则实现dropout很容易。<br><a name="qseuim"></a></p>
<h4 id="使用Keras"><a href="#使用Keras" class="headerlink" title="使用Keras"></a><a href="#qseuim"></a>使用Keras</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dropout(rate, noise_shape=None, seed=None)</span><br></pre></td></tr></table></figure>
<p>以0.5的dropout率开始并将其调低，直到性能最大化。 （<a href="https://www.reddit.com/r/MachineLearning/comments/3oztvk/why_50_when_using_dropout/" target="_blank" rel="noopener">资源</a>）<br><a name="dx1bhs"></a></p>
<h4 id="例如"><a href="#例如" class="headerlink" title="例如"></a><a href="#dx1bhs"></a>例如</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model=keras.models.Sequential()</span><br><span class="line">model.add(keras.layers.Dense(150, activation=&quot;relu&quot;))</span><br><span class="line">model.add(keras.layers.Dropout(0.5))</span><br></pre></td></tr></table></figure>
<p>请注意，这仅适用于您的convnet的完全连接区域。 对于所有其他地区，您不应使用dropout。<br>相反，您应该在卷积之间插入批量标准化。 这将使您的模型正常化，并使您的模型在训练期间更加稳定。<br><a name="042axx"></a></p>
<h4 id="批正则化"><a href="#批正则化" class="headerlink" title="批正则化"></a><a href="#042axx"></a>批正则化</h4><p>批标准化是规范卷积网络的另一种方法。<br>除了正则化效应之外，批量归一化还可以使您的卷积网络在训练期间抵抗消失的梯度。 这可以减少训练时间并获得更好的性能。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229002104-b14e8bf0-9ba5-4470-85c3-ac86fed74c75.png#width=747" alt><br>批量标准化可以消除消失的梯度<br><br><br></p>
<p><a name="uat1zt"></a></p>
<h4 id="Keras实施"><a href="#Keras实施" class="headerlink" title="Keras实施"></a><a href="#uat1zt"></a>Keras实施</h4><p>要在Keras中实现批量标准化，请使用以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.BatchNormalization()</span><br></pre></td></tr></table></figure></p>
<p>构建具有批量规范化的卷积体系结构时：</p>
<ul>
<li><p>在卷积和激活层之间插入批量标准化层。 （<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="noopener">资源</a>）</p>
</li>
<li><p>您可以在此功能中调整一些超参数，并使用它们。</p>
</li>
</ul>
<p>您也可以在激活功能之后插入批量标准化，但根据我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">经验</a>，这两种方法都具有相似的性能。<br><a name="i9denc"></a></p>
<h4 id="例如-1"><a href="#例如-1" class="headerlink" title="例如"></a><a href="#i9denc"></a>例如</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.add(Conv2D(60,3, padding = &quot;same&quot;))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Activation(&quot;relu&quot;))</span><br></pre></td></tr></table></figure>
<p>批量标准化取代了dropout。<br>即使您不需要担心过度拟合，实现批量标准化也有很多好处。 正因为如此，它的正规化效应，批量归一化已经在很大程度上取代了现代卷积体系结构中的dropout。<br>“我们提出了一种使用批量规范化网络构建，训练和执行推理的算法。 由此产生的网络可以通过饱和非线性进行训练，更能容忍增加的训练率，并且通常不需要Dropout进行正规化。“ -  Ioffe and Svegedy 2015<br>至于为什么dropout在最近的应用中失宠，主要有两个原因。<br><strong>首先</strong>，在对卷积层进行正则化时，dropout通常不太有效。<br>原因？ 由于卷积层具有很少的参数，因此它们开始时需要较少的正则化。 此外，由于在特征图中编码的空间关系，激活可以变得高度相关。 这使得dropout无效。（<a href="https://www.reddit.com/r/MachineLearning/comments/5l3f1c/d_what_happened_to_dropout/" target="_blank" rel="noopener">资源</a>）<br><strong>其次</strong>，擅长正规化的dropout现在已经过时了。<br>像VGG16这样在网络末端包含完全连接的层的大型模型。 对于这样的模型，过度拟合是通过在完全连接的层之间包括dropout来解决的。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229692686-cc1c012c-7f9a-4865-b6eb-fe547e0f1213.png#width=470" alt><br>不幸的是，<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">最近的架构</a>远离了这个完全连接块。<br>通过用全局平均池替换密集层，现代的网络可以减少模型大小，同时提高性能。<br>我将在未来再写一篇文章，详细说明如何在卷积网络中实现全球平均汇集。 在此之前，我建议阅读<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">ResNet论文</a>，以了解GAP的好处。<br><a name="btyoyw"></a></p>
<h4 id="一个实验"><a href="#一个实验" class="headerlink" title="一个实验"></a><a href="#btyoyw"></a>一个实验</h4><p>我创建了一个实验来测试批量标准化是否会减少在卷积之间插入时的泛化错误。 （<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">链接</a>）<br>我构建了5个相同的卷积体系结构，并在卷积之间插入了dropout，批量规范或任何（控制）。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545229984300-3501e371-42ce-41de-8aec-2d6962959cd3.png#width=500" alt><br>通过在Cifar100数据集上训练每个模型，我获得了以下结果。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545230018898-2895598f-bf57-42f7-ad4f-b7440add1220.png#width=724" alt><br>批量标准化模型的良好表现说明应在卷积之间使用批量标准化。<br>此外，不应在卷基层之间放置dropout，因为dropout的模型往往比控制模型表现更差。<br>有关更多信息，请查看我的<a href="https://github.com/harrisonjansma/Research-Computer-Vision/blob/master/08-12-18%20Batch%20Norm%20vs%20Dropout/08-12-18%20Batch%20Norm%20vs%20Dropout.ipynb" target="_blank" rel="noopener">GitHub</a>上的完整文章。<br>小贴士<br>如果你想知道是否应该在卷积网络中实现dropout，现在你知道了。 仅在完全连接的层上使用dropout，并在卷积之间实现批量标准化。<br>如果您想了解有关批量标准化的更多信息，请阅读：<br><a href="https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b" target="_blank" rel="noopener">https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/不要在卷积网络中使用Dropout/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/理解二进制交叉熵、对数损失函数:一种可视化解释" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/">理解二进制交叉熵、对数损失函数:一种可视化解释</a>
    </h1>
  

        
        <a href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/" class="archive-article-date">
  	<time datetime="2018-12-19T08:27:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-12-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a" target="_blank" rel="noopener">链接</a></p>
<p><a name="61a3ec66"></a></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><a href="#ba72yr"></a>介绍</h2><p>如果您正在训练二进制分类器，则可能使用二进制交叉熵/对数损失作为损失函数。<br>你有没有想过使用这种损失函数究竟是什么意思？ 问题是，考虑到今天的库和框架的易用性，很容易忽略所使用的损失函数的真正含义。<br>动机<br>我正在寻找一篇博文，以一种视觉上清晰简洁的方式解释二进制交叉熵/对数损失背后的概念，所以我可以在Data Science Retreat向我的学生展示它。 由于我找不到任何符合我目的的东西，我自己负责编写任务:-)。<br>一个简单的分类问题<br>让我们从10个随机点开始：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = [-2.2, -1.4, -0.8, 0.2, 0.4, 0.8, 1.2, 2.2, 2.9, 4.6]</span><br></pre></td></tr></table></figure></p>
<p>这是我们唯一的特征：x。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208575711-9a5c4e19-f272-468f-b36e-0d7074d62586.png#align=left&amp;display=inline&amp;height=111&amp;originHeight=111&amp;originWidth=625&amp;status=done&amp;width=625" alt><br>现在，让我们为我们的点分配一些颜色：红色和绿色。 这些是我们的标签。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208606509-b2a7b1cd-b1cf-4ca4-baca-88196d101a0b.png#align=left&amp;display=inline&amp;height=110&amp;originHeight=110&amp;originWidth=643&amp;status=done&amp;width=643" alt><br>因此，我们的分类问题非常简单：鉴于我们的特征x，我们需要预测其标签：红色或绿色。</p>
<p>由于这是一个二元分类，我们也可以将这个问题描述为：“是点绿色”，或者更好的是，“点是绿色的概率是多少”？ 理想情况下，绿点的概率为1.0（绿色），而红点的概率为0.0（绿色）。</p>
<p>在此设置中，绿点属于正类（YES，它们是绿色），而红点属于负类（NO，它们不是绿色）。<br>如果我们拟合模型来执行此分类，它将预测每个点的绿色概率。 根据我们对点的颜色的了解，我们如何评估预测概率的优劣（或差）？ 这是损失功能的全部目的！ 它应该为错误预测返回高值，为良好预测返回低值。</p>
<p>对于像我们的例子那样的二进制分类，典型的损失函数是二进制交叉熵/对数损失函数。<br><a name="6dab43bd"></a></p>
<h2 id="损失函数：二进制交叉熵-对数损失函数"><a href="#损失函数：二进制交叉熵-对数损失函数" class="headerlink" title="损失函数：二进制交叉熵/对数损失函数"></a><a href="#gh52id"></a>损失函数：二进制交叉熵/对数损失函数</h2><p>如果你观察这个损失函数，这就是你会发现的：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545208847996-2aba3677-2186-4f8c-bdab-ae8590ad7c6b.png#align=left&amp;display=inline&amp;height=79&amp;originHeight=79&amp;originWidth=548&amp;status=done&amp;width=548" alt><br>Binary Cross-Entropy / Log Loss<br>其中y是标签（绿点为1，红点为0），p(y)是所有N点的点为绿色的预测概率。</p>
<p>阅读这个公式，它告诉你，对于每个绿点（y = 1），它将log（p（y））添加到损失中，即它是绿色的对数概率。 相反，它为每个红点（y = 0）添加log（1-p（y）），即，它为红色的对数概率。 不一定很难，当然也不是那么直观……</p>
<p>此外，熵与这一切有什么关系？ 为什么我们首先记录概率？ 这些是有效的问题，我希望在下面的“给我看数学”部分回答它们。</p>
<p><a name="9acf4584"></a></p>
<h3 id="计算损失-可视化方法"><a href="#计算损失-可视化方法" class="headerlink" title="计算损失-可视化方法"></a><a href="#sbsnmi"></a>计算损失-可视化方法</h3><p>首先，让我们根据他们的类别（正面或负面）分割点数，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214792607-9e822a37-5f9e-46cb-bc0b-0a68f744faff.png#align=left&amp;display=inline&amp;height=224&amp;originHeight=224&amp;originWidth=620&amp;status=done&amp;width=620" alt><br>现在，让我们训练一个Logistic回归来对我们的点进行分类。 拟合回归是一个S形曲线，表示任何给定x点的绿色概率。 它看起来像这样：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214823897-b1ef51c7-4c5f-4ca4-8543-81231a9f1918.png#align=left&amp;display=inline&amp;height=215&amp;originHeight=215&amp;originWidth=686&amp;status=done&amp;width=686" alt><br>那么，对于属于正类（绿色）的所有点，我们的分类器给出的预测概率是多少？ 这些是S形曲线下的绿色条形，在与这些点对应的x坐标处。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214857312-a0a2e0e3-5317-4fe4-b9a8-64d6f07dbdf1.png#align=left&amp;display=inline&amp;height=209&amp;originHeight=209&amp;originWidth=683&amp;status=done&amp;width=683" alt><br>好的，到目前为止，真好！ 负面阶级的观点怎么样？ 请记住，S形曲线下的绿色条表示给定点为绿色的概率。 那么，给定点是红色的概率是多少？ 红色条在S形曲线上方，当然:-)<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214885683-601d1b29-50b1-4f89-98d8-242b19e28808.png#align=left&amp;display=inline&amp;height=209&amp;originHeight=209&amp;originWidth=678&amp;status=done&amp;width=678" alt><br>总而言之，我们最终会得到这样的结论：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214919348-98029aeb-bbdd-4969-b2bd-c5d5a5b9b83d.png#align=left&amp;display=inline&amp;height=210&amp;originHeight=210&amp;originWidth=683&amp;status=done&amp;width=683" alt><br>条形表示与每个点的相应真实类别相关联的预测概率！</p>
<p>好的，我们有预测的概率……通过计算二进制交叉熵/对数损失来评估它们的时间！</p>
<p>这些概率就是我们所需要的，所以，让我们摆脱x轴并将条带彼此相邻：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545214956710-95a7d392-f358-48ef-bf1e-6fc94c658e98.png#align=left&amp;display=inline&amp;height=262&amp;originHeight=262&amp;originWidth=425&amp;status=done&amp;width=425" alt><br>好吧，吊杆不再有意义了，所以让我们重新定位它们：</p>
<p><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215026705-0bd2aed9-8956-416f-9449-899f50e0ef36.png#align=left&amp;display=inline&amp;height=254&amp;originHeight=254&amp;originWidth=434&amp;status=done&amp;width=434" alt><br>既然我们正试图计算损失，我们需要惩罚不好的预测，对吧？ 如果与真实类相关的概率为1.0，我们需要将其损失为零。 相反，如果这个概率很低，比如0.01，我们需要它的损失是巨大的！<br>事实证明，对于这个目的，取概率的（负）对数就足够了（因为0.0和1.0之间的值的对数是负的，我们采用负对数来获得损失的正值）。<br>实际上，我们使用日志的原因来自交叉熵的定义，请查看下面的“给我看数学”部分了解更多详情。<br>下图给出了一个清晰的图片 - 如果真实类的预测概率接近零，则损失呈指数增长：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215109720-0cebdd78-1004-4e66-8dba-ed416c518790.png#align=left&amp;display=inline&amp;height=307&amp;originHeight=307&amp;originWidth=418&amp;status=done&amp;width=418" alt><br>很公平！ 让我们采用概率的（负）对数 - 这些是每个点的相应损失。<br>最后，我们计算所有这些损失的平均值。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215139483-4a54d212-a279-400b-afe6-df918499a792.png#align=left&amp;display=inline&amp;height=257&amp;originHeight=257&amp;originWidth=441&amp;status=done&amp;width=441" alt><br>瞧！ 我们已经成功计算了这个玩具示例的二进制交叉熵/对数损失。 它是0.3329！<br>告诉我代码<br>如果你想仔细检查我们找到的值，只需运行下面的代码并亲自看看:-)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import log_loss</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.array([-2.2, -1.4, -.8, .2, .4, .8, 1.2, 2.2, 2.9, 4.6])</span><br><span class="line">y = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])</span><br><span class="line"></span><br><span class="line">logr = LogisticRegression(solver=&apos;lbfgs&apos;)</span><br><span class="line">logr.fit(x.reshape(-1, 1), y)</span><br><span class="line"></span><br><span class="line">y_pred = logr.predict_proba(x.reshape(-1, 1))[:, 1].ravel()</span><br><span class="line">loss = log_loss(y, y_pred)</span><br><span class="line"></span><br><span class="line">print(&apos;x = &#123;&#125;&apos;.format(x))</span><br><span class="line">print(&apos;y = &#123;&#125;&apos;.format(y))</span><br><span class="line">print(&apos;p(y) = &#123;&#125;&apos;.format(np.round(y_pred, 2)))</span><br><span class="line">print(&apos;Log Loss / Cross Entropy = &#123;:.4f&#125;&apos;.format(loss))</span><br></pre></td></tr></table></figure></p>
<p>告诉我数学（真的吗？！）<br>除了笑话之外，这篇文章并不打算在数学上倾向于……但是对于你们这些人，我的读者，想要了解熵的作用，所有这些中的对数，我们在这里:-)<br>如果你想深入了解信息理论，包括所有这些概念 - 熵，交叉熵等等 - 检查Chris Olah的帖子，它非常详细！<br><a name="b2c9e438"></a></p>
<h4 id="分布"><a href="#分布" class="headerlink" title="分布"></a><a href="#gs7ekn"></a>分布</h4><p>让我们从分配点开始吧。 由于y表示我们的点的类（我们有3个红点和7个绿点），这就是它的分布，我们称之为q（y），如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215306977-97044aee-62cc-46c7-b7b2-cc4e60a53c39.png#align=left&amp;display=inline&amp;height=284&amp;originHeight=284&amp;originWidth=432&amp;status=done&amp;width=432" alt></p>
<p>熵<br>熵是与给定分布q（y）相关的不确定性的度量。<br>如果我们所有的积分都是绿色怎么办 那个分布的不确定性是什么？ ZERO，对吗？ 毕竟，对于一个点的颜色毫无疑问：它总是绿色的！ 所以，熵是零！<br>另一方面，如果我们确切地知道一半的点是绿色而另一半点是红色的呢？ 那是最糟糕的情况，对吗？ 猜测点的颜色绝对没有优势：它完全是随机的！ 对于这种情况，熵由下面的公式给出（我们有两个类别（颜色） - 红色或绿色 - 因此，2）：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215372228-11ebb814-6d1e-4797-b42e-94b77db29f6d.png#align=left&amp;display=inline&amp;height=43&amp;originHeight=43&amp;originWidth=166&amp;status=done&amp;width=166" alt><br>对于中间的其他情况，我们可以使用下面的公式计算分布的熵，如q（y），其中C是类的数量：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215399649-c50c5363-f426-4527-bf68-134aee0b35a4.png#align=left&amp;display=inline&amp;height=80&amp;originHeight=80&amp;originWidth=306&amp;status=done&amp;width=306" alt><br>因此，如果我们知道随机变量的真实分布，我们就可以计算其熵。 但是，如果是这样的话，为什么首先要费心去训练分类器呢？ 毕竟，我们知道真正的分布……<br>但是，如果我们不这样做呢？ 我们可以尝试用其他一些分布近似真实分布，比如p（y）吗？ 我们当然可以！:-)<br><a name="bf08985d"></a></p>
<h4 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a><a href="#ekaaou"></a>交叉熵</h4><p>让我们假设我们的观点遵循其他分布p（y）。 但我们知道它们实际上来自真实（未知）分布q（y），对吧？<br>如果我们像这样计算熵，我们实际上是在计算两个分布之间的交叉熵：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215448740-5ec55a28-5c13-46a0-b6d1-197063d62b05.png#align=left&amp;display=inline&amp;height=85&amp;originHeight=85&amp;originWidth=320&amp;status=done&amp;width=320" alt><br>如果我们奇迹般地将p（y）与q（y）完美匹配，则交叉熵和熵的计算值也将匹配。<br>由于这可能永远不会发生，因此交叉熵将具有比在真实分布上计算的熵更大的BIGGER值。<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215480123-9afd0d8f-9398-450a-b194-4ab6348a4685.png#align=left&amp;display=inline&amp;height=47&amp;originHeight=47&amp;originWidth=208&amp;status=done&amp;width=208" alt><br>事实证明，交叉熵和熵之间的这个区别有一个名字……<br><a name="bbec16ca"></a></p>
<h4 id="Kullback-Leibler发散"><a href="#Kullback-Leibler发散" class="headerlink" title="Kullback-Leibler发散"></a><a href="#fk7aht"></a>Kullback-Leibler发散</h4><p>Kullback-Leibler Divergence，简称“KL Divergence”，衡量两种发行版之间的差异：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215542635-c4a2d275-64a9-45c9-b68e-3f99fce5fcf5.png#align=left&amp;display=inline&amp;height=89&amp;originHeight=89&amp;originWidth=619&amp;status=done&amp;width=619" alt><br>这意味着，p（y）越接近q（y），发散越低，因此交叉熵越低。<br>所以，我们需要找到一个好的p（y）来使用……但是，这是我们的分类器应该做的，不是吗？！ 确实如此！ 它寻找最好的p（y），这是最小化交叉熵的那个。<br><a name="7162a4e0"></a></p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><a href="#xokywp"></a>损失函数</h4><p>在训练期间，分类器使用其训练集中的N个点中的每一个来计算交叉熵损失，有效地拟合分布p（y）！ 由于每个点的概率是1 / N，因此交叉熵由下式给出：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215580283-c3d40241-87ec-4541-aaf9-971fc6cc90e7.png#align=left&amp;display=inline&amp;height=85&amp;originHeight=85&amp;originWidth=411&amp;status=done&amp;width=411" alt><br>还记得上面的图6到10吗？ 我们需要在与每个点的真实类相关联的概率之上计算交叉熵。 这意味着使用绿色条形作为正类（y = 1）中的点，使用红色条形作为负类中的点（y = 0），或者数学上说：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215611182-db1eab68-632e-45e8-ac03-396234f18194.png#align=left&amp;display=inline&amp;height=75&amp;originHeight=75&amp;originWidth=230&amp;status=done&amp;width=230" alt><br>最后一步是计算两个类中所有点的平均值，正面和负面：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215637206-7fda25fc-c763-46c0-9eca-6e4fe9cec776.png#align=left&amp;display=inline&amp;height=92&amp;originHeight=92&amp;originWidth=592&amp;status=done&amp;width=592" alt><br>最后，通过一些操作，我们可以采用相同的公式，从正面或负面的类中获取任何一点：<br><img src="https://cdn.nlark.com/yuque/0/2018/png/219582/1545215662641-4915d2cb-3c29-4fc8-a535-c0db8b055951.png#align=left&amp;display=inline&amp;height=79&amp;originHeight=79&amp;originWidth=548&amp;status=done&amp;width=548" alt><br>瞧！ 我们回到二进制交叉熵/日志丢失的原始公式:-)<br><a name="fef1217c"></a></p>
<h3 id="最后的想法"><a href="#最后的想法" class="headerlink" title="最后的想法"></a><a href="#3038bg"></a>最后的想法</h3><p>我真的希望这篇文章能够对一个经常被认为理所当然的概念，即二元交叉熵作为损失函数的概念有所启发。 此外，我也希望它能够向您展示机器学习和信息理论如何联系在一起。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/12/19/yuque/理解二进制交叉熵、对数损失函数:一种可视化解释/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/8/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/10/">Next &raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 Zhos
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>

        <!-- 不蒜子统计 -->
        <span id="busuanzi_container_site_pv">
                本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>
        <span class="post-meta-divider">|</span>
        <span id="busuanzi_container_site_uv" style="display:none">
                本站访客数<span id="busuanzi_value_site_uv"></span>人
        </span>
        <script async src="/busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</footer>

    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br>1、请确保node版本大于6.2<br>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br> npm i hexo-generator-json-content --save<br><br>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://www.zhos.me/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">很惭愧&lt;br&gt;&lt;br&gt;只做了一点微小的工作&lt;br&gt;谢谢大家</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>