<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href="http://zhos.me">
  <title>A+</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="研究性材料(算法)">
<meta property="og:type" content="website">
<meta property="og:title" content="A+">
<meta property="og:url" content="http://zhos.me/page/2/index.html">
<meta property="og:site_name" content="A+">
<meta property="og:description" content="研究性材料(算法)">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A+">
<meta name="twitter:description" content="研究性材料(算法)">
  
    <link rel="alternative" href="/atom.xml" title="A+" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>
</html>
<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Zhos</a></h1>
		</hgroup>
		
		<p class="header-subtitle">ai &amp; bigdata &amp; ml</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/187063598" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Zhos</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>ai &amp; bigdata &amp; ml<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/zhosteven" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/187063598" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:ujujzhao@gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 100%"><a href="/">主页</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-yuque/应用机器学习的 XGBoost 简介" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/应用机器学习的 XGBoost 简介/">应用机器学习的 XGBoost 简介</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/应用机器学习的 XGBoost 简介/" class="archive-article-date">
  	<time datetime="2019-04-26T03:17:39.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="应用机器学习的-XGBoost-简介"><a href="#应用机器学习的-XGBoost-简介" class="headerlink" title="应用机器学习的 XGBoost 简介"></a>应用机器学习的 XGBoost 简介</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/</a></p>
</blockquote>
<p>XGBoost 是一种算法，最近一直主导应用机器学习和 Kaggle 竞争结构化或表格数据。</p>
<p>XGBoost 是为速度和表现而设计的梯度提升决策树的实现。</p>
<p>在这篇文章中，您将发现 XGBoost 并轻松了解它的来源，来自何处以及如何了解更多信息。</p>
<p>阅读这篇文章后你会知道：</p>
<ul>
<li>XGBoost 是什么以及项目的目标。</li>
<li>为什么 XGBoost 必须与您的机器学习工具包分开。</li>
<li>在下一个机器学习项目中，您可以了解更多信息以开始使用 XGBoost。</li>
</ul>
<p>让我们开始吧。</p>
<p><img src="img/2bb9abbef6f07700041dc880c95acda8.jpg" alt="A Gentle Introduction to XGBoost for Applied Machine Learning"></p>
<p>应用机器学习的 XGBoost 的温和介绍<br><a href="https://www.flickr.com/photos/sigfridlundberg/14945045482/" target="_blank" rel="noopener">Sigfrid Lundberg</a> 的照片，保留一些权利。</p>
<h2 id="什么是-XGBoost？"><a href="#什么是-XGBoost？" class="headerlink" title="什么是 XGBoost？"></a>什么是 XGBoost？</h2><p>XGBoost 代表 e <strong>X</strong> treme <strong>G</strong> radient <strong>B</strong> oosting。</p>
<blockquote>
<p>但是，名称 xgboost 实际上指的是推动增强树算法的计算资源限制的工程目标。这就是为什么许多人使用 xgboost 的原因。</p>
</blockquote>
<ul>
<li>陈天琪回答问题“ <a href="https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting" target="_blank" rel="noopener">R gbm（梯度提升机）和 xgboost（极限梯度提升）有什么区别？</a> “在 Quora 上</li>
</ul>
<p>它是 <a href="http://homes.cs.washington.edu/~tqchen/" target="_blank" rel="noopener">Tianqi Chen</a> 创建的梯度提升机的实现，现在得到了许多开发人员的贡献。它属于分布式机器学习社区或 <a href="http://dmlc.ml/" target="_blank" rel="noopener">DMLC</a> 旗下的更广泛的工具集，他们也是流行的 <a href="https://github.com/dmlc/mxnet" target="_blank" rel="noopener">mxnet 深度学习库</a>的创建者。</p>
<p>Tianqi Chen 在后期<a href="http://homes.cs.washington.edu/~tqchen/2016/03/10/story-and-lessons-behind-the-evolution-of-xgboost.html" target="_blank" rel="noopener">故事和 XGBoost 演变背后的教训</a>中提供了关于 XGBoost 创作的简短而有趣的背景故事。</p>
<p>XGBoost 是一个软件库，您可以在您的机器上下载和安装，然后从各种界面进行访问。具体来说，XGBoost 支持以下主要接口：</p>
<ul>
<li>命令行界面（CLI）。</li>
<li>C ++（编写库的语言）。</li>
<li>Python 界面以及 scikit-learn 中的模型。</li>
<li>R 接口以及插入符号包中的模型。</li>
<li>朱莉娅。</li>
<li>像 Scala 这样的 Java 和 JVM 语言以及像 Hadoop 这样的平台。</li>
</ul>
<h2 id="XGBoost-功能"><a href="#XGBoost-功能" class="headerlink" title="XGBoost 功能"></a>XGBoost 功能</h2><p>该库激光专注于计算速度和模型表现，因此几乎没有多余的装饰。尽管如此，它确实提供了许多高级功能。</p>
<h3 id="型号特点"><a href="#型号特点" class="headerlink" title="型号特点"></a>型号特点</h3><p>该模型的实现支持 scikit-learn 和 R 实现的功能，以及正规化等新增功能。支持三种主要形式的梯度提升：</p>
<ul>
<li><strong>Gradient Boosting</strong> 算法也称为梯度提升机，包括学习率。</li>
<li><strong>随机梯度提升</strong>，每个分割级别在行，列和列处进行子采样。</li>
<li><strong>正则化梯度提升</strong>同时具有 L1 和 L2 正则化。</li>
</ul>
<h3 id="系统功能"><a href="#系统功能" class="headerlink" title="系统功能"></a>系统功能</h3><p>该库提供了一个在各种计算环境中使用的系统，尤其是：</p>
<ul>
<li><strong>在训练期间使用所有 CPU 内核构建树的并行化</strong>。</li>
<li><strong>分布式计算</strong>用于使用一组机器训练超大型模型。</li>
<li><strong>非核心计算</strong>适用于不适合内存的超大型数据集。</li>
<li><strong>缓存优化</strong>的数据结构和算法，以充分利用硬件。</li>
</ul>
<h3 id="算法特征"><a href="#算法特征" class="headerlink" title="算法特征"></a>算法特征</h3><p>该算法的实现是为了提高计算时间和内存资源的效率而设计的。设计目标是充分利用可用资源来训练模型。一些关键的算法实现功能包括：</p>
<ul>
<li><strong>稀疏感知</strong>实现，自动处理缺失的数据值。</li>
<li><strong>块结构</strong>支持树形结构的并行化。</li>
<li><strong>继续训练</strong>，以便您可以进一步提升已安装的新数据模型。</li>
</ul>
<p>XGBoost 是免费的开源软件，可在许可的 Apache-2 许可下使用。</p>
<h2 id="为什么要使用-XGBoost？"><a href="#为什么要使用-XGBoost？" class="headerlink" title="为什么要使用 XGBoost？"></a>为什么要使用 XGBoost？</h2><p>使用 XGBoost 的两个原因也是该项目的两个目标：</p>
<ol>
<li>执行速度。</li>
<li>模特表演。</li>
</ol>
<h3 id="1-XGBoost-执行速度"><a href="#1-XGBoost-执行速度" class="headerlink" title="1. XGBoost 执行速度"></a>1. XGBoost 执行速度</h3><p>通常，XGBoost 很快。与梯度提升的其他实现相比，真的很快。</p>
<p><a href="https://www.linkedin.com/in/szilard" target="_blank" rel="noopener">Szilard Pafka</a> 进行了一些客观的基准测试，比较了 XGBoost 与梯度提升和袋装决策树的其他实现的表现。他在 2015 年 5 月的博客文章“<a href="http://datascience.la/benchmarking-random-forest-implementations/" target="_blank" rel="noopener">基准随机森林实施基准</a>”中写下了他的结果。</p>
<p>他还提供了 <a href="https://github.com/szilard/benchm-ml" target="_blank" rel="noopener">GitHub</a> 上的所有代码以及更为广泛的硬数字结果报告。</p>
<p><img src="img/6198624aaad562ea913e9dd529a072e5.jpg" alt="Benchmark Performance of XGBoost"></p>
<p>XGBoost 的基准表现，取自<a href="http://datascience.la/benchmarking-random-forest-implementations/" target="_blank" rel="noopener">基准随机森林实施</a>。</p>
<p>他的结果显示 XGBoost 几乎总是比 R，Python Spark 和 H2O 的其他基准测试实现更快。</p>
<p>从他的实验中，他评论说：</p>
<blockquote>
<p>我也尝试过 xgboost，一个流行的增强库，它也可以构建随机森林。它速度快，内存效率高，精度高</p>
</blockquote>
<ul>
<li>Szilard Pafka，<a href="http://datascience.la/benchmarking-random-forest-implementations/" target="_blank" rel="noopener">基准随机森林实施基准</a>。</li>
</ul>
<h3 id="2-XGBoost-模型表现"><a href="#2-XGBoost-模型表现" class="headerlink" title="2. XGBoost 模型表现"></a>2. XGBoost 模型表现</h3><p>XGBoost 在分类和回归预测建模问题上支配结构化或表格数据集。</p>
<p>有证据表明，它是 Kaggle 竞争数据科学平台竞赛获胜者的首选算法。</p>
<p>例如，有一个不完整的第一，第二和第三名比赛获胜者名单，标题为： <a href="https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions" target="_blank" rel="noopener">XGBoost：机器学习挑战获胜解决方案</a>。</p>
<p>为了使这一点更加切实，下面是来自 Kaggle 比赛获胜者的一些有见地的引用：</p>
<blockquote>
<p>作为越来越多的 Kaggle 比赛的赢家，XGBoost 再次向我们展示了一个值得在您的工具箱中使用的全面算法。</p>
</blockquote>
<ul>
<li><a href="http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/" target="_blank" rel="noopener">拿督获奖者专访：第一名，疯狂教授</a></li>
</ul>
<blockquote>
<p>如有疑问，请使用 xgboost。</p>
</blockquote>
<ul>
<li><a href="http://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/" target="_blank" rel="noopener">Avito Winner 的访谈：第一名，Owen Zhang</a></li>
</ul>
<blockquote>
<p>我喜欢单人模特做得很好，我最好的单人模特是 XGBoost，可以自己获得第 10 名。</p>
</blockquote>
<ul>
<li><a href="http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/" target="_blank" rel="noopener">卡特彼勒获奖者专访：第一名</a></li>
</ul>
<blockquote>
<p>我只用过 XGBoost。</p>
</blockquote>
<ul>
<li><a href="http://blog.kaggle.com/2015/09/28/liberty-mutual-property-inspection-winners-interview-qingchen-wang/" target="_blank" rel="noopener">Liberty Mutual Property Inspection，获奖者专访：第一名，王清晨</a></li>
</ul>
<blockquote>
<p>我使用的唯一监督学习方法是梯度提升，在优秀的 xgboost 包中实现。</p>
</blockquote>
<ul>
<li><a href="http://blog.kaggle.com/2015/10/21/recruit-coupon-purchase-winners-interview-2nd-place-halla-yang/" target="_blank" rel="noopener">招募优惠券购买获奖者专访：第二名，Halla Yang</a></li>
</ul>
<h2 id="XGBoost-使用什么算法？"><a href="#XGBoost-使用什么算法？" class="headerlink" title="XGBoost 使用什么算法？"></a>XGBoost 使用什么算法？</h2><p>XGBoost 库实现<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="noopener">梯度提升决策树算法</a>。</p>
<p>该算法有许多不同的名称，例如梯度提升，多重加性回归树，随机梯度提升或梯度提升机器。</p>
<p>Boosting 是一种集合技术，其中添加了新模型以纠正现有模型所产生的错误。依次添加模型，直到不能进一步改进。一个流行的例子是 <a href="http://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/" target="_blank" rel="noopener">AdaBoost 算法</a>，它对很难预测的数据点进行加权。</p>
<p>梯度提升是一种方法，其中创建新模型以预测先前模型的残差或误差，然后将其加在一起以进行最终预测。它被称为梯度提升，因为它使用梯度下降算法来最小化添加新模型时的损失。</p>
<p>该方法支持回归和分类预测建模问题。</p>
<p>有关增强和梯度提升的更多信息，请参阅 Trevor Hastie 关于<a href="https://www.youtube.com/watch?v=wPqtzj5VZus" target="_blank" rel="noopener">梯度提升机器学习</a>的演讲。</p>
<iframe allowfullscreen frameborder="0" height="281" src="https://www.youtube.com/embed/wPqtzj5VZus?feature=oembed" width="500"></iframe>

<h2 id="官方-XGBoost-资源"><a href="#官方-XGBoost-资源" class="headerlink" title="官方 XGBoost 资源"></a>官方 XGBoost 资源</h2><p>关于 XGBoost 的最佳信息来源是项目的<a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">官方 GitHub 存储库。</a></p>
<p>从那里，您可以访问<a href="https://github.com/dmlc/xgboost/issues" target="_blank" rel="noopener">问题跟踪器</a>和<a href="https://groups.google.com/forum/#!forum/xgboost-user/" target="_blank" rel="noopener">用户组</a>，可用于提问和报告错误。</p>
<p><a href="https://github.com/dmlc/xgboost/tree/master/demo" target="_blank" rel="noopener">Awesome XGBoost 页面</a>是一个很好的链接，带有示例代码和帮助。</p>
<p>还有一个<a href="https://xgboost.readthedocs.io/en/latest/" target="_blank" rel="noopener">官方文档页面</a>，其中包含一系列不同语言的入门指南，教程，操作指南等。</p>
<p>关于 XGBoost 的一些更正式的论文值得阅读，以获得更多关于图书馆的背景知识：</p>
<ul>
<li><a href="http://jmlr.org/proceedings/papers/v42/chen14.pdf" target="_blank" rel="noopener">Higgs Boson Discovery with Boosted Trees</a> ，2014。</li>
<li><a href="http://arxiv.org/abs/1603.02754" target="_blank" rel="noopener">XGBoost：可扩展的树木升压系统</a>，2016。</li>
</ul>
<h2 id="谈谈-XGBoost"><a href="#谈谈-XGBoost" class="headerlink" title="谈谈 XGBoost"></a>谈谈 XGBoost</h2><p>当开始使用像 XGBoost 这样的新工具时，在深入研究代码之前，先回顾一下有关该主题的一些讨论会很有帮助。</p>
<h3 id="XGBoost：可扩展的树提升系统"><a href="#XGBoost：可扩展的树提升系统" class="headerlink" title="XGBoost：可扩展的树提升系统"></a>XGBoost：可扩展的树提升系统</h3><p>图书馆的创建者田天琪于 2016 年 6 月与洛杉矶数据科学小组进行了一次题为“ <a href="https://www.youtube.com/watch?v=Vly8xGnNiWs" target="_blank" rel="noopener">XGBoost：可扩展的树木增强系统</a>”的讨论。</p>
<iframe allowfullscreen frameborder="0" height="281" src="https://www.youtube.com/embed/Vly8xGnNiWs?feature=oembed" width="500"></iframe>

<p>您可以在此处查看他演讲中的幻灯片：</p>
<iframe allowfullscreen="true" allowtransparency="true" frameborder="0" height="345" id="talk_frame_345261" mozallowfullscreen="true" src="//speakerdeck.com/player/5c6dab45648344208185d2b1ab4fdc95" style="border:0; padding:0; margin:0; background:transparent;" webkitallowfullscreen="true" width="500"></iframe>

<p>有关 <a href="http://datascience.la/xgboost-workshop-and-meetup-talk-with-tianqi-chen/" target="_blank" rel="noopener">DataScience LA 博客</a>的更多信息。</p>
<h3 id="XGBoost：eXtreme-Gradient-Boosting"><a href="#XGBoost：eXtreme-Gradient-Boosting" class="headerlink" title="XGBoost：eXtreme Gradient Boosting"></a>XGBoost：eXtreme Gradient Boosting</h3><p>2015 年 12 月在纽约数据科学学院举办的题为“ <a href="https://www.youtube.com/watch?v=ufHo8vbk6g4" target="_blank" rel="noopener">XGBoost：极限梯度提升</a>”的纽约数据科学学院发表演讲。</p>
<iframe allowfullscreen frameborder="0" height="281" src="https://www.youtube.com/embed/ufHo8vbk6g4?feature=oembed" width="500"></iframe>

<p>You can review the slides from his talk here:</p>
<iframe allowfullscreen frameborder="0" height="356" marginheight="0" marginwidth="0" scrolling="no" src="https://www.slideshare.net/slideshow/embed_code/key/lhcV8LfZ8RfrG" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" width="427"></iframe>

<p><strong><a href="https://www.slideshare.net/ShangxuanZhang/xgboost-55872323" title="Xgboost" target="_blank" rel="noopener">Xgboost</a></strong> from <strong><a href="http://www.slideshare.net/ShangxuanZhang" target="_blank" rel="noopener">Vivian Shangxuan Zhang</a></strong></p>
<p>有关此演讲的更多信息，请访问<a href="http://blog.nycdatascience.com/faculty/kaggle-winning-solution-xgboost-algorithm-let-us-learn-from-its-author-3/" target="_blank" rel="noopener">纽约数据科学学院博客</a>。</p>
<h2 id="安装-XGBoost"><a href="#安装-XGBoost" class="headerlink" title="安装 XGBoost"></a>安装 XGBoost</h2><p><a href="http://xgboost.readthedocs.io/en/latest/build.html" target="_blank" rel="noopener">XGBoost 文档网站</a>上有一个全面的安装指南。</p>
<p>它涵盖了 Linux，Mac OS X 和 Windows 的安装。</p>
<p>它还包括在 R 和 Python 等平台上的安装。</p>
<h3 id="R-中的-XGBoost"><a href="#R-中的-XGBoost" class="headerlink" title="R 中的 XGBoost"></a>R 中的 XGBoost</h3><p>如果您是 R 用户，最好的入门地点是 xgboost 包的 <a href="https://cran.r-project.org/web/packages/xgboost/index.html" target="_blank" rel="noopener">CRAN 页面。</a></p>
<p>在此页面中，您可以访问 <a href="https://cran.r-project.org/web/packages/xgboost/xgboost.pdf" target="_blank" rel="noopener">R vignette Package’xgboost’</a> [pdf]。</p>
<p>此页面还链接了一些优秀的 R 教程，以帮助您入门：</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/xgboost/vignettes/discoverYourData.html" target="_blank" rel="noopener">发现您的数据</a></li>
<li><a href="https://cran.r-project.org/web/packages/xgboost/vignettes/xgboostPresentation.html" target="_blank" rel="noopener">XGBoost 演示文稿</a></li>
<li><a href="https://cran.r-project.org/web/packages/xgboost/vignettes/xgboost.pdf" target="_blank" rel="noopener">xgboost：eXtreme Gradient Boosting</a> [pdf]</li>
</ul>
<p>还有官方的 <a href="http://xgboost.readthedocs.io/en/latest/R-package/xgboostPresentation.html" target="_blank" rel="noopener">XGBoost R 教程</a>和<a href="http://xgboost.readthedocs.io/en/latest/R-package/discoverYourData.html" target="_blank" rel="noopener">用 XGBoost</a> 教程了解你的数据集。</p>
<h3 id="Python-中的-XGBoost"><a href="#Python-中的-XGBoost" class="headerlink" title="Python 中的 XGBoost"></a>Python 中的 XGBoost</h3><p>安装说明可在 XGBoost 安装指南的 <a href="https://github.com/dmlc/xgboost/blob/master/doc/build.md#python-package-installation" target="_blank" rel="noopener">Python 部分找到。</a></p>
<p>官方 <a href="http://xgboost.readthedocs.io/en/latest/python/python_intro.html" target="_blank" rel="noopener">Python 包简介</a>是在 Python 中使用 XGBoost 时最好的起点。</p>
<p>要快速入门，您可以输入：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install xgboost</span><br></pre></td></tr></table></figure>
<p>在 <a href="https://github.com/tqchen/xgboost/tree/master/demo/guide-python" target="_blank" rel="noopener">XGBoost Python 功能演练</a>中，Python 中还有一个很好的示例源代码列表。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了应用机器学习的 XGBoost 算法。</p>
<p>你了解到：</p>
<ul>
<li>XGBoost 是一个用于开发快速和高表现梯度提升树模型的库。</li>
<li>XGBoost 在一系列困难的机器学习任务中实现了最佳表现。</li>
<li>您可以从命令行，Python 和 R 使用此库以及如何开始使用。</li>
</ul>
<p>你用过 XGBoost 吗？在下面的评论中分享您的经验。</p>
<p>您对 XGBoost 或该帖子有任何疑问吗？在下面的评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/应用机器学习的 XGBoost 简介/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/浅谈机器学习的梯度提升算法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/浅谈机器学习的梯度提升算法/">浅谈机器学习的梯度提升算法</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/浅谈机器学习的梯度提升算法/" class="archive-article-date">
  	<time datetime="2019-04-26T03:17:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="浅谈机器学习的梯度提升算法"><a href="#浅谈机器学习的梯度提升算法" class="headerlink" title="浅谈机器学习的梯度提升算法"></a>浅谈机器学习的梯度提升算法</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/</a></p>
</blockquote>
<p>梯度提升是构建预测模型的最强大技术之一。</p>
<p>在这篇文章中，您将发现梯度提升机器学习算法，并轻松介绍它的来源和工作原理。</p>
<p>阅读这篇文章后，你会知道：</p>
<ul>
<li>从学习理论和 AdaBoost 推动的起源。</li>
<li>梯度提升的工作原理包括损失函数，弱学习器和加法模型。</li>
<li>如何通过各种正则化方案提高基本算法的表现</li>
</ul>
<p>让我们开始吧。</p>
<p><img src="img/3dde9db909245469cc477e5f07363bbe.jpg" alt="A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning"></p>
<p>机器学习梯度提升算法的温和介绍<br><a href="https://www.flickr.com/photos/bpprice/12298787813/" target="_blank" rel="noopener">brando.n</a> 的照片，保留一些权利。</p>
<h2 id="提升的起源"><a href="#提升的起源" class="headerlink" title="提升的起源"></a>提升的起源</h2><p>提升的想法来自于弱学习器是否可以被修改为变得更好的想法。</p>
<p>Michael Kearns 将目标阐述为“_ 假设推进问题 _”从实际角度阐述了目标：</p>
<blockquote>
<p>…一种将相对较差的假设转换为非常好的假设的有效算法</p>
</blockquote>
<ul>
<li><a href="https://www.cis.upenn.edu/~mkearns/papers/boostnote.pdf" target="_blank" rel="noopener">关于假设提升的思考</a> [PDF]，1988</li>
</ul>
<p>弱假设或弱学习器被定义为其表现至少略好于随机机会的假设。</p>
<p>这些想法建立在 Leslie Valiant 关于免费分发或<a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning" target="_blank" rel="noopener">概率近似正确</a>（PAC）学习的工作之上，这是一个研究机器学习问题复杂性的框架。</p>
<p>假设提升是过滤观察的想法，留下弱学习器可以处理的观察，并专注于开发新的弱学习以处理剩余的困难观察。</p>
<blockquote>
<p>我们的想法是多次使用弱学习方法来得到一系列假设，每一个假设都重新聚焦于前面发现的困难和错误分类的例子。 …但是，请注意，如何做到这一点并不明显</p>
</blockquote>
<ul>
<li><a href="http://www.amazon.com/dp/0465060722?tag=inspiredalgor-20" target="_blank" rel="noopener">大概正确：大自然在复杂世界中学习和繁荣的算法</a>，第 152 页，2013</li>
</ul>
<h3 id="AdaBoost-第一个提升算法"><a href="#AdaBoost-第一个提升算法" class="headerlink" title="AdaBoost 第一个提升算法"></a>AdaBoost 第一个提升算法</h3><p>在应用中取得巨大成功的第一个实现提升的是 <a href="http://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/" target="_blank" rel="noopener">Adaptive Boosting 或 AdaBoost</a> 。</p>
<blockquote>
<p>提升是指通过组合粗略和中度不准确的经验法则来产生非常准确的预测规则的一般问题。</p>
</blockquote>
<ul>
<li><a href="http://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf" target="_blank" rel="noopener">在线学习的决策理论推广及其应用</a> [PDF]，1995</li>
</ul>
<p>AdaBoost 中的弱学习器是决策树，只有一个分裂，称为决策树桩的短缺。</p>
<p>AdaBoost 通过对观察结果进行加权，更加重视难以分类的实例，而不是那些已经处理好的实例。新的弱学习器按顺序添加，将他们的训练集中在更难的模式上。</p>
<blockquote>
<p>这意味着难以分类的样本会获得越来越大的权重，直到算法识别出正确分类这些样本的模型</p>
</blockquote>
<ul>
<li><a href="http://www.amazon.com/dp/1461468485?tag=inspiredalgor-20" target="_blank" rel="noopener">Applied Predictive Modeling</a> ，2013</li>
</ul>
<p>通过对弱学习器预测的多数投票进行预测，并根据他们的个人准确性进行加权。 AdaBoost 算法最成功的形式是二进制分类问题，称为 AdaBoost.M1。</p>
<p>您可以在帖子中了解有关 AdaBoost 算法的更多信息：</p>
<ul>
<li><a href="http://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/" target="_blank" rel="noopener">Boosting 和 AdaBoost 机器学习</a>。</li>
</ul>
<h3 id="AdaBoost-作为梯度提升的推广"><a href="#AdaBoost-作为梯度提升的推广" class="headerlink" title="AdaBoost 作为梯度提升的推广"></a>AdaBoost 作为梯度提升的推广</h3><p>AdaBoost 和相关算法首先由 Breiman 称之为 ARCing 算法的统计框架重铸。</p>
<blockquote>
<p>Arcing 是 Adaptive Reweighting and Combining 的首字母缩写。电弧放电算法中的每个步骤都包括加权最小化，然后重新计算[分类器]和[加权输入]。</p>
</blockquote>
<ul>
<li><a href="https://www.stat.berkeley.edu/~breiman/games.pdf" target="_blank" rel="noopener">预测游戏和拱形算法</a> [PDF]，1997</li>
</ul>
<p>这个框架由 Friedman 进一步开发，称为 Gradient Boosting Machines。后来称为梯度提升或梯度树增强。</p>
<p>统计框架将推进作为一个数值优化问题，其目标是通过使用梯度下降类似过程添加弱学习器来最小化模型的损失。</p>
<p>这类算法被描述为阶段性加法模型。这是因为一次添加一个新的弱学习器，并且模型中现有的弱学习器被冻结并保持不变。</p>
<blockquote>
<p>请注意，此阶段策略与逐步方法不同，后者在添加新的时重新调整先前输入的术语。</p>
</blockquote>
<ul>
<li><a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">贪婪函数逼近：梯度增压机</a> [PDF]，1999</li>
</ul>
<p>泛化允许使用任意可微分损失函数，将技术扩展到二元分类问题之外，以支持回归，多类分类等。</p>
<h2 id="梯度提升的工作原理"><a href="#梯度提升的工作原理" class="headerlink" title="梯度提升的工作原理"></a>梯度提升的工作原理</h2><p>梯度提升涉及三个要素：</p>
<ol>
<li>要优化的损失函数。</li>
<li>做出预测的弱学习器。</li>
<li>添加模型，添加弱学习器以最小化损失函数。</li>
</ol>
<h3 id="1-损失功能"><a href="#1-损失功能" class="headerlink" title="1.损失功能"></a>1.损失功能</h3><p>使用的损失函数取决于要解决的问题类型。</p>
<p>它必须是可区分的，但支持许多标准丢失函数，您可以定义自己的函数。</p>
<p>例如，回归可能使用平方误差，分类可能使用对数损失。</p>
<p>梯度提升框架的一个好处是不必为可能想要使用的每个损失函数导出新的增强算法，相反，它是足够通用的框架，可以使用任何可微分损失函数。</p>
<h3 id="2-弱小的学习器"><a href="#2-弱小的学习器" class="headerlink" title="2.弱小的学习器"></a>2.弱小的学习器</h3><p>决策树被用作梯度提升中的弱学习器。</p>
<p>特别是使用回归树，其输出分裂的实际值并且其输出可以被加在一起，允许添加后续模型输出并“校正”预测中的残差。</p>
<p>树木以贪婪的方式构建，根据基尼等纯度分数选择最佳分割点，或尽量减少损失。</p>
<p>最初，例如在 AdaBoost 的情况下，使用非常短的决策树，其仅具有单个分割，称为决策残余。较大的树木通常可以使用 4 到 8 级。</p>
<p>通常以特定方式约束弱学习器，例如最大层数，节点，分裂或叶节点。</p>
<p>这是为了确保学习器保持弱势，但仍然可以贪婪地构建。</p>
<h3 id="3-添加剂模型"><a href="#3-添加剂模型" class="headerlink" title="3.添加剂模型"></a>3.添加剂模型</h3><p>树一次添加一个树，模型中的现有树不会更改。</p>
<p>梯度下降程序用于最小化添加树木时的损失。</p>
<p>传统上，梯度下降用于最小化一组参数，例如回归方程中的系数或神经网络中的权重。在计算错误或丢失之后，更新权重以最小化该错误。</p>
<p>我们有弱学习器子模型或更具体的决策树，而不是参数。在计算损失之后，为了执行梯度下降过程，我们必须向模型添加树以减少损失（即遵循梯度）。我们通过参数化树来完成此操作，然后修改树的参数并向右移动（减少剩余损失。</p>
<p>通常，这种方法称为功能梯度下降或具有功能的梯度下降。</p>
<blockquote>
<p>产生优化[成本]的分类器的加权组合的一种方法是通过函数空间中的梯度下降</p>
</blockquote>
<ul>
<li><a href="http://papers.nips.cc/paper/1766-boosting-algorithms-as-gradient-descent.pdf" target="_blank" rel="noopener">在函数空间中提升算法作为梯度下降</a> [PDF]，1999</li>
</ul>
<p>然后将新树的输出添加到现有树序列的输出中，以便纠正或改进模型的最终输出。</p>
<p>一旦损失达到可接受的水平或在外部验证数据集上不再改进，则添加固定数量的树或训练停止。</p>
<h2 id="基本梯度提升的改进"><a href="#基本梯度提升的改进" class="headerlink" title="基本梯度提升的改进"></a>基本梯度提升的改进</h2><p>梯度提升是一种贪婪算法，可以快速过度训练数据集。</p>
<p>它可以受益于惩罚算法的各个部分的正则化方法，并且通常通过减少过度拟合来改善算法的表现。</p>
<p>在本节中，我们将介绍基本梯度提升的 4 个增强功能：</p>
<ol>
<li>树约束</li>
<li>收缩</li>
<li>随机抽样</li>
<li>惩罚学习</li>
</ol>
<h3 id="1-树约束"><a href="#1-树约束" class="headerlink" title="1.树约束"></a>1.树约束</h3><p>重要的是弱势学习器有技巧但仍然很弱。</p>
<p>树可以通过多种方式进行约束。</p>
<p>一个好的通用启发式方法是，树的创建越多，模型中需要的树就越多，反之，在不受约束的单个树中，所需的树就越少。</p>
<p>以下是可以对决策树构造施加的一些约束：</p>
<ul>
<li><strong>树木数量</strong>，通常会为模型添加更多树木，过度拟合可能会非常缓慢。建议继续添加树木，直至观察不到进一步的改善。</li>
<li><strong>树深</strong>，更深的树木更复杂的树木和更短的树木是首选。通常，4-8 级可以看到更好的结果。</li>
<li><strong>节点数或叶数</strong>，如深度，这可以约束树的大小，但如果使用其他约束，则不限于对称结构。</li>
<li><strong>每次分割的观察次数</strong>对训练节点的训练数据量施加最小约束，然后才能考虑分割</li>
<li><strong>最小化损失</strong>是对添加到树中的任何拆分的改进的约束。</li>
</ul>
<h3 id="2-加权更新"><a href="#2-加权更新" class="headerlink" title="2.加权更新"></a>2.加权更新</h3><p>每棵树的预测按顺序加在一起。</p>
<p>可以对每个树对该总和的贡献进行加权以减慢算法的学习。这种加权称为收缩或学习率。</p>
<blockquote>
<p>每个更新只是通过“学习速率参数 v”的值进行缩放</p>
</blockquote>
<p>— <a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">Greedy Function Approximation: A Gradient Boosting Machine</a> [PDF], 1999</p>
<p>结果是学习速度变慢，反过来需要将更多树木添加到模型中，反过来需要更长的时间来训练，提供树木数量和学习率之间的配置权衡。</p>
<blockquote>
<p>减小 v [学习率]的值会增加 M [树的数量]的最佳值。</p>
</blockquote>
<p>— <a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">Greedy Function Approximation: A Gradient Boosting Machine</a> [PDF], 1999</p>
<p>通常具有 0.1 至 0.3 范围内的小值，以及小于 0.1 的值。</p>
<blockquote>
<p>与随机优化中的学习速率类似，收缩减少了每棵树的影响，并为将来的树木留出了空间来改进模型。</p>
</blockquote>
<ul>
<li><a href="https://statweb.stanford.edu/~jhf/ftp/stobst.pdf" target="_blank" rel="noopener">随机梯度提升</a> [PDF]，1999</li>
</ul>
<h3 id="3-随机梯度提升"><a href="#3-随机梯度提升" class="headerlink" title="3.随机梯度提升"></a>3.随机梯度提升</h3><p>对装袋合奏和随机森林的深入了解允许从训练数据集的子样本中贪婪地创建树。</p>
<p>可以使用相同的益处来减少梯度提升模型中序列中的树之间的相关性。</p>
<p>这种增强的变化称为随机梯度提升。</p>
<blockquote>
<p>在每次迭代中，从完整训练数据集中随机（无替换）绘制训练数据的子样本。然后使用随机选择的子样本而不是完整样本来适合基础学习器。</p>
</blockquote>
<p>— <a href="https://statweb.stanford.edu/~jhf/ftp/stobst.pdf" target="_blank" rel="noopener">Stochastic Gradient Boosting</a> [PDF], 1999</p>
<p>可以使用的一些随机增压变体：</p>
<ul>
<li>在创建每个树之前的子样本行。</li>
<li>创建每个树之前的子样本列</li>
<li>在考虑每个拆分之前的子采样列。</li>
</ul>
<p>通常，积极的子采样（例如仅选择 50％的数据）已被证明是有益的。</p>
<blockquote>
<p>根据用户反馈，使用列子采样可以比传统的行子采样更加防止过度拟合</p>
</blockquote>
<ul>
<li><a href="https://arxiv.org/abs/1603.02754" target="_blank" rel="noopener">XGBoost：可扩展的树升压系统</a>，2016</li>
</ul>
<h3 id="4-Penalized-Gradient-Boosting"><a href="#4-Penalized-Gradient-Boosting" class="headerlink" title="4. Penalized Gradient Boosting"></a>4. Penalized Gradient Boosting</h3><p>除了它们的结构之外，还可以对参数化树施加附加约束。</p>
<p>像 CART 这样的经典决策树不被用作弱学习器，而是使用称为回归树的修改形式，其在叶节点（也称为终端节点）中具有数值。在一些文献中，树叶中的值可以称为权重。</p>
<p>因此，可以使用流行的正则化函数来规范树的叶权值，例如：</p>
<ul>
<li>L1 权重的正则化。</li>
<li>权重的 L2 正则化。</li>
</ul>
<blockquote>
<p>额外的正则化项有助于平滑最终学习的权重以避免过度拟合。直观地，正则化目标将倾向于选择采用简单和预测函数的模型。</p>
</blockquote>
<p>— <a href="https://arxiv.org/abs/1603.02754" target="_blank" rel="noopener">XGBoost: A Scalable Tree Boosting System</a>, 2016</p>
<h2 id="梯度提升资源"><a href="#梯度提升资源" class="headerlink" title="梯度提升资源"></a>梯度提升资源</h2><p>梯度提升是一种迷人的算法，我相信你想要更深入。</p>
<p>本节列出了可用于了解梯度提升算法的更多信息。</p>
<h3 id="梯度提升视频"><a href="#梯度提升视频" class="headerlink" title="梯度提升视频"></a>梯度提升视频</h3><ul>
<li><a href="https://www.youtube.com/watch?v=wPqtzj5VZus" target="_blank" rel="noopener">Gradient Boosting Machine Learning</a> ，Trevor Hastie，2014</li>
<li><a href="https://www.youtube.com/watch?v=sRktKszFmSk" target="_blank" rel="noopener">Gradient Boosting</a> ，Alexander Ihler，2012</li>
<li><a href="https://www.youtube.com/watch?v=WZvPUGNJg18" target="_blank" rel="noopener">GBM</a> ，John Mount，2015 年</li>
<li><a href="https://www.youtube.com/watch?v=UHBmv7qCey4" target="_blank" rel="noopener">学习：提升</a>，麻省理工学院 6.034 人工智能，2010</li>
<li><a href="https://www.youtube.com/watch?v=0IhraqUVJ_E" target="_blank" rel="noopener">xgboost：用于快速准确梯度提升的 R 包</a>，2016</li>
<li><a href="https://www.youtube.com/watch?v=Vly8xGnNiWs" target="_blank" rel="noopener">XGBoost：可扩展的树木升压系统</a>，陈天琪，2016</li>
</ul>
<h3 id="教科书中的梯度提升"><a href="#教科书中的梯度提升" class="headerlink" title="教科书中的梯度提升"></a>教科书中的梯度提升</h3><ul>
<li>第 8.2.3 节 Boosting，第 321 页，<a href="http://www.amazon.com/dp/1461471370?tag=inspiredalgor-20" target="_blank" rel="noopener">统计学习简介：在 R</a> 中的应用。</li>
<li>第 8.6 节 Boosting，第 203 页，<a href="http://www.amazon.com/dp/1461468485?tag=inspiredalgor-20" target="_blank" rel="noopener">应用预测建模</a>。</li>
<li>第 14.5 节“随机梯度提升”，第 390 页，<a href="http://www.amazon.com/dp/1461468485?tag=inspiredalgor-20" target="_blank" rel="noopener">应用预测建模</a>。</li>
<li>第 16.4 节 Boosting，第 556 页，<a href="http://www.amazon.com/dp/0262018020?tag=inspiredalgor-20" target="_blank" rel="noopener">机器学习：概率视角</a></li>
<li>第 10 章 Boosting 和 Additive 树，第 337 页，<a href="http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20" target="_blank" rel="noopener">统计学习的要素：数据挖掘，推理和预测</a></li>
</ul>
<h3 id="Gradient-Boosting-Papers"><a href="#Gradient-Boosting-Papers" class="headerlink" title="Gradient Boosting Papers"></a>Gradient Boosting Papers</h3><ul>
<li><a href="http://www.cis.upenn.edu/~mkearns/papers/boostnote.pdf" target="_blank" rel="noopener">关于假设提升的思考</a> [PDF]，Michael Kearns，1988</li>
<li><a href="http://cns.bu.edu/~gsc/CN710/FreundSc95.pdf" target="_blank" rel="noopener">在线学习的决策理论推广及其应用</a> [PDF]，1995</li>
<li><a href="http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf" target="_blank" rel="noopener">弧形边缘</a> [PDF]，1998</li>
<li><a href="https://statweb.stanford.edu/~jhf/ftp/stobst.pdf" target="_blank" rel="noopener">随机梯度提升</a> [PDF]，1999</li>
<li><a href="http://maths.dur.ac.uk/~dma6kp/pdf/face_recognition/Boosting/Mason99AnyboostLong.pdf" target="_blank" rel="noopener">在函数空间中提升算法作为梯度下降</a> [PDF]，1999</li>
</ul>
<h3 id="梯度提升幻灯片"><a href="#梯度提升幻灯片" class="headerlink" title="梯度提升幻灯片"></a>梯度提升幻灯片</h3><ul>
<li><a href="http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf" target="_blank" rel="noopener">Boosted Trees 简介</a>，2014</li>
<li><a href="http://www.chengli.io/tutorials/gradient_boosting.pdf" target="_blank" rel="noopener">一个温和的梯度提升介绍</a>，程力</li>
</ul>
<h3 id="梯度提升网页"><a href="#梯度提升网页" class="headerlink" title="梯度提升网页"></a>梯度提升网页</h3><ul>
<li><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning" target="_blank" rel="noopener">提升（机器学习）</a>)</li>
<li><a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="noopener">梯度提升</a></li>
<li><a href="http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting" target="_blank" rel="noopener">在 scikit-learn</a> 中提升梯度树</li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了用于机器学习中预测建模的梯度提升算法。</p>
<p>具体来说，你学到了：</p>
<ul>
<li>提升学习理论和 AdaBoost 的历史。</li>
<li>梯度提升算法如何与损失函数，弱学习器和附加模型一起工作。</li>
<li>如何通过正则化提高梯度提升的表现。</li>
</ul>
<p>您对梯度提升算法或此帖有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/浅谈机器学习的梯度提升算法/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/在 Python 中使用 XGBoost 的特征重要性和特征选择" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/在 Python 中使用 XGBoost 的特征重要性和特征选择/">在 Python 中使用 XGBoost 的特征重要性和特征选择</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/在 Python 中使用 XGBoost 的特征重要性和特征选择/" class="archive-article-date">
  	<time datetime="2019-04-26T03:17:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="在-Python-中使用-XGBoost-的特征重要性和特征选择"><a href="#在-Python-中使用-XGBoost-的特征重要性和特征选择" class="headerlink" title="在 Python 中使用 XGBoost 的特征重要性和特征选择"></a>在 Python 中使用 XGBoost 的特征重要性和特征选择</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/</a></p>
</blockquote>
<p>使用诸如梯度提升之类的决策树方法的集合的好处是它们可以从训练的预测模型自动提供特征重要性的估计。</p>
<p>在本文中，您将了解如何使用 Python 中的 XGBoost 库来估计功能对预测建模问题的重要性。</p>
<p>阅读这篇文章后你会知道：</p>
<ul>
<li>如何使用梯度提升算法计算特征重要性。</li>
<li>如何在 XGBoost 模型计算的 Python 中绘制要素重要性。</li>
<li>如何使用 XGBoost 计算的要素重要性来执行要素选择。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
<li><strong>更新 March / 2018</strong> ：添加了备用链接以下载数据集，因为原始图像已被删除。</li>
</ul>
<p><img src="img/5a184d41ab4a4455f4f46aae43b17958.jpg" alt="Feature Importance and Feature Selection With XGBoost in Python"></p>
<p>功能重要性和功能选择使用 Python 中的 XGBoost<br>照片由 <a href="https://www.flickr.com/photos/keithroper/15476027141/" target="_blank" rel="noopener">Keith Roper</a> ，保留一些权利。</p>
<h2 id="梯度提升中的特征重要性"><a href="#梯度提升中的特征重要性" class="headerlink" title="梯度提升中的特征重要性"></a>梯度提升中的特征重要性</h2><p>使用梯度提升的好处是，在构建增强树之后，检索每个属性的重要性分数是相对简单的。</p>
<p>通常，重要性提供分数，该分数指示每个特征在模型内的增强决策树的构造中的有用性或有价值。使用决策树做出关键决策的属性越多，其相对重要性就越高。</p>
<p>对于数据集中的每个属性，明确计算此重要性，允许对属性进行排名并相互比较。</p>
<p>通过每个属性分割点改进表现度量的量来计算单个决策树的重要性，并由节点负责的观察数量加权。表现度量可以是用于选择分裂点的纯度（基尼指数）或另一个更具体的误差函数。</p>
<p>然后，在模型中的所有决策树中对要素重要性进行平均。</p>
<p>有关如何在提升的决策树中计算特征重要性的更多技术信息，请参阅本书<a href="http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20" target="_blank" rel="noopener">统计学习要素：数据挖掘，推理，第 10.53.1 节“_ 预测变量的相对重要性 _”。和预测</a>，第 367 页。</p>
<p>另外，请参阅 Matthew Drury 对 StackOverflow 问题的回答“ <a href="http://stats.stackexchange.com/questions/162162/relative-variable-importance-for-boosting" target="_blank" rel="noopener">Boosting</a> 的相对变量重要性”，他提供了非常详细和实用的答案。</p>
<h2 id="手动绘制功能重要性"><a href="#手动绘制功能重要性" class="headerlink" title="手动绘制功能重要性"></a>手动绘制功能重要性</h2><p>经过训练的 XGBoost 模型可自动计算预测建模问题的特征重要性。</p>
<p>这些重要性分数可在训练模型的 <strong>feature_importances_</strong> 成员变量中找到。例如，它们可以直接打印如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model.feature_importances_)</span><br></pre></td></tr></table></figure>
<p>我们可以直接在条形图上绘制这些分数，以直观地显示数据集中每个要素的相对重要性。例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot</span></span><br><span class="line">pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>我们可以通过在 <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank" rel="noopener">Pima 印第安人糖尿病数据集</a>上训练 XGBoost 模型并根据计算的特征重要性创建条形图来证明这一点（更新：<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv" target="_blank" rel="noopener">从这里下载</a>）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot feature importance manually</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"><span class="comment"># feature importance</span></span><br><span class="line">print(model.feature_importances_)</span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>运行此示例首先输出重要性分数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">0.089701</span>    <span class="number">0.17109634</span>  <span class="number">0.08139535</span>  <span class="number">0.04651163</span>  <span class="number">0.10465116</span>  <span class="number">0.2026578</span> <span class="number">0.1627907</span>   <span class="number">0.14119601</span>]</span><br></pre></td></tr></table></figure>
<p>我们还得到了相对重要性的条形图。</p>
<p><img src="img/745045b3bf82c5128eae73f2ebbfe78e.jpg" alt="Manual Bar Chart of XGBoost Feature Importance"></p>
<p>XGBoost 功能重要性的手动条形图</p>
<p>这个图的缺点是功能按输入索引而不是它们的重要性排序。我们可以在绘图之前对功能进行排序。</p>
<p>值得庆幸的是，有一个内置的绘图功能来帮助我们。</p>
<h2 id="使用内置的-XGBoost-功能重要性图"><a href="#使用内置的-XGBoost-功能重要性图" class="headerlink" title="使用内置的 XGBoost 功能重要性图"></a>使用内置的 XGBoost 功能重要性图</h2><p>XGBoost 库提供了一个内置函数来绘制按其重要性排序的特征。</p>
<p>该函数称为 <strong>plot_importance（）</strong>，可以按如下方式使用：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot feature importance</span></span><br><span class="line">plot_importance(model)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>例如，下面是一个完整的代码清单，使用内置的 <strong>plot_importance（）</strong>函数绘制 Pima Indians 数据集的特征重要性。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot feature importance using built-in function</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"><span class="comment"># plot feature importance</span></span><br><span class="line">plot_importance(model)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>运行该示例为我们提供了更有用的条形图。</p>
<p><img src="img/5f9e25575188c1f1ca109d5a47b9bc13.jpg" alt="XGBoost Feature Importance Bar Chart"></p>
<p>XGBoost 功能重要性条形图</p>
<p>您可以看到功能是根据它们在 F0 到 F7 的输入数组（X）中的索引自动命名的。</p>
<p>在问题描述中手动将这些指数映射到<a href="https://github.com/jbrownlee/Datasets/blob/master/pima-indians-diabetes.names" target="_blank" rel="noopener">名称，我们可以看到该图显示 F5（体重指数）具有最高重要性，F3（皮肤折叠厚度）具有最低重要性。</a></p>
<h2 id="使用-XGBoost-功能重要性分数进行特征选择"><a href="#使用-XGBoost-功能重要性分数进行特征选择" class="headerlink" title="使用 XGBoost 功能重要性分数进行特征选择"></a>使用 XGBoost 功能重要性分数进行特征选择</h2><p>特征重要性分数可用于 scikit-learn 中的特征选择。</p>
<p>这是使用 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html" target="_blank" rel="noopener">SelectFromModel</a> 类完成的，该类采用模型并可以将数据集转换为具有所选特征的子集。</p>
<p>该课程可以采用预训练的模型，例如在整个训练数据集上训练的模型。然后，它可以使用阈值来决定选择哪些功能。当您在 <strong>SelectFromModel</strong> 实例上调用 <strong>transform（）</strong>方法以在训练数据集和测试数据集上始终选择相同的特征时，将使用此阈值。</p>
<p>在下面的示例中，我们首先分别训练并评估整个训练数据集和测试数据集上的 XGBoost 模型。</p>
<p>使用从训练数据集计算的要素重要性，然后我们将模型包装在 SelectFromModel 实例中。我们使用它来选择训练数据集上的特征，从所选特征子集训练模型，然后根据相同的特征选择方案评估测试集上的模型。</p>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select features using threshold</span></span><br><span class="line">selection = SelectFromModel(model, threshold=thresh, prefit=<span class="literal">True</span>)</span><br><span class="line">select_X_train = selection.transform(X_train)</span><br><span class="line"><span class="comment"># train model</span></span><br><span class="line">selection_model = XGBClassifier()</span><br><span class="line">selection_model.fit(select_X_train, y_train)</span><br><span class="line"><span class="comment"># eval model</span></span><br><span class="line">select_X_test = selection.transform(X_test)</span><br><span class="line">y_pred = selection_model.predict(select_X_test)</span><br></pre></td></tr></table></figure>
<p>为了兴趣，我们可以测试多个阈值，以按功能重要性选择要素。具体而言，每个输入变量的特征重要性，基本上允许我们按重要性测试每个特征子集，从所有特征开始，以具有最重要特征的子集结束。</p>
<p>完整的代码清单如下。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use feature importance for feature selection</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> sort</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># fit model on all training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># make predictions for test data and evaluate</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br><span class="line"><span class="comment"># Fit model using each importance as a threshold</span></span><br><span class="line">thresholds = sort(model.feature_importances_)</span><br><span class="line"><span class="keyword">for</span> thresh <span class="keyword">in</span> thresholds:</span><br><span class="line">	<span class="comment"># select features using threshold</span></span><br><span class="line">	selection = SelectFromModel(model, threshold=thresh, prefit=<span class="literal">True</span>)</span><br><span class="line">	select_X_train = selection.transform(X_train)</span><br><span class="line">	<span class="comment"># train model</span></span><br><span class="line">	selection_model = XGBClassifier()</span><br><span class="line">	selection_model.fit(select_X_train, y_train)</span><br><span class="line">	<span class="comment"># eval model</span></span><br><span class="line">	select_X_test = selection.transform(X_test)</span><br><span class="line">	y_pred = selection_model.predict(select_X_test)</span><br><span class="line">	predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line">	accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">	print(<span class="string">"Thresh=%.3f, n=%d, Accuracy: %.2f%%"</span> % (thresh, select_X_train.shape[<span class="number">1</span>], accuracy*<span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例将输出以下输出：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">77.95</span>%</span><br><span class="line">Thresh=<span class="number">0.071</span>, n=<span class="number">8</span>, Accuracy: <span class="number">77.95</span>%</span><br><span class="line">Thresh=<span class="number">0.073</span>, n=<span class="number">7</span>, Accuracy: <span class="number">76.38</span>%</span><br><span class="line">Thresh=<span class="number">0.084</span>, n=<span class="number">6</span>, Accuracy: <span class="number">77.56</span>%</span><br><span class="line">Thresh=<span class="number">0.090</span>, n=<span class="number">5</span>, Accuracy: <span class="number">76.38</span>%</span><br><span class="line">Thresh=<span class="number">0.128</span>, n=<span class="number">4</span>, Accuracy: <span class="number">76.38</span>%</span><br><span class="line">Thresh=<span class="number">0.160</span>, n=<span class="number">3</span>, Accuracy: <span class="number">74.80</span>%</span><br><span class="line">Thresh=<span class="number">0.186</span>, n=<span class="number">2</span>, Accuracy: <span class="number">71.65</span>%</span><br><span class="line">Thresh=<span class="number">0.208</span>, n=<span class="number">1</span>, Accuracy: <span class="number">63.78</span>%</span><br></pre></td></tr></table></figure>
<p>我们可以看到模型的表现通常随着所选特征的数量而减少。</p>
<p>在这个问题上，需要权衡测试集合精度的特征，我们可以决定采用较不复杂的模型（较少的属性，如 n = 4），并接受估计精度的适度降低，从 77.95％降至 76.38％。</p>
<p>这可能是对这么小的数据集的一种洗涤，但对于更大的数据集并且使用交叉验证作为模型评估方案可能是更有用的策略。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了如何在训练有素的 XGBoost 梯度提升模型中访问特征和使用重要性。</p>
<p>具体来说，你学到了：</p>
<ul>
<li>重要的是什么，一般如何在 XGBoost 中计算。</li>
<li>如何从 XGBoost 模型访问和绘制要素重要性分数。</li>
<li>如何使用 XGBoost 模型中的要素重要性来选择要素。</li>
</ul>
<p>您对 XGBoost 或此帖中的功能重要性有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/在 Python 中使用 XGBoost 的特征重要性和特征选择/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/如何在 Python 中使用 XGBoost 评估梯度提升模型" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/如何在 Python 中使用 XGBoost 评估梯度提升模型/">如何在 Python 中使用 XGBoost 评估梯度提升模型</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/如何在 Python 中使用 XGBoost 评估梯度提升模型/" class="archive-article-date">
  	<time datetime="2019-04-26T03:16:40.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="如何在-Python-中使用-XGBoost-评估梯度提升模型"><a href="#如何在-Python-中使用-XGBoost-评估梯度提升模型" class="headerlink" title="如何在 Python 中使用 XGBoost 评估梯度提升模型"></a>如何在 Python 中使用 XGBoost 评估梯度提升模型</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/evaluate-gradient-boosting-models-xgboost-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/evaluate-gradient-boosting-models-xgboost-python/</a></p>
</blockquote>
<p>开发预测模型的目标是开发一个对看不见的数据准确的模型。</p>
<p>这可以使用统计技术来实现，其中训练数据集被仔细地用于估计模型在新的和未看到的数据上的表现。</p>
<p>在本教程中，您将了解如何使用 Python 中的 XGBoost 评估梯度提升模型的表现。</p>
<p>完成本教程后，您将了解到。</p>
<ul>
<li>如何使用训练和测试数据集评估 XGBoost 模型的表现。</li>
<li>如何使用 k-fold 交叉验证评估 XGBoost 模型的表现。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
<li><strong>更新 March / 2018</strong> ：添加了备用链接以下载数据集，因为原始图像已被删除。</li>
</ul>
<p><img src="img/22202cde2c6a7833a222b951de920b6b.jpg" alt="How to Evaluate Gradient Boosting Models with XGBoost in Python"></p>
<p>如何在 Python 中使用 XGBoost 评估梯度提升模型<br>照片由 <a href="https://www.flickr.com/photos/nox_noctis_silentium/5526750448/" target="_blank" rel="noopener">Timitrius</a> ，保留一些权利。</p>
<h2 id="使用训练和测试集评估-XGBoost-模型"><a href="#使用训练和测试集评估-XGBoost-模型" class="headerlink" title="使用训练和测试集评估 XGBoost 模型"></a>使用训练和测试集评估 XGBoost 模型</h2><p>我们可以用来评估机器学习算法表现的最简单方法是使用不同的训练和测试数据集。</p>
<p>我们可以将原始数据集分成两部分。在第一部分训练算法，然后对第二部分进行预测，并根据预期结果评估预测。</p>
<p>拆分的大小可能取决于数据集的大小和细节，尽管通常使用 67％的数据进行训练，剩余的 33％用于测试。</p>
<p>该算法评估技术很快。它非常适用于大型数据集（数百万条记录），其中有强有力的证据表明数据的两个分裂都代表了潜在的问题。由于速度的原因，当您正在调查的算法训练缓慢时，使用此方法很有用。</p>
<p>这种技术的缺点是它可能具有很大的差异。这意味着训练和测试数据集的差异可能导致模型精度估计的有意义差异。</p>
<p>我们可以使用 scikit-learn 库中的 <strong>train_test_split（）</strong>函数将数据集拆分为训练和测试集。例如，我们可以将数据集拆分为 67％和 33％的分组，用于训练和测试集，如下所示：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">7</span>)</span><br></pre></td></tr></table></figure>
<p>下面使用 <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank" rel="noopener">Pima 印第安人糖尿病数据集</a>开始提供完整的代码清单，假设它位于当前工作目录中（更新：<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv" target="_blank" rel="noopener">从这里下载</a>）。具有默认配置的 XGBoost 模型适合训练数据集并在测试数据集上进行评估。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train-test split evaluation of xgboost model</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例总结了测试集上模型的表现。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">77.95</span>%</span><br></pre></td></tr></table></figure>
<h2 id="使用-k-fold-交叉验证评估-XGBoost-模型"><a href="#使用-k-fold-交叉验证评估-XGBoost-模型" class="headerlink" title="使用 k-fold 交叉验证评估 XGBoost 模型"></a>使用 k-fold 交叉验证评估 XGBoost 模型</h2><p>交叉验证是一种可用于估计机器学习算法表现的方法，其方差小于单个训练测试集拆分。</p>
<p>它的工作原理是将数据集分成 k 部分（例如 k = 5 或 k = 10）。每次分割数据称为折叠。该算法在 k-1 折叠上进行训练，其中一个被扣住并在保持的背部折叠上进行测试。重复这一过程，以便数据集的每个折叠都有机会成为阻碍测试集。</p>
<p>运行交叉验证后，您最终得到 k 个不同的表现分数，您可以使用均值和标准差来总结。</p>
<p>结果是在给定测试数据的情况下，对新数据的算法表现进行更可靠的估计。它更准确，因为算法在不同数据上被多次训练和评估。</p>
<p>k 的选择必须允许每个测试分区的大小足够大以成为问题的合理样本，同时允许对算法的训练测试评估的足够重复以提供对看不见的数据的算法表现的公平估计。 。对于数千或数万个观测值中的适度大小的数据集，k 值为 3,5 和 10 是常见的。</p>
<p>我们可以使用 scikit-learn 中提供的 k-fold 交叉验证支持。首先，我们必须创建 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html" target="_blank" rel="noopener">KFold</a> 对象，指定折叠的数量和数据集的大小。然后，我们可以将此方案与特定数据集一起使用。来自 scikit-learn 的 <strong>cross_val_score（）</strong>函数允许我们使用交叉验证方案评估模型，并返回每个折叠上训练的每个模型的分数列表。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kfold = KFold(n_splits=<span class="number">10</span>, random_state=<span class="number">7</span>)</span><br><span class="line">results = cross_val_score(model, X, Y, cv=kfold)</span><br></pre></td></tr></table></figure>
<p>下面提供了用于评估具有 k 折交叉验证的 XGBoost 模型的完整代码清单，以确保完整性。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k-fold cross validation evaluation of xgboost model</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># CV model</span></span><br><span class="line">model = xgboost.XGBClassifier()</span><br><span class="line">kfold = KFold(n_splits=<span class="number">10</span>, random_state=<span class="number">7</span>)</span><br><span class="line">results = cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%% (%.2f%%)"</span> % (results.mean()*<span class="number">100</span>, results.std()*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例总结了数据集上默认模型配置的表现，包括平均值和标准差分类精度。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">76.69</span>% (<span class="number">7.11</span>%)</span><br></pre></td></tr></table></figure>
<p>如果您有许多类用于分类类型预测建模问题，或者类是不平衡的（一个类的实例比另一个类多得多），那么在执行交叉验证时创建分层折叠可能是个好主意。</p>
<p>这具有在执行交叉验证评估时在每个折叠中强制执行与在整个训练数据集中相同的类分布的效果。 scikit-learn 库在 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html" target="_blank" rel="noopener">StratifiedKFold</a> 类中提供此功能。</p>
<p>下面是修改为使用分层交叉验证来评估 XGBoost 模型的相同示例。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stratified k-fold cross validation evaluation of xgboost model</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># CV model</span></span><br><span class="line">model = xgboost.XGBClassifier()</span><br><span class="line">kfold = StratifiedKFold(n_splits=<span class="number">10</span>, random_state=<span class="number">7</span>)</span><br><span class="line">results = cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%% (%.2f%%)"</span> % (results.mean()*<span class="number">100</span>, results.std()*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例将生成以下输出。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">76.95</span>% (<span class="number">5.88</span>%)</span><br></pre></td></tr></table></figure>
<h2 id="什么技术使用时"><a href="#什么技术使用时" class="headerlink" title="什么技术使用时"></a>什么技术使用时</h2><ul>
<li>通常，k 折交叉验证是用于评估机器学习算法在看不见的数据上的表现的金标准，其中 k 设置为 3,5 或 10。</li>
<li>当存在大量类或每个类的实例不平衡时，使用分层交叉验证来强制执行类分发。</li>
<li>使用慢速算法时，使用训练/测试分割有利于提高速度，并在使用大型数据集时产生具有较低偏差的表现估计。</li>
</ul>
<p>最好的建议是试验并找到一种快速解决问题的技术，并产生可用于制定决策的合理表现估算。</p>
<p>如果有疑问，请对回归问题使用 10 倍交叉验证，并对分类问题进行 10 倍交叉验证。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在本教程中，您了解了如何通过估计 XGBoost 模型在未见数据上的执行情况来评估它们。</p>
<p>具体来说，你学到了：</p>
<ul>
<li>如何将数据集拆分为训练和测试子集以进行训练和评估模型的表现。</li>
<li>如何在数据集的不同子集上创建 k XGBoost 模型并平均得分以获得更稳健的模型表现估计。</li>
<li>启发式帮助您在问题中选择训练测试拆分和 k 折交叉验证。</li>
</ul>
<p>您对如何评估 XGBoost 模型或该帖子的表现有任何疑问吗？在下面的评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/如何在 Python 中使用 XGBoost 评估梯度提升模型/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型/">如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型/" class="archive-article-date">
  	<time datetime="2019-04-26T03:16:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="如何使用-scikit-learn-在-Python-中开发您的第一个-XGBoost-模型"><a href="#如何使用-scikit-learn-在-Python-中开发您的第一个-XGBoost-模型" class="headerlink" title="如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型"></a>如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/" target="_blank" rel="noopener">https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/</a></p>
</blockquote>
<p>XGBoost 是梯度提升决策树的一种实现，旨在提高竞争机器学习速度和表现。</p>
<p>在这篇文章中，您将了解如何在 Python 中安装和创建第一个 XGBoost 模型。</p>
<p>阅读这篇文章后你会知道：</p>
<ul>
<li>如何在您的系统上安装 XGBoost 以便在 Python 中使用。</li>
<li>如何准备数据并训练您的第一个 XGBoost 模型。</li>
<li>如何使用 XGBoost 模型进行预测。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
<li><strong>2017 年 3 月更新</strong>：添加缺失导入，使导入更清晰。</li>
<li><strong>更新 March / 2018</strong> ：添加了备用链接以下载数据集，因为原始图像已被删除。</li>
</ul>
<p><img src="img/c4698227a6e8a3bd125ec3366c9ee135.jpg" alt="How to Develop Your First XGBoost Model in Python with scikit-learn"></p>
<p>如何用 scikit-learn 开发你的第一个 XGBoost 模型<br>照片由 <a href="https://www.flickr.com/photos/zappowbang/524307651/" target="_blank" rel="noopener">Justin Henry</a> 开发，保留一些权利。</p>
<h2 id="教程概述"><a href="#教程概述" class="headerlink" title="教程概述"></a>教程概述</h2><p>本教程分为以下 6 个部分：</p>
<ol>
<li>安装 XGBoost 以与 Python 一起使用。</li>
<li>问题定义和下载数据集。</li>
<li>加载并准备数据。</li>
<li>训练 XGBoost 模型。</li>
<li>进行预测并评估模型。</li>
<li>将它们结合在一起并运行示例。</li>
</ol>
<h2 id="1-安装-XGBoost-以便在-Python-中使用"><a href="#1-安装-XGBoost-以便在-Python-中使用" class="headerlink" title="1.安装 XGBoost 以便在 Python 中使用"></a>1.安装 XGBoost 以便在 Python 中使用</h2><p>假设您有一个可用的 SciPy 环境，可以使用 pip 轻松安装 XGBoost。</p>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install xgboost</span><br></pre></td></tr></table></figure>
<p>要更新 XGBoost 的安装，您可以键入：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install --upgrade xgboost</span><br></pre></td></tr></table></figure>
<p>如果您不能使用 pip 或者想要从 GitHub 运行最新代码，则另一种安装 XGBoost 的方法要求您复制 XGBoost 项目并执行手动构建和安装。</p>
<p>例如，要在 Mac OS X 上没有多线程构建 XGBoost（已经通过 macports 或 homebrew 安装了 GCC），您可以键入：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/dmlc/xgboost</span><br><span class="line">cd xgboost</span><br><span class="line">cp make/minimum.mk ./config.mk</span><br><span class="line">make -j4</span><br><span class="line">cd python-package</span><br><span class="line">sudo python setup.py install</span><br></pre></td></tr></table></figure>
<p>您可以在 <a href="http://xgboost.readthedocs.io/en/latest/build.html" target="_blank" rel="noopener">XGBoost 安装指南</a>上了解有关如何为不同平台安装 XGBoost 的更多信息。有关安装 XGBoost for Python 的最新说明，请参阅 <a href="https://github.com/dmlc/xgboost/tree/master/python-package" target="_blank" rel="noopener">XGBoost Python 包</a>。</p>
<p>作为参考，您可以查看 <a href="http://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="noopener">XGBoost Python API 参考</a>。</p>
<h2 id="2-问题描述：预测糖尿病的发病"><a href="#2-问题描述：预测糖尿病的发病" class="headerlink" title="2.问题描述：预测糖尿病的发病"></a>2.问题描述：预测糖尿病的发病</h2><p>在本教程中，我们将使用皮马印第安人糖尿病数据集。</p>
<p>该数据集由描述患者医疗细节的 8 个输入变量和一个输出变量组成，以指示患者是否在 5 年内患有糖尿病。</p>
<p>您可以在 UCI 机器学习存储库网站上了解有关此数据集的更多信息。</p>
<p>这是第一个 XGBoost 模型的一个很好的数据集，因为所有输入变量都是数字的，问题是一个简单的二进制分类问题。对于 XGBoost 算法来说，它不一定是一个好问题，因为它是一个相对较小的数据集，并且很容易建模。</p>
<p>下载此数据集并将其放入当前工作目录，文件名为“ <strong>pima-indians-diabetes.csv</strong> ”（更新：<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv" target="_blank" rel="noopener">从此处下载</a>）。</p>
<h2 id="3-加载和准备数据"><a href="#3-加载和准备数据" class="headerlink" title="3.加载和准备数据"></a>3.加载和准备数据</h2><p>在本节中，我们将从文件加载数据并准备用于训练和评估 XGBoost 模型。</p>
<p>我们将从导入我们打算在本教程中使用的类和函数开始。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>
<p>接下来，我们可以使用 NumPy 函数 <strong>loadtext（）</strong>将 CSV 文件作为 NumPy 数组加载。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br></pre></td></tr></table></figure>
<p>我们必须将数据集的列（属性或特征）分成输入模式（X）和输出模式（Y）。我们可以通过以 NumPy 数组格式指定列索引来轻松完成此操作。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br></pre></td></tr></table></figure>
<p>最后，我们必须将 X 和 Y 数据拆分为训练和测试数据集。训练集将用于准备 XGBoost 模型，测试集将用于进行新的预测，我们可以从中评估模型的表现。</p>
<p>为此，我们将使用 scikit-learn 库中的 <strong>train_test_split（）</strong>函数。我们还为随机数生成器指定种子，以便每次执行此示例时始终获得相同的数据分割。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)</span><br></pre></td></tr></table></figure>
<p>我们现在准备训练我们的模型。</p>
<h2 id="4-训练-XGBoost-模型"><a href="#4-训练-XGBoost-模型" class="headerlink" title="4.训练 XGBoost 模型"></a>4.训练 XGBoost 模型</h2><p>XGBoost 提供了一个包装类，允许在 scikit-learn 框架中将模型视为分类器或回归器。</p>
<p>这意味着我们可以使用带有 XGBoost 模型的完整 scikit-learn 库。</p>
<p>用于分类的 XGBoost 模型称为 <strong>XGBClassifier</strong> 。我们可以创建并使其适合我们的训练数据集。使用 scikit-learn API 和 <strong>model.fit（）</strong>函数拟合模型。</p>
<p>训练模型的参数可以传递给构造函数中的模型。在这里，我们使用合理的默认值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p>您可以通过打印模型来查看训练模型中使用的参数，例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<p>您可以在 <a href="http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn" target="_blank" rel="noopener">XGBoost Python scikit-learn API</a> 中了解有关 <strong>XGBClassifier</strong> 和 <strong>XGBRegressor</strong> 类的默认值的更多信息。</p>
<p>您可以在 <a href="http://xgboost.readthedocs.io/en/latest//parameter.html" target="_blank" rel="noopener">XGBoost 参数页面</a>上了解有关每个参数含义以及如何配置它们的更多信息。</p>
<p>我们现在准备使用训练有素的模型进行预测。</p>
<h2 id="5-使用-XGBoost-模型进行预测"><a href="#5-使用-XGBoost-模型进行预测" class="headerlink" title="5.使用 XGBoost 模型进行预测"></a>5.使用 XGBoost 模型进行预测</h2><p>我们可以使用测试数据集上的拟合模型进行预测。</p>
<p>为了进行预测，我们使用 scikit-learn 函数 <strong>model.predict（）</strong>。</p>
<p>默认情况下，XGBoost 进行的预测是概率。因为这是二元分类问题，所以每个预测是输入模式属于第一类的概率。我们可以通过将它们四舍五入为 0 或 1 来轻松地将它们转换为二进制类值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br></pre></td></tr></table></figure>
<p>现在我们已经使用拟合模型对新数据进行预测，我们可以通过将预测值与预期值进行比较来评估预测的表现。为此，我们将在 scikit-learn 中使用内置的 <strong>accuracy_score（）</strong>函数。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<h2 id="6-将它们捆绑在一起"><a href="#6-将它们捆绑在一起" class="headerlink" title="6.将它们捆绑在一起"></a>6.将它们捆绑在一起</h2><p>我们可以将所有这些部分组合在一起，下面是完整的代码清单。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First XGBoost model for Pima Indians dataset</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例将生成以下输出。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">77.95</span>%</span><br></pre></td></tr></table></figure>
<p>对于这个问题，这是一个<a href="http://www.is.umk.pl/projects/datasets.html#Diabetes" target="_blank" rel="noopener">良好的准确度得分，我们可以期待，考虑到模型的能力和问题的适度复杂性。</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您了解了如何在 Python 中开发第一个 XGBoost 模型。</p>
<p>具体来说，你学到了：</p>
<ul>
<li>如何在您的系统上安装 XGBoost 以备 Python 使用。</li>
<li>如何在标准机器学习数据集上准备数据并训练您的第一个 XGBoost 模型。</li>
<li>如何使用 scikit-learn 进行预测并评估训练有素的 XGBoost 模型的表现。</li>
</ul>
<p>您对 XGBoost 或该帖子有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/如何使用 scikit-learn 在 Python 中开发您的第一个 XGBoost 模型/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/在 Python 中使用 XGBoost 进行梯度提升的数据准备" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/在 Python 中使用 XGBoost 进行梯度提升的数据准备/">在 Python 中使用 XGBoost 进行梯度提升的数据准备</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/在 Python 中使用 XGBoost 进行梯度提升的数据准备/" class="archive-article-date">
  	<time datetime="2019-04-26T03:16:01.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="在-Python-中使用-XGBoost-进行梯度提升的数据准备"><a href="#在-Python-中使用-XGBoost-进行梯度提升的数据准备" class="headerlink" title="在 Python 中使用 XGBoost 进行梯度提升的数据准备"></a>在 Python 中使用 XGBoost 进行梯度提升的数据准备</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/data-preparation-gradient-boosting-xgboost-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/data-preparation-gradient-boosting-xgboost-python/</a></p>
</blockquote>
<p>XGBoost 因其速度和表现而成为 Gradient Boosting 的流行实现。</p>
<p>在内部，XGBoost 模型将所有问题表示为回归预测建模问题，仅将数值作为输入。如果您的数据格式不同，则必须将其准备为预期格式。</p>
<p>在这篇文章中，您将了解如何准备数据，以便在 Python 中使用 XGBoost 库进行梯度提升。</p>
<p>阅读这篇文章后你会知道：</p>
<ul>
<li>如何编码字符串输出变量进行分类。</li>
<li>如何使用一个热编码准备分类输入变量。</li>
<li>如何使用 XGBoost 自动处理丢失的数据。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2016 年 9 月更新</strong>：我在 impute 示例中更新了一些小错字。</li>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
<li><strong>2017 年 1 月更新</strong>：更新了将输入数据转换为字符串的乳腺癌示例。</li>
</ul>
<p><img src="img/93adf08afc03afb270f7ec43a70644cd.jpg" alt="Data Preparation for Gradient Boosting with XGBoost in Python"></p>
<p>使用 Python 中的 XGBoost 进行梯度提升的数据准备<br>照片由 <a href="https://www.flickr.com/photos/blachswan/14990404869/" target="_blank" rel="noopener">Ed Dunens</a> 拍摄，保留一些权利。</p>
<h2 id="标签编码字符串类值"><a href="#标签编码字符串类值" class="headerlink" title="标签编码字符串类值"></a>标签编码字符串类值</h2><p>虹膜花分类问题是具有字符串类值的问题的示例。</p>
<p>这是一个预测问题，其中以厘米为单位给出鸢尾花的测量值，任务是预测给定花属于哪个物种。</p>
<p>下面是原始数据集的示例。您可以从 <a href="http://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" rel="noopener">UCI 机器学习库</a>中了解有关此数据集的更多信息并以 CSV 格式下载原始数据。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br></pre></td></tr></table></figure>
<p>XGBoost 无法按原样对此问题进行建模，因为它要求输出变量为数字。</p>
<p>我们可以使用 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" target="_blank" rel="noopener">LabelEncoder</a> 轻松地将字符串值转换为整数值。三个类值（Iris-setosa，Iris-versicolor，Iris-virginica）被映射到整数值（0,1,2）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br></pre></td></tr></table></figure>
<p>我们将标签编码器保存为单独的对象，以便我们可以使用相同的编码方案转换训练以及稍后的测试和验证数据集。</p>
<p>下面是一个演示如何加载虹膜数据集的完整示例。请注意，Pandas 用于加载数据以处理字符串类值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># multiclass classification</span></span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">data = pandas.read_csv(<span class="string">'iris.csv'</span>, header=<span class="literal">None</span>)</span><br><span class="line">dataset = data.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">Y = dataset[:,<span class="number">4</span>]</span><br><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, label_encoded_y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = xgboost.XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">print(model)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行该示例将生成以下输出：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">XGBClassifier(base_score=<span class="number">0.5</span>, colsample_bylevel=<span class="number">1</span>, colsample_bytree=<span class="number">1</span>,</span><br><span class="line">       gamma=<span class="number">0</span>, learning_rate=<span class="number">0.1</span>, max_delta_step=<span class="number">0</span>, max_depth=<span class="number">3</span>,</span><br><span class="line">       min_child_weight=<span class="number">1</span>, missing=<span class="literal">None</span>, n_estimators=<span class="number">100</span>, nthread=<span class="number">-1</span>,</span><br><span class="line">       objective=<span class="string">'multi:softprob'</span>, reg_alpha=<span class="number">0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">       scale_pos_weight=<span class="number">1</span>, seed=<span class="number">0</span>, silent=<span class="literal">True</span>, subsample=<span class="number">1</span>)</span><br><span class="line">Accuracy: <span class="number">92.00</span>%</span><br></pre></td></tr></table></figure>
<p>请注意 XGBoost 模型如何配置为使用 <strong>multi：softprob</strong> 目标自动建模多类分类问题，该目标是 softmax loss 函数的一种变体，用于模拟类概率。这表明在内部，输出类自动转换为一种热类型编码。</p>
<h2 id="一个热编码分类数据"><a href="#一个热编码分类数据" class="headerlink" title="一个热编码分类数据"></a>一个热编码分类数据</h2><p>一些数据集仅包含分类数据，例如乳腺癌数据集。</p>
<p>该数据集描述了乳腺癌活组织检查的技术细节，预测任务是预测患者是否复发癌症。</p>
<p>下面是原始数据集的示例。您可以在 <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer" target="_blank" rel="noopener">UCI 机器学习库</a>中了解有关此数据集的更多信息，并从 <a href="http://mldata.org/repository/data/viewslug/datasets-uci-breast-cancer/" target="_blank" rel="noopener">mldata.org</a> 以 CSV 格式下载。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'40-49'</span>,<span class="string">'premeno'</span>,<span class="string">'15-19'</span>,<span class="string">'0-2'</span>,<span class="string">'yes'</span>,<span class="string">'3'</span>,<span class="string">'right'</span>,<span class="string">'left_up'</span>,<span class="string">'no'</span>,<span class="string">'recurrence-events'</span></span><br><span class="line"><span class="string">'50-59'</span>,<span class="string">'ge40'</span>,<span class="string">'15-19'</span>,<span class="string">'0-2'</span>,<span class="string">'no'</span>,<span class="string">'1'</span>,<span class="string">'right'</span>,<span class="string">'central'</span>,<span class="string">'no'</span>,<span class="string">'no-recurrence-events'</span></span><br><span class="line"><span class="string">'50-59'</span>,<span class="string">'ge40'</span>,<span class="string">'35-39'</span>,<span class="string">'0-2'</span>,<span class="string">'no'</span>,<span class="string">'2'</span>,<span class="string">'left'</span>,<span class="string">'left_low'</span>,<span class="string">'no'</span>,<span class="string">'recurrence-events'</span></span><br><span class="line"><span class="string">'40-49'</span>,<span class="string">'premeno'</span>,<span class="string">'35-39'</span>,<span class="string">'0-2'</span>,<span class="string">'yes'</span>,<span class="string">'3'</span>,<span class="string">'right'</span>,<span class="string">'left_low'</span>,<span class="string">'yes'</span>,<span class="string">'no-recurrence-events'</span></span><br><span class="line"><span class="string">'40-49'</span>,<span class="string">'premeno'</span>,<span class="string">'30-34'</span>,<span class="string">'3-5'</span>,<span class="string">'yes'</span>,<span class="string">'2'</span>,<span class="string">'left'</span>,<span class="string">'right_up'</span>,<span class="string">'no'</span>,<span class="string">'recurrence-events'</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到所有 9 个输入变量都是分类的，并以字符串格式描述。问题是二进制分类预测问题，输出类值也以字符串格式描述。</p>
<p>我们可以重用上一节中的相同方法，并将字符串类值转换为整数值，以使用 LabelEncoder 对预测进行建模。例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br></pre></td></tr></table></figure>
<p>我们可以在 X 中的每个输入要素上使用相同的方法，但这只是一个起点。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode string input values as integers</span></span><br><span class="line">features = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, X.shape[<span class="number">1</span>]):</span><br><span class="line">	label_encoder = LabelEncoder()</span><br><span class="line">	feature = label_encoder.fit_transform(X[:,i])</span><br><span class="line">	features.append(feature)</span><br><span class="line">encoded_x = numpy.array(features)</span><br><span class="line">encoded_x = encoded_x.reshape(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>XGBoost 可以假设每个输入变量的编码整数值具有序数关系。例如，对于 breast-quad 变量，“left-up”编码为 0 并且“left-low”编码为 1 具有作为整数的有意义的关系。在这种情况下，这种假设是不真实的。</p>
<p>相反，我们必须将这些整数值映射到新的二进制变量，每个分类值都有一个新变量。</p>
<p>例如，breast-quad 变量具有以下值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">left-up</span><br><span class="line">left-low</span><br><span class="line">right-up</span><br><span class="line">right-low</span><br><span class="line">central</span><br></pre></td></tr></table></figure>
<p>我们可以将其建模为 5 个二进制变量，如下所示：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">left-up, left-low, right-up, right-low, central</span><br><span class="line"><span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line"><span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line"><span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line"><span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span></span><br><span class="line"><span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这称为<a href="https://en.wikipedia.org/wiki/One-hot" target="_blank" rel="noopener">一个热编码</a>。我们可以使用 scikit-learn 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" target="_blank" rel="noopener">OneHotEncoder</a> 类对所有分类输入变量进行热编码。</p>
<p>在我们对其进行标签编码后，我们可以对每个功能进行热编码。首先，我们必须将要素数组转换为 2 维 NumPy 数组，其中每个整数值是长度为 1 的要素向量。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature = feature.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>然后我们可以创建 OneHotEncoder 并对特征数组进行编码。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">onehot_encoder = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">feature = onehot_encoder.fit_transform(feature)</span><br></pre></td></tr></table></figure>
<p>最后，我们可以通过逐个连接一个热编码特征来建立输入数据集，将它们作为新列添加（轴= 2）。我们最终得到一个由 43 个二进制输入变量组成的输入向量。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode string input values as integers</span></span><br><span class="line">encoded_x = <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, X.shape[<span class="number">1</span>]):</span><br><span class="line">	label_encoder = LabelEncoder()</span><br><span class="line">	feature = label_encoder.fit_transform(X[:,i])</span><br><span class="line">	feature = feature.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">	onehot_encoder = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">	feature = onehot_encoder.fit_transform(feature)</span><br><span class="line">	<span class="keyword">if</span> encoded_x <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">		encoded_x = feature</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		encoded_x = numpy.concatenate((encoded_x, feature), axis=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"X shape: : "</span>, encoded_x.shape)</span><br></pre></td></tr></table></figure>
<p>理想情况下，我们可以尝试不使用一个热编码输入属性，因为我们可以使用显式序数关系对它们进行编码，例如第一个列的年龄值为’40 -49’和’50 -59’。如果您有兴趣扩展此示例，则将其留作练习。</p>
<p>下面是带有标签和一个热编码输入变量和标签编码输出变量的完整示例。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># binary classification, breast cancer dataset, label and one hot encoded</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">data = read_csv(<span class="string">'datasets-uci-breast-cancer.csv'</span>, header=<span class="literal">None</span>)</span><br><span class="line">dataset = data.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">9</span>]</span><br><span class="line">X = X.astype(str)</span><br><span class="line">Y = dataset[:,<span class="number">9</span>]</span><br><span class="line"><span class="comment"># encode string input values as integers</span></span><br><span class="line">encoded_x = <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, X.shape[<span class="number">1</span>]):</span><br><span class="line">	label_encoder = LabelEncoder()</span><br><span class="line">	feature = label_encoder.fit_transform(X[:,i])</span><br><span class="line">	feature = feature.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">	onehot_encoder = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">	feature = onehot_encoder.fit_transform(feature)</span><br><span class="line">	<span class="keyword">if</span> encoded_x <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">		encoded_x = feature</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		encoded_x = numpy.concatenate((encoded_x, feature), axis=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"X shape: : "</span>, encoded_x.shape)</span><br><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">print(model)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例，我们得到以下输出：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(<span class="string">'X shape: : '</span>, (<span class="number">285</span>, <span class="number">43</span>))</span><br><span class="line">XGBClassifier(base_score=<span class="number">0.5</span>, colsample_bylevel=<span class="number">1</span>, colsample_bytree=<span class="number">1</span>,</span><br><span class="line">       gamma=<span class="number">0</span>, learning_rate=<span class="number">0.1</span>, max_delta_step=<span class="number">0</span>, max_depth=<span class="number">3</span>,</span><br><span class="line">       min_child_weight=<span class="number">1</span>, missing=<span class="literal">None</span>, n_estimators=<span class="number">100</span>, nthread=<span class="number">-1</span>,</span><br><span class="line">       objective=<span class="string">'binary:logistic'</span>, reg_alpha=<span class="number">0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">       scale_pos_weight=<span class="number">1</span>, seed=<span class="number">0</span>, silent=<span class="literal">True</span>, subsample=<span class="number">1</span>)</span><br><span class="line">Accuracy: <span class="number">71.58</span>%</span><br></pre></td></tr></table></figure>
<p>我们再次看到 XGBoost 框架自动选择’ <strong>binary：logistic</strong> ‘目标，这是二进制分类问题的正确目标。</p>
<h2 id="支持缺失数据"><a href="#支持缺失数据" class="headerlink" title="支持缺失数据"></a>支持缺失数据</h2><p>XGBoost 可以自动学习如何最好地处理丢失的数据。</p>
<p>事实上，XGBoost 被设计为处理稀疏数据，如前一节中的一个热编码数据，并且通过最小化损失函数来处理丢失数据的方式与处理稀疏或零值的方式相同。</p>
<p>有关如何在 XGBoost 中处理缺失值的技术细节的更多信息，请参见文章 <a href="https://arxiv.org/abs/1603.02754" target="_blank" rel="noopener">XGBoost：可伸缩树升压系统</a>中的第 3.4 节“_ 稀疏感知拆分查找 _”。</p>
<p>Horse Colic 数据集是演示此功能的一个很好的示例，因为它包含大部分缺失数据，大约 30％。</p>
<p>您可以了解有关 Horse Colic 数据集的更多信息，并从 <a href="https://archive.ics.uci.edu/ml/datasets/Horse+Colic" target="_blank" rel="noopener">UCI 机器学习库</a>下载原始数据文件。</p>
<p>这些值由空格分隔，我们可以使用 Pandas 函数 <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" target="_blank" rel="noopener">read_csv</a> 轻松加载它。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataframe = read_csv(<span class="string">"horse-colic.csv"</span>, delim_whitespace=<span class="literal">True</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>加载后，我们可以看到缺少的数据标有问号字符（’？’）。我们可以将这些缺失值更改为 XGBoost 预期的稀疏值，即值零（0）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set missing values to 0</span></span><br><span class="line">X[X == <span class="string">'?'</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>由于缺少的数据被标记为字符串，因此缺少数据的那些列都作为字符串数据类型加载。我们现在可以将整个输入数据集转换为数值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># convert to numeric</span></span><br><span class="line">X = X.astype(<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>
<p>最后，这是一个二元分类问题，尽管类值用整数 1 和 2 标记。我们将 XGBoost 中的二进制分类问题建模为逻辑 0 和 1 值。我们可以使用 LabelEncoder 轻松地将 Y 数据集转换为 0 和 1 整数，就像我们在虹膜花示例中所做的那样。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode Y class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br></pre></td></tr></table></figure>
<p>完整性代码清单如下所示。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># binary classification, missing data</span></span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataframe = read_csv(<span class="string">"horse-colic.csv"</span>, delim_whitespace=<span class="literal">True</span>, header=<span class="literal">None</span>)</span><br><span class="line">dataset = dataframe.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">27</span>]</span><br><span class="line">Y = dataset[:,<span class="number">27</span>]</span><br><span class="line"><span class="comment"># set missing values to 0</span></span><br><span class="line">X[X == <span class="string">'?'</span>] = <span class="number">0</span></span><br><span class="line"><span class="comment"># convert to numeric</span></span><br><span class="line">X = X.astype(<span class="string">'float32'</span>)</span><br><span class="line"><span class="comment"># encode Y class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, label_encoded_y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">print(model)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例将生成以下输出。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">XGBClassifier(base_score=<span class="number">0.5</span>, colsample_bylevel=<span class="number">1</span>, colsample_bytree=<span class="number">1</span>,</span><br><span class="line">       gamma=<span class="number">0</span>, learning_rate=<span class="number">0.1</span>, max_delta_step=<span class="number">0</span>, max_depth=<span class="number">3</span>,</span><br><span class="line">       min_child_weight=<span class="number">1</span>, missing=<span class="literal">None</span>, n_estimators=<span class="number">100</span>, nthread=<span class="number">-1</span>,</span><br><span class="line">       objective=<span class="string">'binary:logistic'</span>, reg_alpha=<span class="number">0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">       scale_pos_weight=<span class="number">1</span>, seed=<span class="number">0</span>, silent=<span class="literal">True</span>, subsample=<span class="number">1</span>)</span><br><span class="line">Accuracy: <span class="number">83.84</span>%</span><br></pre></td></tr></table></figure>
<p>我们可以通过使用非零值（例如 1）标记缺失值来梳理 XGBoost 自动处理缺失值的效果。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[X == <span class="string">'?'</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>重新运行该示例表明模型的准确性下降。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">79.80</span>%</span><br></pre></td></tr></table></figure>
<p>我们还可以使用特定值来估算缺失的数据。</p>
<p>通常使用列的平均值或中值。我们可以使用 scikit-learn <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html" target="_blank" rel="noopener">Imputer</a> 类轻松地估算缺失的数据。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># impute missing values as the mean</span></span><br><span class="line">imputer = Imputer()</span><br><span class="line">imputed_x = imputer.fit_transform(X)</span><br></pre></td></tr></table></figure>
<p>下面是完整的示例，其中缺少的数据与每列的平均值估算。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># binary classification, missing data, impute with mean</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataframe = read_csv(<span class="string">"horse-colic.csv"</span>, delim_whitespace=<span class="literal">True</span>, header=<span class="literal">None</span>)</span><br><span class="line">dataset = dataframe.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">27</span>]</span><br><span class="line">Y = dataset[:,<span class="number">27</span>]</span><br><span class="line"><span class="comment"># set missing values to 0</span></span><br><span class="line">X[X == <span class="string">'?'</span>] = numpy.nan</span><br><span class="line"><span class="comment"># convert to numeric</span></span><br><span class="line">X = X.astype(<span class="string">'float32'</span>)</span><br><span class="line"><span class="comment"># impute missing values as the mean</span></span><br><span class="line">imputer = Imputer()</span><br><span class="line">imputed_x = imputer.fit_transform(X)</span><br><span class="line"><span class="comment"># encode Y class values as integers</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder = label_encoder.fit(Y)</span><br><span class="line">label_encoded_y = label_encoder.transform(Y)</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(imputed_x, label_encoded_y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">print(model)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例，我们看到的结果等同于将值固定为一（1）。这表明至少在这种情况下，我们最好用不同的零（0）值而不是有效值（1）或估算值来标记缺失值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">79.80</span>%</span><br></pre></td></tr></table></figure>
<p>当您缺少值时，尝试这两种方法（自动处理和输入）是一个很好的教训。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了如何使用 Python 中的 XGBoost 为梯度提升准备机器学习数据。</p>
<p>具体来说，你学到了：</p>
<ul>
<li>如何使用标签编码为二进制分类准备字符串类值。</li>
<li>如何使用一个热编码准备分类输入变量以将它们建模为二进制变量。</li>
<li>XGBoost 如何自动处理丢失的数据以及如何标记和估算缺失值。</li>
</ul>
<p>您对如何为 XGBoost 或此帖子准备数据有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/在 Python 中使用 XGBoost 进行梯度提升的数据准备/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/如何配置梯度提升算法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/如何配置梯度提升算法/">如何配置梯度提升算法</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/如何配置梯度提升算法/" class="archive-article-date">
  	<time datetime="2019-04-26T03:15:40.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="如何配置梯度提升算法"><a href="#如何配置梯度提升算法" class="headerlink" title="如何配置梯度提升算法"></a>如何配置梯度提升算法</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/configure-gradient-boosting-algorithm/" target="_blank" rel="noopener">https://machinelearningmastery.com/configure-gradient-boosting-algorithm/</a></p>
</blockquote>
<p>梯度提升是应用机器学习最强大的技术之一，因此很快成为最受欢迎的技术之一。</p>
<p>但是，如何为您的问题配置梯度提升？</p>
<p>在这篇文章中，您将了解如何通过查看书籍，论文和竞赛结果中报告的配置来配置机器学习问题的梯度提升。</p>
<p>阅读这篇文章后，你会知道：</p>
<ul>
<li>如何根据原始来源配置梯度提升。</li>
<li>从标准实现中的默认值和建议配置算法的想法。</li>
<li>从顶级 Kaggle 竞争对手配置梯度提升和 XGBoost 的经验法则。</li>
</ul>
<p>让我们开始吧。</p>
<p><img src="img/e28ff0c7b20a64f211069bb538f08486.jpg" alt="How to Configure the Gradient Boosting Algorithm"></p>
<p>如何配置梯度提升算法<br>照片来自 <a href="https://www.flickr.com/photos/stone65/7925550064/" target="_blank" rel="noopener">Chris Sorge</a> ，保留一些权利。</p>
<h2 id="如何配置梯度增压机"><a href="#如何配置梯度增压机" class="headerlink" title="如何配置梯度增压机"></a>如何配置梯度增压机</h2><p>在 1999 年的论文“<a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">贪婪函数逼近：梯度提升机</a>”中，Jerome Friedman 评论了树木数量（M）和学习率（v）之间的权衡：</p>
<blockquote>
<p>v-M 的权衡显而易见;较小的 v 值会产生较大的最佳 M 值。它们还提供更高的准确度，v <1 的回报递减。 0.125。对于 m> 1，错误分类错误率非常平坦。 200，因此它的最佳 M 值是不稳定的。 ……这些结果的定性性质相当普遍。</1></p>
</blockquote>
<p>他建议首先为树木数量设置一个较大的值，然后调整收缩参数以获得最佳结果。本文的研究优选收缩值为 0.1，树木的数量在 100 到 500 之间，树木中的终端节点数在 2 到 8 之间。</p>
<p>在 1999 年的论文“ <a href="https://statweb.stanford.edu/~jhf/ftp/stobst.pdf" target="_blank" rel="noopener">Stochastic Gradient Boosting</a> ”中，弗里德曼重申了对收缩参数的偏好：</p>
<blockquote>
<p>“收缩”参数 0 &lt; v＆lt; 1 控制程序的学习率。根据经验……，发现小值（v​​ &lt;= 0.1）导致更好的泛化误差。</p>
</blockquote>
<p>在论文中，弗里德曼介绍并实证研究了随机梯度提升（基于行的子采样）。他发现几乎所有的子采样百分比都比所谓的确定性提升更好，或许 30％到 50％是一个很好的选择一些问题的价值和 50％到 80％的其他问题。</p>
<blockquote>
<p>…采样分数的最佳值…约为 40％（f = 0.4）……然而，在每次迭代中仅采样 30％甚至 20％的数据比没有采样有相当大的改进，并且具有相应的计算速度 - 因子分别为 3 和 5。</p>
</blockquote>
<p>他还研究了树木中终端节点数量的影响，发现像 3 和 6 这样的值比 11,21 和 41 等更大的值更好。</p>
<blockquote>
<p>在两种情况下，平均超过 100 个目标的最佳树大小是 L = 6.通过使用较大的树来增加基础学习器的容量通过“过度拟合”降低表现。</p>
</blockquote>
<p>在 H2O 中题为“<a href="https://www.youtube.com/watch?v=wPqtzj5VZus" target="_blank" rel="noopener">梯度提升机器学习</a>”的演讲中，Trevor Hastie 评论说，一般梯度提升比随机森林表现更好，后者反过来比单个决策树表现更好。</p>
<blockquote>
<p>随机森林＆gt;套袋＆gt;单树</p>
</blockquote>
<p>第 10 章标题为“<a href="http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20" target="_blank" rel="noopener">统计学习要素：数据挖掘，推理和预测</a>”中的“提升和加性树”专门用于提升。在其中，它们提供了用于配置梯度提升的启发式方法以及一些实证研究。</p>
<p>他们评论说树中的节点数（J）的值很好，约为 6，通常在 4 到 8 的范围内有良好的值。</p>
<blockquote>
<p>虽然在许多应用中 J = 2 是不够的，但是 J&gt;不可能。将需要 10。到目前为止的经验表明 4＆lt; = J＆lt; = 8 在增强的情况下工作良好，结果对该范围内的特定选择相当不敏感。</p>
</blockquote>
<p>他们建议监控验证数据集的表现，以便校准树的数量，并在验证数据集的表现开始降低后使用早期停止程序。</p>
<p>正如在弗里德曼的第一个梯度提升论文中，他们评论了树木数量（M）和学习率（v）之间的权衡，并建议学习率的一个小值＆lt; 0.1。</p>
<blockquote>
<p>对于相同的训练风险，较小的 v 值导致较大的 M 值，因此在它们之间存在折衷。 ……实际上，最好的策略似乎是将 v 设置得非常小（v &lt;0.1），然后通过提前停止选择 M.</p>
</blockquote>
<p>此外，正如弗里德曼的随机梯度提升纸一样，他们建议采用二次采样百分比（n）而不更换值约为 50％。</p>
<blockquote>
<p>n 的典型值可以是 1/2，但是对于大的 N，n 可以基本上小于 1/2。</p>
</blockquote>
<h2 id="R-中梯度提升的配置"><a href="#R-中梯度提升的配置" class="headerlink" title="R 中梯度提升的配置"></a>R 中梯度提升的配置</h2><p>梯度提升算法在 R 中实现为 <a href="https://cran.r-project.org/web/packages/gbm/index.html" target="_blank" rel="noopener">gbm 包</a>。</p>
<p>回顾<a href="https://cran.r-project.org/web/packages/gbm/gbm.pdf" target="_blank" rel="noopener">软件包文档</a>，gbm（）函数指定合理的默认值：</p>
<ul>
<li>n.trees = 100（树木数量）。</li>
<li>interaction.depth = 1（叶数）。</li>
<li>n.minobsinnode = 10（树终端节点中的最小样本数）。</li>
<li>收缩率= 0.001（学习率）。</li>
</ul>
<p>值得注意的是，使用较小的收缩因子并且树桩是默认值。接下来，里奇韦解释了小的收缩。</p>
<p>在 R 中使用 gbm 软件包的标题为“ <a href="http://www.saedsayad.com/docs/gbm2.pdf" target="_blank" rel="noopener">Generalized Boosted Models：gbm 软件包的指南</a>”中，Greg Ridgeway 提供了一些使用启发式方法。他建议第一次将学习率（lambda）设置为尽可能小，然后使用交叉验证调整树的数量（迭代或 T）。</p>
<blockquote>
<p>在实践中，我将 lambda 设置为尽可能小，然后通过交叉验证选择 T.当 lambda 尽可能小的表现时，表现最佳，并且对于越来越小的 lambda，边际效用越来越小。</p>
</blockquote>
<p>他评论了他将默认收缩率设置为 0.001 而不是 0.1 的小值的基本原理。</p>
<blockquote>
<p>重要的是要知道较小的收缩值（几乎）总能提高预测表现。也就是说，设置收缩率= 0.001 几乎肯定会导致模型具有比设置收缩率= 0.01 更好的样本外预测表现。 …收缩率= 0.001 的模型可能需要十倍于具有收缩率= 0.01 的模型的迭代次数</p>
</blockquote>
<p>Ridgeway 还使用了大量的树（这里称为迭代），数千而不是数百</p>
<blockquote>
<p>我通常瞄准 3,000 到 10,000 次迭代，收缩率在 0.01 到 0.001 之间。</p>
</blockquote>
<h2 id="在-scikit-learn-中配置梯度提升"><a href="#在-scikit-learn-中配置梯度提升" class="headerlink" title="在 scikit-learn 中配置梯度提升"></a>在 scikit-learn 中配置梯度提升</h2><p>Python 库提供了用于分类的梯度提升的实现，称为 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" target="_blank" rel="noopener">GradientBoostingClassifier</a> 类，并且回归称为 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html" target="_blank" rel="noopener">GradientBoostingRegressor</a> 类。</p>
<p>查看此库中算法的默认配置很有用。</p>
<p>有许多参数，但下面是几个关键的默认值。</p>
<ul>
<li>learning_rate = 0.1（收缩）。</li>
<li>n_estimators = 100（树的数量）。</li>
<li>MAX_DEPTH = 3。</li>
<li>min_samples_split = 2。</li>
<li>min_samples_leaf = 1。</li>
<li>子样本= 1.0。</li>
</ul>
<p>有趣的是，默认收缩与 Friedman 匹配，并且树深度未设置为 R 包之类的树桩。树深度为 3（如果创建的树是对称的）将具有 8 个叶节点，匹配 Friedman 研究中的首选终端节点数的上限（可以设置 max_leaf_nodes）。</p>
<p>在标题为“ <a href="http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting" target="_blank" rel="noopener">Gradient Tree Boosting</a> ”的部分下的 scikit-learn 用户指南中，作者评论说，设置最大叶节点与将最大深度设置为减去最大叶节点的效果类似，但结果表现更差。</p>
<blockquote>
<p>我们发现 max_leaf_nodes = k 给出了与 max_depth = k-1 相当的结果，但是以稍高的训练误差为代价训练得更快。</p>
</blockquote>
<p>在一项小型研究中，证明了梯度提升的正则化方法“<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regularization.html" target="_blank" rel="noopener">梯度提升正则化</a>”，结果显示了使用收缩和二次采样的好处。</p>
<h2 id="在-XGBoost-中配置梯度提升"><a href="#在-XGBoost-中配置梯度提升" class="headerlink" title="在 XGBoost 中配置梯度提升"></a>在 XGBoost 中配置梯度提升</h2><p>XGBoost 库专用于梯度提升算法。</p>
<p>它也指定了值得注意的默认参数，首先是 <a href="https://github.com/dmlc/xgboost/blob/master/doc/parameter.md" target="_blank" rel="noopener">XGBoost 参数页面</a>：</p>
<ul>
<li>eta = 0.3（收缩率或学习率）。</li>
<li>MAX_DEPTH = 6。</li>
<li>子样本= 1。</li>
</ul>
<p>与大多数研究和其他图书馆相比，这显示出更高的学习率和更大的最大深度。同样，我们可以在 <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="noopener">Python API 参考</a>中总结 XGBoost 的默认参数。</p>
<ul>
<li>MAX_DEPTH = 3。</li>
<li>learning_rate = 0.1。</li>
<li>n_estimators = 100。</li>
<li>子样本= 1。</li>
</ul>
<p>这些默认值通常更符合 scikit-learn 默认值和论文推荐。</p>
<p>在与 TechEd Europe 的一次题为“ <a href="https://www.youtube.com/watch?v=0IhraqUVJ_E" target="_blank" rel="noopener">xgboost：用于快速和准确梯度提升</a>的 R 包”的谈话中，当被问及如何配置 XGBoost 时，Tong He 建议调整三个最重要的参数：</p>
<ul>
<li>树木数量。</li>
<li>树深度。</li>
<li>步长（学习率）。</li>
</ul>
<p>他还为新问题提供了简洁的配置策略：</p>
<ol>
<li>运行默认配置（并且可能会查看学习曲线？）。</li>
<li>如果系统过度学习，请减慢学习速度（使用收缩？）。</li>
<li>如果系统学习不足，可以加快学习速度（使用收缩？）。</li>
</ol>
<p>在 Owen Zhang 于 2015 年与 NYC 数据科学学院进行的题为“<a href="https://www.youtube.com/watch?v=LgLcfZjNF44" target="_blank" rel="noopener">获奖数据科学竞赛</a>”的谈话中，他提供了一些使用 XGBoost 配置梯度提升的一般技巧。 Owen 是梯度提升的重要用户。</p>
<blockquote>
<p>我的忏悔：我（过）使用 GBM。如有疑问，请使用 GBM。</p>
</blockquote>
<p>他提供了一些配置梯度提升的技巧：</p>
<ul>
<li>学习率+树木数量：定位 500 到 1000 棵树并调整学习率。</li>
<li>叶子中的样本数量：获得良好平均估计值所需的观察数量。</li>
<li>互动深度：10+。</li>
</ul>
<p>在同一个谈话的<a href="http://www.slideshare.net/ShangxuanZhang/winning-data-science-competitions-presented-by-owen-zhang" target="_blank" rel="noopener">更新幻灯片中，他总结了他用于 XGBoost 的常见参数：</a></p>
<p><img src="img/a135310fc17a2814209801719aeeeceb.jpg" alt="Owen Zhang Table of Suggestions for Hyperparameter Tuning of XGBoost"></p>
<p>Owen Zhang 超级参数调整 XGBoost 的建议表</p>
<p>我们可以在这张表中看到一些有趣的东西。</p>
<ul>
<li>将学习率与树木数量的关系简化为近似比例：学习率= [2-10] /树。</li>
<li>探索随机梯度提升的行和列采样的值。</li>
<li>探索与弗里德曼（4-10）报道的最大深度相同的范围。</li>
<li>调整最小叶重量，作为罕见事件数量百分比的近似比率为 3。</li>
</ul>
<p>欧文在 2015 年波士顿 ODSC 题为“<a href="https://www.youtube.com/watch?v=7YnVZrabTA8" target="_blank" rel="noopener">开源工具和数据科学竞赛</a>”的类似演讲中，他再次总结了他使用的常用参数：</p>
<p><img src="img/e5b7b7097db7d9e7fd1c4b15821ce44c.jpg" alt="Owen Zhang Suggestions for Tuning XGBoost"></p>
<p>Owen Zhang 关于调整 XGBoost 的建议</p>
<p>我们可以看到一些可能相关的细微差别。</p>
<ul>
<li>目标 100 而不是 1000 棵树并调整学习率。</li>
<li>最小孩子体重在事件率的平方根上为 1。</li>
<li>没有行的子采样。</li>
</ul>
<p>最后，Abhishek Thakur 在题为“<a href="https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur" target="_blank" rel="noopener">接近（几乎）任何机器学习问题</a>”的帖子中提供了一个类似的表格，列出了关键的 XGBoost 参数和调整建议。</p>
<p><img src="img/5d3f0eee33d08c57dec1e88506d7cc2a.jpg" alt="Abhishek Thakur Suggestions for Tuning XGBoost"></p>
<p>Abhishek Thakur 对调整 XGBoost 的建议</p>
<p>点差确实涵盖了上面建议的一般默认值以及更多。</p>
<p>值得注意的是，Abhishek 确实提供了一些调整 alpha 和 beta 模型惩罚术语以及行采样的建议。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您深入了解了如何为您自己的机器学习问题配置梯度提升。</p>
<p>特别是你学到了：</p>
<ul>
<li>关于树木数量的折衷以及子采样的收缩和良好的默认值。</li>
<li>关于限制树大小的不同想法以及树深度和终端节点数量的良好默认值。</li>
<li>顶级 Kaggle 比赛获胜者使用的网格搜索策略。</li>
</ul>
<p>您对配置梯度提升或关于此帖子有任何疑问吗？在评论中提出您的问题。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/如何配置梯度提升算法/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/如何在 Python 中调优 XGBoost 的多线程支持" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/如何在 Python 中调优 XGBoost 的多线程支持/">如何在 Python 中调优 XGBoost 的多线程支持</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/如何在 Python 中调优 XGBoost 的多线程支持/" class="archive-article-date">
  	<time datetime="2019-04-26T03:15:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="如何在-Python-中调优-XGBoost-的多线程支持"><a href="#如何在-Python-中调优-XGBoost-的多线程支持" class="headerlink" title="如何在 Python 中调优 XGBoost 的多线程支持"></a>如何在 Python 中调优 XGBoost 的多线程支持</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/best-tune-multithreading-support-xgboost-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/best-tune-multithreading-support-xgboost-python/</a></p>
</blockquote>
<p>用于梯度提升用途的 XGBoost 库专为高效的多核并行处理而设计。</p>
<p>这使它可以在训练时有效地使用系统中的所有 CPU 核心。</p>
<p>在这篇文章中，您将发现 Python 中 XGBoost 的并行处理功能。</p>
<p>阅读这篇文章后你会知道：</p>
<ul>
<li>如何确认 XGBoost 多线程支持在您的系统上正在运行。</li>
<li>如何评估增加 XGBoost 上的线程数的效果。</li>
<li>如何在使用交叉验证和网格搜索时充分利用多线程 XGBoost。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
</ul>
<p><img src="img/ed8730017a4b756792937527e1a8af75.jpg" alt="How to Best Tune Multithreading Support for XGBoost in Python"></p>
<p>如何最好地调整 Python 中 XGBoost 的多线程支持<br>照片由 <a href="https://www.flickr.com/photos/nicholas_t/14946860658/" target="_blank" rel="noopener">Nicholas A. Tonelli</a> ，保留一些权利。</p>
<h2 id="问题描述：Otto-Dataset"><a href="#问题描述：Otto-Dataset" class="headerlink" title="问题描述：Otto Dataset"></a>问题描述：Otto Dataset</h2><p>在本教程中，我们将使用 <a href="https://www.kaggle.com/c/otto-group-product-classification-challenge" target="_blank" rel="noopener">Otto Group 产品分类挑战</a>数据集。</p>
<p>此数据集可从 Kaggle 获得（您需要注册 Kaggle 才能下载此数据集）。您可以从<a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/data" target="_blank" rel="noopener">数据页面</a>下载训练数据集 <strong>train.zip</strong> ，并将解压缩的 <strong>trian.csv</strong> 文件放入您的工作目录。</p>
<p>该数据集描述了超过 61,000 种产品的 93 个模糊细节，这些产品分为 10 个产品类别（例如时尚，电子等）。输入属性是某种不同事件的计数。</p>
<p>目标是对新产品进行预测，因为 10 个类别中的每个类别都有一组概率，并且使用多类对数损失（也称为交叉熵）来评估模型。</p>
<p>这个竞赛在 2015 年 5 月完成，这个数据集对 XGBoost 来说是一个很好的挑战，因为有大量的例子和问题的难度以及需要很少的数据准备这一事实（除了将字符串类变量编码为整数）。</p>
<h2 id="线程数的影响"><a href="#线程数的影响" class="headerlink" title="线程数的影响"></a>线程数的影响</h2><p>XGBoost 在 C ++中实现，以明确地使用 <a href="https://en.wikipedia.org/wiki/OpenMP" target="_blank" rel="noopener">OpenMP API</a> 进行并行处理。</p>
<p>梯度提升中的并行性可以在单个树的构造中实现，而不是像随机森林那样并行创建树。这是因为在增强中，树木被顺序添加到模型中。 XGBoost 的速度既可以在单个树木的构造中增加平行度，也可以有效地准备输入数据，以帮助加快树木的构建。</p>
<p>根据您的平台，您可能需要专门编译 XGBoost 以支持多线程。有关详细信息，请参阅 <a href="https://github.com/dmlc/xgboost/blob/master/doc/build.md" target="_blank" rel="noopener">XGBoost 安装说明</a>。</p>
<p>用于 scikit-learn 的 XGBoost 的 <strong>XGBClassifier</strong> 和 <strong>XGBRegressor</strong> 包装类提供了 <strong>nthread</strong> 参数，用于指定 XGBoost 在训练期间可以使用的线程数。</p>
<p>默认情况下，此参数设置为-1 以使用系统中的所有核心。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = XGBClassifier(nthread=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>通常，您应该为 XGBoost 安装获得多线程支持，而无需任何额外的工作。</p>
<p>根据您的 Python 环境（例如 Python 3），您可能需要显式启用 XGBoost 的多线程支持。如果您需要帮助， <a href="https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_parallel.py" target="_blank" rel="noopener">XGBoost 库提供了一个示例</a>。</p>
<p>您可以通过构建许多不同的 XGBoost 模型来确认 XGBoost 多线程支持是否正常工作，指定线程数并计算构建每个模型所需的时间。这一趋势将向您展示启用了多线程支持，并指出了构建模型时的效果。</p>
<p>例如，如果您的系统有 4 个核心，您可以训练 8 个不同的模型，并计算创建每个模型所需的时间（以秒为单位），然后比较时间。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># evaluate the effect of the number of threads</span></span><br><span class="line">results = []</span><br><span class="line">num_threads = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> num_threads:</span><br><span class="line">	start = time.time()</span><br><span class="line">	model = XGBClassifier(nthread=n)</span><br><span class="line">	model.fit(X_train, y_train)</span><br><span class="line">	elapsed = time.time() - start</span><br><span class="line">	print(n, elapsed)</span><br><span class="line">	results.append(elapsed)</span><br></pre></td></tr></table></figure>
<p>我们可以在 Otto 数据集上使用这种方法。下面提供完整示例以确保完整性。</p>
<p>您可以更改 <strong>num_threads</strong> 阵列以满足系统上的核心数。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Otto, tune number of threads</span></span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">data = read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">dataset = data.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">94</span>]</span><br><span class="line">y = dataset[:,<span class="number">94</span>]</span><br><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoded_y = LabelEncoder().fit_transform(y)</span><br><span class="line"><span class="comment"># evaluate the effect of the number of threads</span></span><br><span class="line">results = []</span><br><span class="line">num_threads = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> num_threads:</span><br><span class="line">	start = time.time()</span><br><span class="line">	model = XGBClassifier(nthread=n)</span><br><span class="line">	model.fit(X, label_encoded_y)</span><br><span class="line">	elapsed = time.time() - start</span><br><span class="line">	print(n, elapsed)</span><br><span class="line">	results.append(elapsed)</span><br><span class="line"><span class="comment"># plot results</span></span><br><span class="line">pyplot.plot(num_threads, results)</span><br><span class="line">pyplot.ylabel(<span class="string">'Speed (seconds)'</span>)</span><br><span class="line">pyplot.xlabel(<span class="string">'Number of Threads'</span>)</span><br><span class="line">pyplot.title(<span class="string">'XGBoost Training Speed vs Number of Threads'</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>运行此示例总结了每个配置的执行时间（以秒为单位），例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1</span>, <span class="number">115.51652717590332</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="number">62.7727689743042</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">46.042901039123535</span>)</span><br><span class="line">(<span class="number">4</span>, <span class="number">40.55334496498108</span>)</span><br></pre></td></tr></table></figure>
<p>下面提供了这些时间的图表。</p>
<p><img src="img/146726c5dc2eed3eec56e9a56373187a.jpg" alt="XGBoost Tune Number of Threads for Single Model"></p>
<p>XGBoost Tune 单个模型的线程数</p>
<p>随着线程数量的增加，我们可以看到执行时间减少的好趋势。</p>
<p>如果您没有看到每个新线程的运行时间有所改善，您可能需要研究如何在安装过程中或运行时在 XGBoost 中启用多线程支持。</p>
<p>我们可以在具有更多内核的机器上运行相同的代码。据报道，大型 Amazon Web Services EC2 实例具有 32 个核心。我们可以调整上面的代码来计算训练具有 1 到 32 个内核的模型所需的时间。结果如下。</p>
<p><img src="img/146f19ae6f7ee6886994a2b084b410b3.jpg" alt="XGBoost Time to Train Model on 1 to 32 Cores"></p>
<p>XGBoost 在 1 到 32 个核心上训练模型的时间</p>
<p>值得注意的是，除了 16 个线程（大约 7 秒）之外，我们没有看到太多改进。我希望其原因是亚马逊实例仅在硬件中提供 16 个内核，并且超线程可以提供额外的 16 个内核。结果表明，如果您的计算机具有超线程，则可能需要将 <strong>num_threads</strong> 设置为等于计算机中物理 CPU 核心的数量。</p>
<p>使用 OpenMP 进行 XGBoost 的低级优化实现会挤出像这样的大型机器的每个最后一个周期。</p>
<h2 id="交叉验证-XGBoost-模型时的并行性"><a href="#交叉验证-XGBoost-模型时的并行性" class="headerlink" title="交叉验证 XGBoost 模型时的并行性"></a>交叉验证 XGBoost 模型时的并行性</h2><p>scikit-learn 中的 k-fold 交叉验证支持也支持多线程。</p>
<p>例如， <strong>cross_val_score（）</strong>函数上的 <strong>n_jobs</strong> 参数用于使用 k-fold 交叉验证评估数据集上的模型，允许您指定要运行的并行作业数。</p>
<p>默认情况下，此值设置为 1，但可以设置为-1 以使用系统上的所有 CPU 核心，这是一种很好的做法。例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring=<span class="string">'log_loss'</span>, n_jobs=<span class="number">-1</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>这就提出了如何配置交叉验证的问题：</p>
<ul>
<li>禁用 XGBoost 中的多线程支持，并允许交叉验证在所有核心上运行。</li>
<li>在交叉验证中禁用多线程支持，并允许 XGBoost 在所有核心上运行。</li>
<li>为 XGBoost 和 Cross 验证启用多线程支持。</li>
</ul>
<p>我们可以通过简单计算在每种情况下评估模型所需的时间来得到这个问题的答案。</p>
<p>在下面的示例中，我们使用 10 倍交叉验证来评估 Otto 训练数据集上的默认 XGBoost 模型。评估上述每个场景，并报告评估模型所花费的时间。</p>
<p>完整的代码示例如下所示。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Otto, parallel cross validation</span></span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">data = read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">dataset = data.values</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">94</span>]</span><br><span class="line">y = dataset[:,<span class="number">94</span>]</span><br><span class="line"><span class="comment"># encode string class values as integers</span></span><br><span class="line">label_encoded_y = LabelEncoder().fit_transform(y)</span><br><span class="line"><span class="comment"># prepare cross validation</span></span><br><span class="line">kfold = StratifiedKFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># Single Thread XGBoost, Parallel Thread CV</span></span><br><span class="line">start = time.time()</span><br><span class="line">model = XGBClassifier(nthread=<span class="number">1</span>)</span><br><span class="line">results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring=<span class="string">'neg_log_loss'</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">elapsed = time.time() - start</span><br><span class="line">print(<span class="string">"Single Thread XGBoost, Parallel Thread CV: %f"</span> % (elapsed))</span><br><span class="line"><span class="comment"># Parallel Thread XGBoost, Single Thread CV</span></span><br><span class="line">start = time.time()</span><br><span class="line">model = XGBClassifier(nthread=<span class="number">-1</span>)</span><br><span class="line">results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring=<span class="string">'neg_log_loss'</span>, n_jobs=<span class="number">1</span>)</span><br><span class="line">elapsed = time.time() - start</span><br><span class="line">print(<span class="string">"Parallel Thread XGBoost, Single Thread CV: %f"</span> % (elapsed))</span><br><span class="line"><span class="comment"># Parallel Thread XGBoost and CV</span></span><br><span class="line">start = time.time()</span><br><span class="line">model = XGBClassifier(nthread=<span class="number">-1</span>)</span><br><span class="line">results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring=<span class="string">'neg_log_loss'</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">elapsed = time.time() - start</span><br><span class="line">print(<span class="string">"Parallel Thread XGBoost and CV: %f"</span> % (elapsed))</span><br></pre></td></tr></table></figure>
<p>运行该示例将打印以下结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Single Thread XGBoost, Parallel Thread CV: <span class="number">359.854589</span></span><br><span class="line">Parallel Thread XGBoost, Single Thread CV: <span class="number">330.498101</span></span><br><span class="line">Parallel Thread XGBoost <span class="keyword">and</span> CV: <span class="number">313.382301</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到，通过交叉验证折叠并行化 XGBoost 会带来好处。这是有道理的，因为 10 个连续快速任务比（10 除以 num_cores）慢任务更好。</p>
<p>有趣的是，我们可以看到通过在 XGBoost 和交叉验证中启用多线程来实现最佳结果。这是令人惊讶的，因为这意味着 num_cores 数量的并行 XGBoost 模型在其模型构造中竞争相同的 num_cores。然而，这实现了最快的结果，并且建议使用 XGBoost 进行交叉验证。</p>
<p>因为网格搜索使用相同的基础方法来实现并行性，所以我们期望同样的发现可用于优化 XGBoost 的超参数。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了 XGBoost 的多线程功能。</p>
<p>你了解到：</p>
<ul>
<li>如何检查系统上是否启用了 XGBoost 中的多线程支持。</li>
<li>如何增加线程数会影响训练 XGBoost 模型的表现。</li>
<li>如何在 Python 中最佳地配置 XGBoost 和交叉验证，以最短的运行时间。</li>
</ul>
<p>您对 XGBoost 或此帖子的多线程支持有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/如何在 Python 中调优 XGBoost 的多线程支持/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/通过在 Python 中使用 XGBoost 提前停止来避免过度拟合" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/26/yuque/通过在 Python 中使用 XGBoost 提前停止来避免过度拟合/">通过在 Python 中使用 XGBoost 提前停止来避免过度拟合</a>
    </h1>
  

        
        <a href="/2019/04/26/yuque/通过在 Python 中使用 XGBoost 提前停止来避免过度拟合/" class="archive-article-date">
  	<time datetime="2019-04-26T03:15:01.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-26</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href></a><a name="49c4a9fb"></a></p>
<h1 id="通过在-Python-中使用-XGBoost-提前停止来避免过度拟合"><a href="#通过在-Python-中使用-XGBoost-提前停止来避免过度拟合" class="headerlink" title="通过在 Python 中使用 XGBoost 提前停止来避免过度拟合"></a>通过在 Python 中使用 XGBoost 提前停止来避免过度拟合</h1><blockquote>
<p>原文： <a href="https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/</a></p>
</blockquote>
<p>过度拟合是复杂的非线性学习算法（例如梯度提升）的问题。</p>
<p>在这篇文章中，您将了解如何使用早期停止来限制 Python 中的 XGBoost 过度拟合。</p>
<p>阅读这篇文章后，你会知道：</p>
<ul>
<li>关于早期停止作为减少训练数据过度拟合的方法。</li>
<li>如何在训练期间监控 XGBoost 模型的表现并绘制学习曲线。</li>
<li>如何使用早期停止来提前停止在最佳时期训练 XGBoost 模型。</li>
</ul>
<p>让我们开始吧。</p>
<ul>
<li><strong>2017 年 1 月更新</strong>：已更新，以反映 scikit-learn API 版本 0.18.1 中的更改​​。</li>
<li><strong>更新 March / 2018</strong> ：添加了备用链接以下载数据集，因为原始图像已被删除。</li>
</ul>
<p><img src="img/3b5a137b9d5bd85033c44aac0f3068ff.jpg#alt=Avoid%20Overfitting%20By%20Early%20Stopping%20With%20XGBoost%20In%20Python" alt></p>
<p>通过 Python 中的 XGBoost 提前停止来避免过度拟合<br><br>照片由 <a href="https://www.flickr.com/photos/michitux/7218180540/" target="_blank" rel="noopener">Michael Hamann</a> 拍摄，保留一些权利。</p>
<p><a href></a><a name="a876c49b"></a></p>
<h2 id="提前停止以避免过度拟合"><a href="#提前停止以避免过度拟合" class="headerlink" title="提前停止以避免过度拟合"></a>提前停止以避免过度拟合</h2><p><a href="https://en.wikipedia.org/wiki/Early_stopping" target="_blank" rel="noopener">早期停止</a>是一种训练复杂机器学习模型的方法，以避免过度拟合。</p>
<p>它通过监视在单独的测试数据集上训练的模型的表现并且一旦在固定数量的训练迭代之后测试数据集上的表现没有改善就停止训练过程。</p>
<p>它通过尝试自动选择测试数据集上的表现开始降低的拐点来避免过度拟合，同时随着模型开始过度拟合，训练数据集上的表现继续提高。</p>
<p>表现度量可以是针对训练模型而优化的损失函数（例如对数损失），或者一般对问题感兴趣的外部度量（例如分类准确度）。</p>
<p><a href></a><a name="bd09b8be"></a></p>
<h2 id="使用-XGBoost-监控训练表现"><a href="#使用-XGBoost-监控训练表现" class="headerlink" title="使用 XGBoost 监控训练表现"></a>使用 XGBoost 监控训练表现</h2><p>XGBoost 模型可以在训练期间评估和报告模型的测试集上的表现。</p>
<p>它通过在训练模型和指定详细输出时调用 <strong>model.fit（）</strong>时指定测试数据集和评估指标来支持此功能。</p>
<p>例如，我们可以在独立测试集（ <strong>eval_set</strong> ）上报告二进制分类错误率（“_ 错误 _”），同时训练 XGBoost 模型，如下所示：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval_set = [(X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, eval_metric=<span class="string">"error"</span>, eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>XGBoost 支持一套评估指标，不仅限于：</p>
<ul>
<li>“ <em>rmse</em> ”表示均方根误差。</li>
<li>“ <em>mae</em> ”表示平均绝对误差。</li>
<li>“ _logloss_mlogloss_ ”用于多级对数损失（交叉熵）。</li>
<li>“_ 错误 _”表示分类错误。</li>
<li>“ <em>auc</em> ”用于 ROC 曲线下的面积。</li>
</ul>
<p>完整列表在 XGBoost 参数网页的“<a href="http://xgboost.readthedocs.io/en/latest//parameter.html" target="_blank" rel="noopener">学习任务参数</a>”部分中提供。</p>
<p>例如，我们可以演示如何跟踪 <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank" rel="noopener">Pima 印第安人糖尿病数据集</a>的 XGBoost 模型训练的表现，可从 UCI 机器学习库获取（更新：<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv" target="_blank" rel="noopener">从此处下载</a>）。</p>
<p>完整示例如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># monitor training performance</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">eval_set = [(X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, eval_metric=<span class="string">"error"</span>, eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行此示例在 67％的数据上训练模型，并在 33％的测试数据集上评估每个训练时期的模型。</p>
<p>每次迭代都会报告分类错误，最后报告分类准确性。</p>
<p>下面提供了输出，为简洁起见，将其截断。我们可以看到，每次训练迭代都会报告分类错误（在每个提升的树被添加到模型之后）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">[<span class="number">89</span>]	validation_0-error:<span class="number">0.204724</span></span><br><span class="line">[<span class="number">90</span>]	validation_0-error:<span class="number">0.208661</span></span><br><span class="line">[<span class="number">91</span>]	validation_0-error:<span class="number">0.208661</span></span><br><span class="line">[<span class="number">92</span>]	validation_0-error:<span class="number">0.208661</span></span><br><span class="line">[<span class="number">93</span>]	validation_0-error:<span class="number">0.208661</span></span><br><span class="line">[<span class="number">94</span>]	validation_0-error:<span class="number">0.208661</span></span><br><span class="line">[<span class="number">95</span>]	validation_0-error:<span class="number">0.212598</span></span><br><span class="line">[<span class="number">96</span>]	validation_0-error:<span class="number">0.204724</span></span><br><span class="line">[<span class="number">97</span>]	validation_0-error:<span class="number">0.212598</span></span><br><span class="line">[<span class="number">98</span>]	validation_0-error:<span class="number">0.216535</span></span><br><span class="line">[<span class="number">99</span>]	validation_0-error:<span class="number">0.220472</span></span><br><span class="line">Accuracy: <span class="number">77.95</span>%</span><br></pre></td></tr></table></figure>
<p>回顾所有输出，我们可以看到测试集上的模型表现平稳，甚至在训练结束时变得更糟。</p>
<p><a href></a><a name="7a25cb01"></a></p>
<h2 id="使用学习曲线评估-XGBoost-模型"><a href="#使用学习曲线评估-XGBoost-模型" class="headerlink" title="使用学习曲线评估 XGBoost 模型"></a>使用学习曲线评估 XGBoost 模型</h2><p>我们可以在评估数据集上检索模型的表现并绘制它以深入了解在训练时如何展开学习。</p>
<p>在拟合 XGBoost 模型时，我们为 <strong>eval_metric</strong> 参数提供了一对 X 和 y 对。除了测试集，我们还可以提供训练数据集。这将提供一份报告，说明模型在训练期间对训练和测试集的执行情况。</p>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval_set = [(X_train, y_train), (X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, eval_metric=<span class="string">"error"</span>, eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>此外，通过调用 <strong>model.evals_result（）</strong>函数，模型在训练后存储并使模型在每个评估集上的表现可用。这将返回评估数据集和分数的字典，例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">results = model.evals_result()</span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<p>这将打印如下结果（为简洁起见，将其截断）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="string">'validation_0'</span>: &#123;<span class="string">'error'</span>: [<span class="number">0.259843</span>, <span class="number">0.26378</span>, <span class="number">0.26378</span>, ...]&#125;,</span><br><span class="line">	<span class="string">'validation_1'</span>: &#123;<span class="string">'error'</span>: [<span class="number">0.22179</span>, <span class="number">0.202335</span>, <span class="number">0.196498</span>, ...]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>‘ _validation_0_ ‘和’ _validation_1_ ‘中的每一个对应于在 <strong>fit（）调用中向 </strong>eval_set<strong> 参数提供数据集的顺序</strong>。</p>
<p>可以按如下方式访问特定的结果数组，例如第一个数据集和错误度量标准：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results[<span class="string">'validation_0'</span>][<span class="string">'error'</span>]</span><br></pre></td></tr></table></figure>
<p>此外，我们可以通过为 <strong>fit（）</strong>函数的 eval_metric 参数提供一系列度量来指定更多评估度量来评估和收集。</p>
<p>然后，我们可以使用这些收集的表现度量来创建线图，并进一步了解模型在训练时期的训练和测试数据集上的表现。</p>
<p>下面是完整的代码示例，显示了如何在线图上显示收集的结果。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot learning curve</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">eval_set = [(X_train, y_train), (X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, eval_metric=[<span class="string">"error"</span>, <span class="string">"logloss"</span>], eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br><span class="line"><span class="comment"># retrieve performance metrics</span></span><br><span class="line">results = model.evals_result()</span><br><span class="line">epochs = len(results[<span class="string">'validation_0'</span>][<span class="string">'error'</span>])</span><br><span class="line">x_axis = range(<span class="number">0</span>, epochs)</span><br><span class="line"><span class="comment"># plot log loss</span></span><br><span class="line">fig, ax = pyplot.subplots()</span><br><span class="line">ax.plot(x_axis, results[<span class="string">'validation_0'</span>][<span class="string">'logloss'</span>], label=<span class="string">'Train'</span>)</span><br><span class="line">ax.plot(x_axis, results[<span class="string">'validation_1'</span>][<span class="string">'logloss'</span>], label=<span class="string">'Test'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">pyplot.ylabel(<span class="string">'Log Loss'</span>)</span><br><span class="line">pyplot.title(<span class="string">'XGBoost Log Loss'</span>)</span><br><span class="line">pyplot.show()</span><br><span class="line"><span class="comment"># plot classification error</span></span><br><span class="line">fig, ax = pyplot.subplots()</span><br><span class="line">ax.plot(x_axis, results[<span class="string">'validation_0'</span>][<span class="string">'error'</span>], label=<span class="string">'Train'</span>)</span><br><span class="line">ax.plot(x_axis, results[<span class="string">'validation_1'</span>][<span class="string">'error'</span>], label=<span class="string">'Test'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">pyplot.ylabel(<span class="string">'Classification Error'</span>)</span><br><span class="line">pyplot.title(<span class="string">'XGBoost Classification Error'</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>运行此代码会报告每个纪元的训练和测试数据集的分类错误。我们可以通过在 <strong>fit（）</strong>函数的调用中设置 <strong>verbose = False</strong> （默认值）来关闭它。</p>
<p>创建了两个图。第一个显示了训练和测试数据集中每个时期的 XGBoost 模型的对数损失。</p>
<p><img src="img/3dd164f486ba1862fa97f82eb6693360.jpg#alt=XGBoost%20Learning%20Curve%20Log%20Loss" alt></p>
<p>XGBoost 学习曲线日志丢失</p>
<p>第二个图显示了训练和测试数据集中每个时期的 XGBoost 模型的分类错误。</p>
<p><img src="img/cdfec3000bac01a37daacb6f874ff978.jpg#alt=XGBoost%20Learning%20Curve%20Classification%20Error" alt></p>
<p>XGBoost 学习曲线分类错误</p>
<p>通过回顾 logloss 图，看起来有机会提前停止学习，也许在 20 世纪到 40 世纪左右。</p>
<p>我们看到了类似的分类错误故事，其中错误似乎在 40 左右的时间内重新出现。</p>
<p><a href></a><a name="c8947272"></a></p>
<h2 id="早期停止使用-XGBoost"><a href="#早期停止使用-XGBoost" class="headerlink" title="早期停止使用 XGBoost"></a>早期停止使用 XGBoost</h2><p>XGBoost 支持在固定次数的迭代后提前停止。</p>
<p>除了为每个时期指定用于评估的度量和度量数据集之外，还必须指定一个窗口，其中没有观察到任何改进的时期数。这在 <strong>early_stopping_rounds</strong> 参数中指定。</p>
<p>例如，我们可以检查 10 个时期的对数损失没有改善如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval_set = [(X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, early_stopping_rounds=<span class="number">10</span>, eval_metric=<span class="string">"logloss"</span>, eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>如果提供了多个评估数据集或多个评估指标，则提前停止将使用列表中的最后一个。</p>
<p>下面提供了完整性的完整示例，提前停止。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># early stopping</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">dataset = loadtxt(<span class="string">'pima-indians-diabetes.csv'</span>, delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># split data into X and y</span></span><br><span class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">Y = dataset[:,<span class="number">8</span>]</span><br><span class="line"><span class="comment"># split data into train and test sets</span></span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">test_size = <span class="number">0.33</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)</span><br><span class="line"><span class="comment"># fit model no training data</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">eval_set = [(X_test, y_test)]</span><br><span class="line">model.fit(X_train, y_train, early_stopping_rounds=<span class="number">10</span>, eval_metric=<span class="string">"logloss"</span>, eval_set=eval_set, verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># make predictions for test data</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="comment"># evaluate predictions</span></span><br><span class="line">accuracy = accuracy_score(y_test, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>
<p>运行该示例提供以下输出，为简洁起见，将其截断：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">[<span class="number">35</span>]	validation_0-logloss:<span class="number">0.487962</span></span><br><span class="line">[<span class="number">36</span>]	validation_0-logloss:<span class="number">0.488218</span></span><br><span class="line">[<span class="number">37</span>]	validation_0-logloss:<span class="number">0.489582</span></span><br><span class="line">[<span class="number">38</span>]	validation_0-logloss:<span class="number">0.489334</span></span><br><span class="line">[<span class="number">39</span>]	validation_0-logloss:<span class="number">0.490969</span></span><br><span class="line">[<span class="number">40</span>]	validation_0-logloss:<span class="number">0.48978</span></span><br><span class="line">[<span class="number">41</span>]	validation_0-logloss:<span class="number">0.490704</span></span><br><span class="line">[<span class="number">42</span>]	validation_0-logloss:<span class="number">0.492369</span></span><br><span class="line">Stopping. Best iteration:</span><br><span class="line">[<span class="number">32</span>]	validation_0-logloss:<span class="number">0.487297</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到模型在第 42 纪元停止训练（接近我们对学习曲线的手动判断的预期），并且在第 32 纪元观察到具有最佳损失的模型。</p>
<p>选择 <strong>early_stopping_rounds</strong> 作为训练时期总数（在这种情况下为 10％）的合理函数通常是个好主意，或者尝试对应于在情节上可以观察到的拐点时期。学习曲线。</p>
<p><a href></a><a name="3ae14696"></a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这篇文章中，您发现了监控表现和提前停止。</p>
<p>你了解到：</p>
<ul>
<li>关于在模型过度训练数据之前停止模型训练的早期停止技术。</li>
<li>如何在训练期间监控 XGBoost 模型的表现并绘制学习曲线。</li>
<li>如何在训练 XGBoost 模型时配置早期停止。</li>
</ul>
<p>您对过度拟合或有关此帖子有任何疑问吗？在评论中提出您的问题，我会尽力回答。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/26/yuque/通过在 Python 中使用 XGBoost 提前停止来避免过度拟合/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-yuque/时间序列分类实践介绍（使用Python代码）" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/25/yuque/时间序列分类实践介绍（使用Python代码）/">时间序列分类实践介绍（使用Python代码）</a>
    </h1>
  

        
        <a href="/2019/04/25/yuque/时间序列分类实践介绍（使用Python代码）/" class="archive-article-date">
  	<time datetime="2019-04-25T09:48:43.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href></a><br><a name="61a3ec66"></a></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>分类时间序列数据？这真的有可能吗？可能有什么用呢？这些只是您阅读本文标题时必须具备的一些问题。这是公平的 - 当我第一次遇到这个概念时，我有完全相同的想法！</p>
<p>我们大多数人的时间序列数据主要涉及产生预测的交易。无论是预测产品的需求还是销售额，航空公司的乘客数量或特定股票的收盘价，我们都习惯于利用久经考验的时间序列技术来预测需求。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/jpeg/219582/1556185921707-66d9bdc3-0973-4b8a-bac2-9d55f161b0d1.jpeg#align=left&amp;display=inline&amp;height=370&amp;name=time-series-.jpg&amp;originHeight=370&amp;originWidth=500&amp;size=129532&amp;status=done&amp;width=500" alt="time-series-.jpg"></p>
<p>但随着生成的数据量呈指数增长，尝试新想法和算法的机会也随之增加。使用复杂的时间序列数据集仍然是一个利基领域，扩展您的保留曲目以包含新想法总是有帮助的。</p>
<p>这就是我在文章中的目的，向您介绍时间序列分类的新概念。我们将首先了解这个主题的含义以及它在行业中的应用。但是我们不会停留在理论部分 - 我们将通过处理时间序列数据集并执行二进制时间序列分类来解决问题。边做边学 - 这将有助于您以实际的方式理解这个概念。</p>
<p>如果您之前没有处理过时间序列问题，我强烈建议您先从一些基本预测开始。您可以通过以下文章了解初学者：</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/" target="_blank" rel="noopener">全面的初学者指南，用于创建时间序列预测（使用Python中的代码）</a></li>
</ul>
        
          <a class="article-more-a" href="/2019/04/25/yuque/时间序列分类实践介绍（使用Python代码）/#more">more >></a>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/25/yuque/时间序列分类实践介绍（使用Python代码）/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 Zhos
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br>1、请确保node版本大于6.2<br>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br> npm i hexo-generator-json-content --save<br><br>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://www.zhos.me/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">很惭愧&lt;br&gt;&lt;br&gt;只做了一点微小的工作&lt;br&gt;谢谢大家</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>